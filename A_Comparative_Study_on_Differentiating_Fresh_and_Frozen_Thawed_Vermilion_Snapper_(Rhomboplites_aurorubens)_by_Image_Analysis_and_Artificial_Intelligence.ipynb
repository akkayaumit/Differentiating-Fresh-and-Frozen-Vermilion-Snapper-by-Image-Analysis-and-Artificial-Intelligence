{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "kkWt_4vVENns"
      },
      "outputs": [],
      "source": [
        "# for loading/processing the images\n",
        "from keras.preprocessing.image import load_img\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "\n",
        "# models\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.models import Model\n",
        "\n",
        "# clustering and dimension reduction\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# for everything else\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from random import randint\n",
        "import pandas as pd\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Python version\n",
        "import sys\n",
        "print(f\"Python version: {sys.version}\")\n",
        "\n",
        "# Check TensorFlow version\n",
        "import tensorflow as tf\n",
        "print(f\"TensorFlow version: {tf.__version__}\")\n",
        "\n",
        "# Check Keras version\n",
        "import keras\n",
        "print(f\"Keras version: {keras.__version__}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GtQZhRCuF792",
        "outputId": "2be4c51a-ed4f-41fa-81fa-9abc134c038a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python version: 3.10.12 (main, Sep 11 2024, 15:47:36) [GCC 11.4.0]\n",
            "TensorFlow version: 2.17.0\n",
            "Keras version: 3.4.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Dosyaların Drive dan alınması\n",
        "path = r\"/content/drive/MyDrive/CorrectedAll\"\n",
        "\n",
        "# change the working directory to the path where the images are located\n",
        "os.chdir(path)\n",
        "\n",
        "# this list holds all the image filename\n",
        "flowers = []\n",
        "\n",
        "# creates a ScandirIterator aliased as files\n",
        "with os.scandir(path) as files:\n",
        "  # loops through each file in the directory\n",
        "    for file in files:\n",
        "        if file.name.endswith('.jpg'):\n",
        "          # adds only the image files to the flowers list\n",
        "            flowers.append(file.name)"
      ],
      "metadata": {
        "id": "FHp9G3edGCf_"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# removing faulty images\n",
        "strings_to_remove = {'F20T1_102Left_CorrectedImage.jpg', 'F20T3-201Left_CorrectedImage.jpg'}\n",
        "\n",
        "flowers = list(filter(lambda x: x not in strings_to_remove, flowers))"
      ],
      "metadata": {
        "id": "GqXxltdqGSRG"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# extracting features from images using Transfer Learning\n",
        "model = VGG16()\n",
        "model = Model(inputs = model.inputs, outputs = model.layers[-2].output)\n",
        "\n",
        "def extract_features(file, model):\n",
        "\n",
        "    #crop images resize and load\n",
        "    img = load_img(file)\n",
        "    img = img.crop((0,0,img.size[0],img.size[1]-220))\n",
        "    img = img.resize((224,224))\n",
        "\n",
        "\n",
        "    # convert from image to numpy array\n",
        "    img = np.array(img)\n",
        "    # reshape the data for the model reshape(num_of_samples, dim 1, dim 2, channels)\n",
        "    reshaped_img = img.reshape(1,224,224,3)\n",
        "    # prepare image for model\n",
        "    imgx = preprocess_input(reshaped_img)\n",
        "    # get the feature vector\n",
        "    features = model.predict(imgx)\n",
        "    return features"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jgZe3l4IGcIF",
        "outputId": "2890f4ef-ed88-4bf7-caf6-5b74ae18a2a4"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n",
            "\u001b[1m553467096/553467096\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# rigth, left for two-class classification\n",
        "def get_label(flower):\n",
        "    if 'ight' in flower:\n",
        "        return '0'\n",
        "    elif 'eft' in flower:\n",
        "        return '1'\n",
        "    else:\n",
        "        return '7'\n",
        "\n",
        "# Create the DataFrame\n",
        "df = pd.DataFrame({'file': flowers})\n",
        "df['label'] = df['file'].apply(get_label)"
      ],
      "metadata": {
        "id": "GO0iHyjdI515"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# assigning Labels to Images\n",
        "def get_label(flower):\n",
        "    if 'Fresh' in flower:\n",
        "        return '0'\n",
        "    elif 'F20T1' in flower:\n",
        "        return '1'\n",
        "    elif 'F20T2' in flower:\n",
        "        return '1'\n",
        "    elif 'F20T3' in flower:\n",
        "        return '1'\n",
        "    elif 'F60T1' in flower:\n",
        "        return '2'\n",
        "    elif 'F60-T1' in flower:\n",
        "        return '2'\n",
        "    elif 'F60T2' in flower:\n",
        "        return '2'\n",
        "    elif 'F60T3' in flower:\n",
        "        return '2'\n",
        "    else:\n",
        "        return '7'\n",
        "\n",
        "# create the DataFrame\n",
        "df = pd.DataFrame({'file': flowers})\n",
        "df['label'] = df['file'].apply(get_label)"
      ],
      "metadata": {
        "id": "CG1t85KJJ3HP"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = df['label'].tolist()"
      ],
      "metadata": {
        "id": "D3mK1dbCMEaL"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Count the number of elements in each class\n",
        "class_counts = df['label'].value_counts()\n",
        "\n",
        "print(class_counts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cOfIS1s2KKBf",
        "outputId": "931d4755-ae11-47a9-cc19-69865fdc9431"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "label\n",
            "1    46\n",
            "2    45\n",
            "0    32\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# extracting features from images using Transfer Learning\n",
        "data = {}\n",
        "\n",
        "for flower in flowers:\n",
        "  feat = extract_features(flower,model)\n",
        "  data[flower] = feat"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "0XymWX29KT2e",
        "outputId": "3ddf7fc4-edd7-4f80-e286-2f0c08155cbb"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 929ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 583ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 546ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 573ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 573ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 598ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 569ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 572ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 570ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 574ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 560ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 559ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 561ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 584ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 949ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step   \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 824ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 574ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 568ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 568ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 574ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 556ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 572ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 877ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 559ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 575ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 694ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 942ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 922ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 980ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 952ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 595ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 589ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 571ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 577ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 585ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 564ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 599ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 573ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 565ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 595ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 558ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 589ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 586ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 576ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 586ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 637ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 891ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 932ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 866ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 559ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 591ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 558ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 577ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 594ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 573ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 584ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 576ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 576ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 590ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 577ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 594ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 600ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 577ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 585ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 930ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 994ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 989ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 985ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 968ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 565ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 597ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 599ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 567ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 587ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 566ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 572ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 573ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 558ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 580ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 575ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 562ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 579ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 565ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 577ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 737ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 988ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 627ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 574ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 587ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 566ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 581ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 553ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 550ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 579ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 556ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 587ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 577ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 565ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 586ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 582ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 596ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 611ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 981ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 982ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 968ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 950ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# put the extracted features together in an array\n",
        "filenames = np.array(list(data.keys()))\n",
        "\n",
        "feat = np.array(list(data.values()))\n",
        "\n",
        "feat = feat.reshape(-1,4096)"
      ],
      "metadata": {
        "id": "0mo8g7w9Ksd1"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# obtaining PCA components\n",
        "pca = PCA(n_components=3, random_state=22)\n",
        "pca.fit(feat)\n",
        "x = pca.transform(feat)\n",
        "\n",
        "labels_array = np.array(labels)\n",
        "\n",
        "# to be used when any class needs to be removed\n",
        "indices_to_keep = labels_array != '7'\n",
        "\n",
        "filtered_features = x[indices_to_keep]\n",
        "labels = labels_array[indices_to_keep]"
      ],
      "metadata": {
        "id": "w9d500EvLCNt"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_features.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hnWi-v0sTJAX",
        "outputId": "fe1a8852-4918-49a0-ed0c-2862d2d7238b"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(123, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Extract x, y coordinates from features\n",
        "x1 = filtered_features[:, 0]\n",
        "y = filtered_features[:, 1]\n",
        "\n",
        "# Define custom labels, colors, and markers for each category\n",
        "custom_label_names = [\"Frozen at -20\", \"Frozen at -60\"]\n",
        "#custom_label_names = [\"Fish Right Side\", \"Fish Left Side\"]\n",
        "custom_colors = [\"blue\", \"orange\"]\n",
        "custom_markers = [\"o\", \"^\"]\n",
        "\n",
        "# Create the figure for a single plot\n",
        "plt.figure(figsize=(10, 8))\n",
        "\n",
        "# Plot data for each label\n",
        "for label, custom_name, color, marker in zip(sorted(set(labels)), custom_label_names, custom_colors, custom_markers):\n",
        "    indices = [i for i, l in enumerate(labels) if l == label]\n",
        "    plt.scatter(x1[indices], y[indices], label=custom_name, color=color, marker=marker)\n",
        "\n",
        "# Set axis labels and legend\n",
        "plt.xlabel('PC 1')\n",
        "plt.ylabel('PC 2')\n",
        "plt.legend()\n",
        "\n",
        "# Adjust layout\n",
        "plt.tight_layout()\n",
        "\n",
        "# Save the plot as a PNG file\n",
        "file_name = '/content/scatter_plots_Frozen20_Frozen60.jpeg'\n",
        "plt.savefig(file_name, format='jpeg', dpi=800)\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 807
        },
        "id": "8yyWVTzdA8EP",
        "outputId": "ced3999d-dc29-4822-f493-0846a9910839"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x800 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#2 class right left classification\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from keras.utils import to_categorical\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_curve, roc_auc_score\n",
        "from keras.models import Sequential, load_model\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Assuming x_train, y_train are available from the previous code\n",
        "\n",
        "# Convert labels to integers using LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "y_train_encoded = label_encoder.fit_transform(labels)\n",
        "y_train_categorical = to_categorical(y_train_encoded)\n",
        "\n",
        "# Split the data into training and validation sets\n",
        "x_train, x_test, y_train_cat, y_test = train_test_split(feat, y_train_categorical, test_size=0.2, random_state=42)\n",
        "x_train, x_val, y_train_cat, y_val_cat = train_test_split(x_train, y_train_cat, test_size=0.25, random_state=42)\n",
        "\n",
        "\n",
        "# Build the neural network model\n",
        "model = Sequential()\n",
        "# pca 3 ile yapılınca alınan sonuç için\n",
        "#model.add(Dense(64, input_dim=3, activation='relu'))\n",
        "model.add(Dense(64, input_dim=4096, activation='relu'))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(16, activation='relu'))\n",
        "model.add(Dense(len(label_encoder.classes_), activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Define early stopping criteria\n",
        "#early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "checkpoint_path = \"/content/drive/MyDrive/CorrectedAll/Model_Weightes/Right_Left.keras\"\n",
        "checkpoint = ModelCheckpoint(checkpoint_path, monitor='val_accuracy', save_best_only=True, mode='max')\n",
        "\n",
        "# Train the model with early stopping\n",
        "model.fit(x_train, y_train_cat, epochs=200, batch_size=32, validation_data=(x_val, y_val_cat), callbacks=[checkpoint])\n",
        "\n",
        "model.load_weights(\"/content/drive/MyDrive/CorrectedAll/Model_Weightes/Right_Left.keras\")\n",
        "# Predict on the test data\n",
        "predicted_probabilities = model.predict(x_test)\n",
        "predicted_labels = np.argmax(predicted_probabilities, axis=1)\n",
        "predicted_labels_original = label_encoder.inverse_transform(predicted_labels)\n",
        "\n",
        "# Convert y_val_cat back to class labels\n",
        "y_val_labels = np.argmax(y_test, axis=1)\n",
        "y_val_labels_original = label_encoder.inverse_transform(y_val_labels)\n",
        "\n",
        "# Calculate and print accuracy, precision, recall, and F1 score\n",
        "accuracy = accuracy_score(y_val_labels_original, predicted_labels_original)\n",
        "precision = precision_score(y_val_labels_original, predicted_labels_original, average='weighted')\n",
        "recall = recall_score(y_val_labels_original, predicted_labels_original, average='weighted')\n",
        "f1 = f1_score(y_val_labels_original, predicted_labels_original, average='weighted')\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1 Score:\", f1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ol39JnCkLH_m",
        "outputId": "8c826041-5ea3-44f6-b695-98371706cf82"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 160ms/step - accuracy: 0.4272 - loss: 0.7210 - val_accuracy: 0.4800 - val_loss: 0.6718\n",
            "Epoch 2/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.7517 - loss: 0.5427 - val_accuracy: 0.6000 - val_loss: 0.6046\n",
            "Epoch 3/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.8436 - loss: 0.4226 - val_accuracy: 0.6400 - val_loss: 0.7233\n",
            "Epoch 4/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.8387 - loss: 0.4157 - val_accuracy: 0.7600 - val_loss: 0.4421\n",
            "Epoch 5/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8387 - loss: 0.2698 - val_accuracy: 0.7600 - val_loss: 0.3499\n",
            "Epoch 6/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.9414 - loss: 0.1586 - val_accuracy: 0.8800 - val_loss: 0.2672\n",
            "Epoch 7/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.9560 - loss: 0.0977 - val_accuracy: 0.9200 - val_loss: 0.1799\n",
            "Epoch 8/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.9892 - loss: 0.0556 - val_accuracy: 0.9600 - val_loss: 0.1466\n",
            "Epoch 9/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 0.0256 - val_accuracy: 0.8800 - val_loss: 0.1786\n",
            "Epoch 10/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0201 - val_accuracy: 0.8800 - val_loss: 0.1790\n",
            "Epoch 11/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 0.0080 - val_accuracy: 0.9600 - val_loss: 0.0778\n",
            "Epoch 12/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 1.0000 - loss: 0.0040 - val_accuracy: 1.0000 - val_loss: 0.0509\n",
            "Epoch 13/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 0.0044 - val_accuracy: 1.0000 - val_loss: 0.0464\n",
            "Epoch 14/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 1.0000 - loss: 0.0028 - val_accuracy: 1.0000 - val_loss: 0.0440\n",
            "Epoch 15/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.9600 - val_loss: 0.0534\n",
            "Epoch 16/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 1.0000 - loss: 0.0010 - val_accuracy: 0.9600 - val_loss: 0.0694\n",
            "Epoch 17/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 1.0000 - loss: 8.8035e-04 - val_accuracy: 0.9600 - val_loss: 0.0820\n",
            "Epoch 18/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 1.0000 - loss: 9.6940e-04 - val_accuracy: 0.9600 - val_loss: 0.0852\n",
            "Epoch 19/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 6.2451e-04 - val_accuracy: 0.9600 - val_loss: 0.0824\n",
            "Epoch 20/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 5.5968e-04 - val_accuracy: 0.9600 - val_loss: 0.0734\n",
            "Epoch 21/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 1.0000 - loss: 4.1957e-04 - val_accuracy: 0.9600 - val_loss: 0.0600\n",
            "Epoch 22/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 4.7021e-04 - val_accuracy: 0.9600 - val_loss: 0.0469\n",
            "Epoch 23/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 1.0000 - loss: 3.2989e-04 - val_accuracy: 1.0000 - val_loss: 0.0404\n",
            "Epoch 24/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 1.0000 - loss: 3.4751e-04 - val_accuracy: 1.0000 - val_loss: 0.0376\n",
            "Epoch 25/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 3.7671e-04 - val_accuracy: 1.0000 - val_loss: 0.0365\n",
            "Epoch 26/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 2.5944e-04 - val_accuracy: 1.0000 - val_loss: 0.0361\n",
            "Epoch 27/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 1.0000 - loss: 3.0132e-04 - val_accuracy: 1.0000 - val_loss: 0.0367\n",
            "Epoch 28/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 2.9410e-04 - val_accuracy: 1.0000 - val_loss: 0.0377\n",
            "Epoch 29/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 2.4772e-04 - val_accuracy: 1.0000 - val_loss: 0.0387\n",
            "Epoch 30/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 2.3505e-04 - val_accuracy: 1.0000 - val_loss: 0.0400\n",
            "Epoch 31/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 2.4893e-04 - val_accuracy: 1.0000 - val_loss: 0.0414\n",
            "Epoch 32/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 1.0000 - loss: 1.8593e-04 - val_accuracy: 1.0000 - val_loss: 0.0427\n",
            "Epoch 33/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 1.0000 - loss: 2.2735e-04 - val_accuracy: 1.0000 - val_loss: 0.0430\n",
            "Epoch 34/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 1.0000 - loss: 1.9696e-04 - val_accuracy: 1.0000 - val_loss: 0.0430\n",
            "Epoch 35/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 1.0000 - loss: 1.8212e-04 - val_accuracy: 1.0000 - val_loss: 0.0418\n",
            "Epoch 36/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 1.6782e-04 - val_accuracy: 1.0000 - val_loss: 0.0401\n",
            "Epoch 37/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 1.0000 - loss: 1.4036e-04 - val_accuracy: 1.0000 - val_loss: 0.0386\n",
            "Epoch 38/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 1.6481e-04 - val_accuracy: 1.0000 - val_loss: 0.0374\n",
            "Epoch 39/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 1.5806e-04 - val_accuracy: 1.0000 - val_loss: 0.0368\n",
            "Epoch 40/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 1.3166e-04 - val_accuracy: 1.0000 - val_loss: 0.0364\n",
            "Epoch 41/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 1.3992e-04 - val_accuracy: 1.0000 - val_loss: 0.0363\n",
            "Epoch 42/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 1.3706e-04 - val_accuracy: 1.0000 - val_loss: 0.0365\n",
            "Epoch 43/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 1.2230e-04 - val_accuracy: 1.0000 - val_loss: 0.0369\n",
            "Epoch 44/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 1.2151e-04 - val_accuracy: 1.0000 - val_loss: 0.0366\n",
            "Epoch 45/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 9.4551e-05 - val_accuracy: 1.0000 - val_loss: 0.0362\n",
            "Epoch 46/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 1.0000 - loss: 1.0349e-04 - val_accuracy: 1.0000 - val_loss: 0.0356\n",
            "Epoch 47/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 1.0000 - loss: 1.1102e-04 - val_accuracy: 1.0000 - val_loss: 0.0347\n",
            "Epoch 48/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 1.0262e-04 - val_accuracy: 1.0000 - val_loss: 0.0342\n",
            "Epoch 49/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 9.1622e-05 - val_accuracy: 1.0000 - val_loss: 0.0337\n",
            "Epoch 50/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 1.0000 - loss: 9.0812e-05 - val_accuracy: 1.0000 - val_loss: 0.0335\n",
            "Epoch 51/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 8.6049e-05 - val_accuracy: 1.0000 - val_loss: 0.0332\n",
            "Epoch 52/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 8.1872e-05 - val_accuracy: 1.0000 - val_loss: 0.0331\n",
            "Epoch 53/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 9.5637e-05 - val_accuracy: 1.0000 - val_loss: 0.0329\n",
            "Epoch 54/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 8.2433e-05 - val_accuracy: 1.0000 - val_loss: 0.0328\n",
            "Epoch 55/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 8.1373e-05 - val_accuracy: 1.0000 - val_loss: 0.0330\n",
            "Epoch 56/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 7.8424e-05 - val_accuracy: 1.0000 - val_loss: 0.0332\n",
            "Epoch 57/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 6.1332e-05 - val_accuracy: 1.0000 - val_loss: 0.0336\n",
            "Epoch 58/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 7.6721e-05 - val_accuracy: 1.0000 - val_loss: 0.0343\n",
            "Epoch 59/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 6.0269e-05 - val_accuracy: 1.0000 - val_loss: 0.0344\n",
            "Epoch 60/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 6.6060e-05 - val_accuracy: 1.0000 - val_loss: 0.0342\n",
            "Epoch 61/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 6.7452e-05 - val_accuracy: 1.0000 - val_loss: 0.0342\n",
            "Epoch 62/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 6.8248e-05 - val_accuracy: 1.0000 - val_loss: 0.0342\n",
            "Epoch 63/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 5.7825e-05 - val_accuracy: 1.0000 - val_loss: 0.0342\n",
            "Epoch 64/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 5.4498e-05 - val_accuracy: 1.0000 - val_loss: 0.0339\n",
            "Epoch 65/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 5.9272e-05 - val_accuracy: 1.0000 - val_loss: 0.0334\n",
            "Epoch 66/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 5.2947e-05 - val_accuracy: 1.0000 - val_loss: 0.0328\n",
            "Epoch 67/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 5.6640e-05 - val_accuracy: 1.0000 - val_loss: 0.0322\n",
            "Epoch 68/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 4.7439e-05 - val_accuracy: 1.0000 - val_loss: 0.0318\n",
            "Epoch 69/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 4.7529e-05 - val_accuracy: 1.0000 - val_loss: 0.0316\n",
            "Epoch 70/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 5.4861e-05 - val_accuracy: 1.0000 - val_loss: 0.0314\n",
            "Epoch 71/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 5.0802e-05 - val_accuracy: 1.0000 - val_loss: 0.0312\n",
            "Epoch 72/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 4.3685e-05 - val_accuracy: 1.0000 - val_loss: 0.0309\n",
            "Epoch 73/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 4.5815e-05 - val_accuracy: 1.0000 - val_loss: 0.0307\n",
            "Epoch 74/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 4.7238e-05 - val_accuracy: 1.0000 - val_loss: 0.0303\n",
            "Epoch 75/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 4.6936e-05 - val_accuracy: 1.0000 - val_loss: 0.0299\n",
            "Epoch 76/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 4.2476e-05 - val_accuracy: 1.0000 - val_loss: 0.0296\n",
            "Epoch 77/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 4.5103e-05 - val_accuracy: 1.0000 - val_loss: 0.0291\n",
            "Epoch 78/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 4.3680e-05 - val_accuracy: 1.0000 - val_loss: 0.0287\n",
            "Epoch 79/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 3.9036e-05 - val_accuracy: 1.0000 - val_loss: 0.0284\n",
            "Epoch 80/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 4.0963e-05 - val_accuracy: 1.0000 - val_loss: 0.0282\n",
            "Epoch 81/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 4.0307e-05 - val_accuracy: 1.0000 - val_loss: 0.0279\n",
            "Epoch 82/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 4.0248e-05 - val_accuracy: 1.0000 - val_loss: 0.0277\n",
            "Epoch 83/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 4.2565e-05 - val_accuracy: 1.0000 - val_loss: 0.0275\n",
            "Epoch 84/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 3.6062e-05 - val_accuracy: 1.0000 - val_loss: 0.0273\n",
            "Epoch 85/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 4.1811e-05 - val_accuracy: 1.0000 - val_loss: 0.0269\n",
            "Epoch 86/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 3.5436e-05 - val_accuracy: 1.0000 - val_loss: 0.0265\n",
            "Epoch 87/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 4.0161e-05 - val_accuracy: 1.0000 - val_loss: 0.0262\n",
            "Epoch 88/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 3.6349e-05 - val_accuracy: 1.0000 - val_loss: 0.0259\n",
            "Epoch 89/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 3.2633e-05 - val_accuracy: 1.0000 - val_loss: 0.0259\n",
            "Epoch 90/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 3.4572e-05 - val_accuracy: 1.0000 - val_loss: 0.0259\n",
            "Epoch 91/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 3.6059e-05 - val_accuracy: 1.0000 - val_loss: 0.0259\n",
            "Epoch 92/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 3.0378e-05 - val_accuracy: 1.0000 - val_loss: 0.0261\n",
            "Epoch 93/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 3.3417e-05 - val_accuracy: 1.0000 - val_loss: 0.0262\n",
            "Epoch 94/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 1.0000 - loss: 2.8947e-05 - val_accuracy: 1.0000 - val_loss: 0.0263\n",
            "Epoch 95/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 2.8906e-05 - val_accuracy: 1.0000 - val_loss: 0.0261\n",
            "Epoch 96/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 3.1214e-05 - val_accuracy: 1.0000 - val_loss: 0.0258\n",
            "Epoch 97/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 3.2229e-05 - val_accuracy: 1.0000 - val_loss: 0.0254\n",
            "Epoch 98/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 2.8774e-05 - val_accuracy: 1.0000 - val_loss: 0.0250\n",
            "Epoch 99/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 3.0539e-05 - val_accuracy: 1.0000 - val_loss: 0.0248\n",
            "Epoch 100/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 2.6299e-05 - val_accuracy: 1.0000 - val_loss: 0.0247\n",
            "Epoch 101/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 2.9007e-05 - val_accuracy: 1.0000 - val_loss: 0.0247\n",
            "Epoch 102/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 2.9329e-05 - val_accuracy: 1.0000 - val_loss: 0.0246\n",
            "Epoch 103/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 2.6629e-05 - val_accuracy: 1.0000 - val_loss: 0.0245\n",
            "Epoch 104/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 2.7548e-05 - val_accuracy: 1.0000 - val_loss: 0.0244\n",
            "Epoch 105/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 2.5601e-05 - val_accuracy: 1.0000 - val_loss: 0.0243\n",
            "Epoch 106/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 2.4930e-05 - val_accuracy: 1.0000 - val_loss: 0.0242\n",
            "Epoch 107/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 2.3257e-05 - val_accuracy: 1.0000 - val_loss: 0.0242\n",
            "Epoch 108/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 2.2024e-05 - val_accuracy: 1.0000 - val_loss: 0.0242\n",
            "Epoch 109/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 2.3047e-05 - val_accuracy: 1.0000 - val_loss: 0.0241\n",
            "Epoch 110/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 2.3592e-05 - val_accuracy: 1.0000 - val_loss: 0.0241\n",
            "Epoch 111/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 2.1360e-05 - val_accuracy: 1.0000 - val_loss: 0.0241\n",
            "Epoch 112/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 2.6756e-05 - val_accuracy: 1.0000 - val_loss: 0.0242\n",
            "Epoch 113/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 2.2523e-05 - val_accuracy: 1.0000 - val_loss: 0.0242\n",
            "Epoch 114/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 2.3769e-05 - val_accuracy: 1.0000 - val_loss: 0.0243\n",
            "Epoch 115/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 2.4445e-05 - val_accuracy: 1.0000 - val_loss: 0.0244\n",
            "Epoch 116/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 2.6025e-05 - val_accuracy: 1.0000 - val_loss: 0.0244\n",
            "Epoch 117/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 2.2380e-05 - val_accuracy: 1.0000 - val_loss: 0.0244\n",
            "Epoch 118/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 2.0006e-05 - val_accuracy: 1.0000 - val_loss: 0.0244\n",
            "Epoch 119/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 2.2223e-05 - val_accuracy: 1.0000 - val_loss: 0.0244\n",
            "Epoch 120/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 2.2632e-05 - val_accuracy: 1.0000 - val_loss: 0.0244\n",
            "Epoch 121/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 1.7102e-05 - val_accuracy: 1.0000 - val_loss: 0.0246\n",
            "Epoch 122/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 2.1257e-05 - val_accuracy: 1.0000 - val_loss: 0.0249\n",
            "Epoch 123/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 2.0905e-05 - val_accuracy: 1.0000 - val_loss: 0.0253\n",
            "Epoch 124/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 2.1010e-05 - val_accuracy: 1.0000 - val_loss: 0.0255\n",
            "Epoch 125/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 2.2774e-05 - val_accuracy: 1.0000 - val_loss: 0.0256\n",
            "Epoch 126/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 2.1129e-05 - val_accuracy: 1.0000 - val_loss: 0.0256\n",
            "Epoch 127/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 1.8450e-05 - val_accuracy: 1.0000 - val_loss: 0.0255\n",
            "Epoch 128/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 2.0802e-05 - val_accuracy: 1.0000 - val_loss: 0.0254\n",
            "Epoch 129/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 1.7680e-05 - val_accuracy: 1.0000 - val_loss: 0.0252\n",
            "Epoch 130/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 1.8434e-05 - val_accuracy: 1.0000 - val_loss: 0.0251\n",
            "Epoch 131/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 1.8243e-05 - val_accuracy: 1.0000 - val_loss: 0.0249\n",
            "Epoch 132/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 2.0199e-05 - val_accuracy: 1.0000 - val_loss: 0.0246\n",
            "Epoch 133/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 2.0680e-05 - val_accuracy: 1.0000 - val_loss: 0.0245\n",
            "Epoch 134/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 2.0735e-05 - val_accuracy: 1.0000 - val_loss: 0.0244\n",
            "Epoch 135/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 1.6929e-05 - val_accuracy: 1.0000 - val_loss: 0.0243\n",
            "Epoch 136/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 1.9223e-05 - val_accuracy: 1.0000 - val_loss: 0.0241\n",
            "Epoch 137/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 1.0000 - loss: 1.6671e-05 - val_accuracy: 1.0000 - val_loss: 0.0240\n",
            "Epoch 138/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 1.6986e-05 - val_accuracy: 1.0000 - val_loss: 0.0240\n",
            "Epoch 139/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 1.9997e-05 - val_accuracy: 1.0000 - val_loss: 0.0238\n",
            "Epoch 140/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 1.5334e-05 - val_accuracy: 1.0000 - val_loss: 0.0238\n",
            "Epoch 141/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 1.8142e-05 - val_accuracy: 1.0000 - val_loss: 0.0237\n",
            "Epoch 142/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 1.0000 - loss: 1.7365e-05 - val_accuracy: 1.0000 - val_loss: 0.0237\n",
            "Epoch 143/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 1.0000 - loss: 1.8656e-05 - val_accuracy: 1.0000 - val_loss: 0.0236\n",
            "Epoch 144/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 1.0000 - loss: 1.6289e-05 - val_accuracy: 1.0000 - val_loss: 0.0235\n",
            "Epoch 145/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 1.5943e-05 - val_accuracy: 1.0000 - val_loss: 0.0233\n",
            "Epoch 146/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 1.4444e-05 - val_accuracy: 1.0000 - val_loss: 0.0231\n",
            "Epoch 147/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 1.4565e-05 - val_accuracy: 1.0000 - val_loss: 0.0231\n",
            "Epoch 148/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 1.3992e-05 - val_accuracy: 1.0000 - val_loss: 0.0230\n",
            "Epoch 149/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 1.0000 - loss: 1.5611e-05 - val_accuracy: 1.0000 - val_loss: 0.0230\n",
            "Epoch 150/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 1.6050e-05 - val_accuracy: 1.0000 - val_loss: 0.0230\n",
            "Epoch 151/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 1.4698e-05 - val_accuracy: 1.0000 - val_loss: 0.0230\n",
            "Epoch 152/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 1.2721e-05 - val_accuracy: 1.0000 - val_loss: 0.0229\n",
            "Epoch 153/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 1.5053e-05 - val_accuracy: 1.0000 - val_loss: 0.0229\n",
            "Epoch 154/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 1.5272e-05 - val_accuracy: 1.0000 - val_loss: 0.0228\n",
            "Epoch 155/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 1.4329e-05 - val_accuracy: 1.0000 - val_loss: 0.0228\n",
            "Epoch 156/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 1.3635e-05 - val_accuracy: 1.0000 - val_loss: 0.0228\n",
            "Epoch 157/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 1.4249e-05 - val_accuracy: 1.0000 - val_loss: 0.0228\n",
            "Epoch 158/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 1.4299e-05 - val_accuracy: 1.0000 - val_loss: 0.0229\n",
            "Epoch 159/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 1.2884e-05 - val_accuracy: 1.0000 - val_loss: 0.0229\n",
            "Epoch 160/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 1.3223e-05 - val_accuracy: 1.0000 - val_loss: 0.0228\n",
            "Epoch 161/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 1.3553e-05 - val_accuracy: 1.0000 - val_loss: 0.0227\n",
            "Epoch 162/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 1.5816e-05 - val_accuracy: 1.0000 - val_loss: 0.0226\n",
            "Epoch 163/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 1.3399e-05 - val_accuracy: 1.0000 - val_loss: 0.0226\n",
            "Epoch 164/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 1.1406e-05 - val_accuracy: 1.0000 - val_loss: 0.0225\n",
            "Epoch 165/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 1.3103e-05 - val_accuracy: 1.0000 - val_loss: 0.0225\n",
            "Epoch 166/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 1.5492e-05 - val_accuracy: 1.0000 - val_loss: 0.0225\n",
            "Epoch 167/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 1.2996e-05 - val_accuracy: 1.0000 - val_loss: 0.0224\n",
            "Epoch 168/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 1.2136e-05 - val_accuracy: 1.0000 - val_loss: 0.0224\n",
            "Epoch 169/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 1.2789e-05 - val_accuracy: 1.0000 - val_loss: 0.0223\n",
            "Epoch 170/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 1.2924e-05 - val_accuracy: 1.0000 - val_loss: 0.0223\n",
            "Epoch 171/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 1.3051e-05 - val_accuracy: 1.0000 - val_loss: 0.0222\n",
            "Epoch 172/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 1.1815e-05 - val_accuracy: 1.0000 - val_loss: 0.0222\n",
            "Epoch 173/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 1.2226e-05 - val_accuracy: 1.0000 - val_loss: 0.0223\n",
            "Epoch 174/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 1.2831e-05 - val_accuracy: 1.0000 - val_loss: 0.0223\n",
            "Epoch 175/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 1.0892e-05 - val_accuracy: 1.0000 - val_loss: 0.0224\n",
            "Epoch 176/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 1.2890e-05 - val_accuracy: 1.0000 - val_loss: 0.0224\n",
            "Epoch 177/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 1.1230e-05 - val_accuracy: 1.0000 - val_loss: 0.0224\n",
            "Epoch 178/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 1.0070e-05 - val_accuracy: 1.0000 - val_loss: 0.0224\n",
            "Epoch 179/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 1.0260e-05 - val_accuracy: 1.0000 - val_loss: 0.0223\n",
            "Epoch 180/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 1.0656e-05 - val_accuracy: 1.0000 - val_loss: 0.0222\n",
            "Epoch 181/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 9.6358e-06 - val_accuracy: 1.0000 - val_loss: 0.0222\n",
            "Epoch 182/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 9.9417e-06 - val_accuracy: 1.0000 - val_loss: 0.0221\n",
            "Epoch 183/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 1.1200e-05 - val_accuracy: 1.0000 - val_loss: 0.0220\n",
            "Epoch 184/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 1.0767e-05 - val_accuracy: 1.0000 - val_loss: 0.0219\n",
            "Epoch 185/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 1.1196e-05 - val_accuracy: 1.0000 - val_loss: 0.0218\n",
            "Epoch 186/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 1.1622e-05 - val_accuracy: 1.0000 - val_loss: 0.0217\n",
            "Epoch 187/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 1.0842e-05 - val_accuracy: 1.0000 - val_loss: 0.0217\n",
            "Epoch 188/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 9.3669e-06 - val_accuracy: 1.0000 - val_loss: 0.0217\n",
            "Epoch 189/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 1.2168e-05 - val_accuracy: 1.0000 - val_loss: 0.0217\n",
            "Epoch 190/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 9.7382e-06 - val_accuracy: 1.0000 - val_loss: 0.0217\n",
            "Epoch 191/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 9.4868e-06 - val_accuracy: 1.0000 - val_loss: 0.0216\n",
            "Epoch 192/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 9.6991e-06 - val_accuracy: 1.0000 - val_loss: 0.0216\n",
            "Epoch 193/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 8.9621e-06 - val_accuracy: 1.0000 - val_loss: 0.0216\n",
            "Epoch 194/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 1.0132e-05 - val_accuracy: 1.0000 - val_loss: 0.0215\n",
            "Epoch 195/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 1.0131e-05 - val_accuracy: 1.0000 - val_loss: 0.0214\n",
            "Epoch 196/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 9.0763e-06 - val_accuracy: 1.0000 - val_loss: 0.0213\n",
            "Epoch 197/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 1.0493e-05 - val_accuracy: 1.0000 - val_loss: 0.0212\n",
            "Epoch 198/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 8.4123e-06 - val_accuracy: 1.0000 - val_loss: 0.0211\n",
            "Epoch 199/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 9.1424e-06 - val_accuracy: 1.0000 - val_loss: 0.0211\n",
            "Epoch 200/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 1.0748e-05 - val_accuracy: 1.0000 - val_loss: 0.0210\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step\n",
            "Accuracy: 0.96\n",
            "Precision: 0.965\n",
            "Recall: 0.96\n",
            "F1 Score: 0.9607619047619047\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# creating confusion matrix\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "labels = [\"Fresh\", \"Frozen\"]\n",
        "\n",
        "cm = confusion_matrix(y_val_labels_original, predicted_labels_original)\n",
        "\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
        "\n",
        "disp.plot(cmap=plt.cm.Blues)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "tSwdM3XZSlcY",
        "outputId": "dda15022-13c4-44a7-d0cf-b245980cb17d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3 class classification\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from keras.utils import to_categorical\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Convert labels to integers using LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "y_train_encoded = label_encoder.fit_transform(labels)\n",
        "y_train_categorical = to_categorical(y_train_encoded)\n",
        "\n",
        "# Split the data into training and validation sets\n",
        "x_train, x_test, y_train_cat, y_test = train_test_split(feat, y_train_categorical, test_size=0.2, random_state=42)\n",
        "x_train, x_val, y_train_cat, y_val_cat = train_test_split(x_train, y_train_cat, test_size=0.25, random_state=42)\n",
        "\n",
        "# Build the neural network model\n",
        "model = Sequential()\n",
        "# Classification with L a b values\n",
        "#model.add(Dense(64, input_dim=3, activation='relu'))\n",
        "model.add(Dense(64, input_dim=4096, activation='relu'))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Dense(16, activation='relu'))\n",
        "model.add(Dense(len(label_encoder.classes_), activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Define early stopping criteria\n",
        "#early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "\n",
        "\n",
        "checkpoint_path = \"/content/drive/MyDrive/CorrectedAll/Model_Weightes/Fresh_Frozen20_Frozen60.keras\"\n",
        "checkpoint = ModelCheckpoint(checkpoint_path, monitor='val_accuracy', save_best_only=True, mode='max')\n",
        "\n",
        "# Train the model with early stopping\n",
        "model.fit(x_train, y_train_cat, epochs=200, batch_size=32, validation_data=(x_val, y_val_cat), callbacks=[checkpoint])\n",
        "\n",
        "\n",
        "model.load_weights(\"/content/drive/MyDrive/CorrectedAll/Model_Weightes/Fresh_Frozen20_Frozen60.keras\")\n",
        "# Predict on the test data\n",
        "predicted_probabilities = model.predict(x_test)\n",
        "predicted_labels = np.argmax(predicted_probabilities, axis=1)\n",
        "predicted_labels_original = label_encoder.inverse_transform(predicted_labels)\n",
        "\n",
        "# Convert y_val_cat back to class labels\n",
        "y_val_labels = np.argmax(y_test, axis=1)\n",
        "y_val_labels_original = label_encoder.inverse_transform(y_val_labels)\n",
        "\n",
        "# Calculate and print accuracy, precision, recall, and F1 score\n",
        "accuracy = accuracy_score(y_val_labels_original, predicted_labels_original)\n",
        "precision = precision_score(y_val_labels_original, predicted_labels_original, average='weighted')\n",
        "recall = recall_score(y_val_labels_original, predicted_labels_original, average='weighted')\n",
        "f1 = f1_score(y_val_labels_original, predicted_labels_original, average='weighted')\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1 Score:\", f1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cit06KOFM5_P",
        "outputId": "e91a5d37-0634-4a08-fd2f-5ec9e0084611"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 178ms/step - accuracy: 0.2923 - loss: 1.4186 - val_accuracy: 0.4000 - val_loss: 1.0592\n",
            "Epoch 2/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.3001 - loss: 1.2712 - val_accuracy: 0.4000 - val_loss: 1.0987\n",
            "Epoch 3/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.4418 - loss: 1.1300 - val_accuracy: 0.3600 - val_loss: 1.0610\n",
            "Epoch 4/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - accuracy: 0.4252 - loss: 1.1224 - val_accuracy: 0.4400 - val_loss: 1.0628\n",
            "Epoch 5/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - accuracy: 0.3813 - loss: 1.1754 - val_accuracy: 0.4800 - val_loss: 1.0724\n",
            "Epoch 6/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.2679 - loss: 1.2037 - val_accuracy: 0.4800 - val_loss: 1.0180\n",
            "Epoch 7/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.4760 - loss: 1.0264 - val_accuracy: 0.5600 - val_loss: 0.9806\n",
            "Epoch 8/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.3304 - loss: 1.1634 - val_accuracy: 0.3600 - val_loss: 1.0692\n",
            "Epoch 9/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.4115 - loss: 1.1508 - val_accuracy: 0.4000 - val_loss: 1.0116\n",
            "Epoch 10/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.4311 - loss: 1.0959 - val_accuracy: 0.5200 - val_loss: 0.9157\n",
            "Epoch 11/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.4604 - loss: 1.0424 - val_accuracy: 0.6400 - val_loss: 0.8758\n",
            "Epoch 12/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.4917 - loss: 0.9524 - val_accuracy: 0.4400 - val_loss: 0.8746\n",
            "Epoch 13/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.4702 - loss: 1.0192 - val_accuracy: 0.6000 - val_loss: 0.8618\n",
            "Epoch 14/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.5054 - loss: 0.9468 - val_accuracy: 0.7200 - val_loss: 0.8787\n",
            "Epoch 15/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.4223 - loss: 0.9863 - val_accuracy: 0.6400 - val_loss: 0.9053\n",
            "Epoch 16/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.5103 - loss: 1.0081 - val_accuracy: 0.5200 - val_loss: 0.8906\n",
            "Epoch 17/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6774 - loss: 0.8689 - val_accuracy: 0.4400 - val_loss: 0.9117\n",
            "Epoch 18/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.5171 - loss: 0.9426 - val_accuracy: 0.4800 - val_loss: 0.8727\n",
            "Epoch 19/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.5073 - loss: 0.8677 - val_accuracy: 0.5200 - val_loss: 0.8516\n",
            "Epoch 20/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.5132 - loss: 0.8413 - val_accuracy: 0.4800 - val_loss: 0.8583\n",
            "Epoch 21/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.3978 - loss: 0.9939 - val_accuracy: 0.6400 - val_loss: 0.8586\n",
            "Epoch 22/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.5337 - loss: 0.8935 - val_accuracy: 0.7200 - val_loss: 0.8663\n",
            "Epoch 23/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.5680 - loss: 0.8536 - val_accuracy: 0.7200 - val_loss: 0.8659\n",
            "Epoch 24/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - accuracy: 0.6129 - loss: 0.7959 - val_accuracy: 0.7600 - val_loss: 0.8317\n",
            "Epoch 25/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.7165 - loss: 0.7465 - val_accuracy: 0.7600 - val_loss: 0.8011\n",
            "Epoch 26/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.5904 - loss: 0.8057 - val_accuracy: 0.8000 - val_loss: 0.7373\n",
            "Epoch 27/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.6393 - loss: 0.7432 - val_accuracy: 0.7600 - val_loss: 0.6958\n",
            "Epoch 28/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.6755 - loss: 0.7103 - val_accuracy: 0.7600 - val_loss: 0.7149\n",
            "Epoch 29/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5767 - loss: 0.7578 - val_accuracy: 0.7200 - val_loss: 0.7148\n",
            "Epoch 30/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6315 - loss: 0.8097 - val_accuracy: 0.6800 - val_loss: 0.7108\n",
            "Epoch 31/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.6539 - loss: 0.7104 - val_accuracy: 0.7600 - val_loss: 0.7171\n",
            "Epoch 32/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.6647 - loss: 0.6909 - val_accuracy: 0.8400 - val_loss: 0.6516\n",
            "Epoch 33/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5875 - loss: 0.8310 - val_accuracy: 0.7600 - val_loss: 0.7444\n",
            "Epoch 34/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.6286 - loss: 0.7898 - val_accuracy: 0.8000 - val_loss: 0.6473\n",
            "Epoch 35/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7048 - loss: 0.6452 - val_accuracy: 0.7600 - val_loss: 0.6779\n",
            "Epoch 36/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6862 - loss: 0.6292 - val_accuracy: 0.7600 - val_loss: 0.6476\n",
            "Epoch 37/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6676 - loss: 0.7190 - val_accuracy: 0.8400 - val_loss: 0.6239\n",
            "Epoch 38/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7468 - loss: 0.5901 - val_accuracy: 0.8400 - val_loss: 0.6008\n",
            "Epoch 39/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7371 - loss: 0.5797 - val_accuracy: 0.7600 - val_loss: 0.6579\n",
            "Epoch 40/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7810 - loss: 0.5052 - val_accuracy: 0.8000 - val_loss: 0.5950\n",
            "Epoch 41/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7165 - loss: 0.6035 - val_accuracy: 0.8000 - val_loss: 0.5627\n",
            "Epoch 42/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8289 - loss: 0.4922 - val_accuracy: 0.7200 - val_loss: 0.5775\n",
            "Epoch 43/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7468 - loss: 0.5372 - val_accuracy: 0.8000 - val_loss: 0.5425\n",
            "Epoch 44/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7859 - loss: 0.5368 - val_accuracy: 0.8000 - val_loss: 0.5155\n",
            "Epoch 45/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8543 - loss: 0.4352 - val_accuracy: 0.8000 - val_loss: 0.5041\n",
            "Epoch 46/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9237 - loss: 0.3891 - val_accuracy: 0.8400 - val_loss: 0.4984\n",
            "Epoch 47/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.8035 - loss: 0.5186 - val_accuracy: 0.8000 - val_loss: 0.4972\n",
            "Epoch 48/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.8299 - loss: 0.4938 - val_accuracy: 0.7600 - val_loss: 0.5080\n",
            "Epoch 49/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9130 - loss: 0.3226 - val_accuracy: 0.8000 - val_loss: 0.5139\n",
            "Epoch 50/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7468 - loss: 0.5087 - val_accuracy: 0.7600 - val_loss: 0.4982\n",
            "Epoch 51/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8680 - loss: 0.4149 - val_accuracy: 0.8000 - val_loss: 0.4709\n",
            "Epoch 52/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9081 - loss: 0.3709 - val_accuracy: 0.7600 - val_loss: 0.5011\n",
            "Epoch 53/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9198 - loss: 0.2950 - val_accuracy: 0.8000 - val_loss: 0.5182\n",
            "Epoch 54/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9042 - loss: 0.3140 - val_accuracy: 0.7600 - val_loss: 0.5044\n",
            "Epoch 55/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8583 - loss: 0.4096 - val_accuracy: 0.8000 - val_loss: 0.5069\n",
            "Epoch 56/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9022 - loss: 0.3270 - val_accuracy: 0.8000 - val_loss: 0.5662\n",
            "Epoch 57/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9061 - loss: 0.2727 - val_accuracy: 0.8000 - val_loss: 0.5329\n",
            "Epoch 58/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9316 - loss: 0.2472 - val_accuracy: 0.7600 - val_loss: 0.5676\n",
            "Epoch 59/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8759 - loss: 0.3190 - val_accuracy: 0.8000 - val_loss: 0.4987\n",
            "Epoch 60/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8866 - loss: 0.3673 - val_accuracy: 0.8000 - val_loss: 0.4171\n",
            "Epoch 61/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9755 - loss: 0.2455 - val_accuracy: 0.7600 - val_loss: 0.4723\n",
            "Epoch 62/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9022 - loss: 0.3425 - val_accuracy: 0.7600 - val_loss: 0.4746\n",
            "Epoch 63/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.9629 - loss: 0.2009 - val_accuracy: 0.8800 - val_loss: 0.3872\n",
            "Epoch 64/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9277 - loss: 0.2836 - val_accuracy: 0.8400 - val_loss: 0.3848\n",
            "Epoch 65/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9003 - loss: 0.2867 - val_accuracy: 0.8400 - val_loss: 0.4809\n",
            "Epoch 66/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9120 - loss: 0.2255 - val_accuracy: 0.7600 - val_loss: 0.5498\n",
            "Epoch 67/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9746 - loss: 0.1958 - val_accuracy: 0.8400 - val_loss: 0.4402\n",
            "Epoch 68/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9453 - loss: 0.1942 - val_accuracy: 0.8400 - val_loss: 0.4036\n",
            "Epoch 69/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9345 - loss: 0.2153 - val_accuracy: 0.8000 - val_loss: 0.3908\n",
            "Epoch 70/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9824 - loss: 0.1543 - val_accuracy: 0.8400 - val_loss: 0.3980\n",
            "Epoch 71/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9198 - loss: 0.2130 - val_accuracy: 0.8400 - val_loss: 0.4016\n",
            "Epoch 72/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9521 - loss: 0.1996 - val_accuracy: 0.8400 - val_loss: 0.3980\n",
            "Epoch 73/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9609 - loss: 0.1985 - val_accuracy: 0.8400 - val_loss: 0.4282\n",
            "Epoch 74/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9355 - loss: 0.1764 - val_accuracy: 0.8000 - val_loss: 0.4305\n",
            "Epoch 75/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9932 - loss: 0.1955 - val_accuracy: 0.8400 - val_loss: 0.4347\n",
            "Epoch 76/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9599 - loss: 0.1417 - val_accuracy: 0.8400 - val_loss: 0.4262\n",
            "Epoch 77/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 0.1267 - val_accuracy: 0.8400 - val_loss: 0.4127\n",
            "Epoch 78/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9237 - loss: 0.1991 - val_accuracy: 0.8000 - val_loss: 0.4163\n",
            "Epoch 79/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9345 - loss: 0.2333 - val_accuracy: 0.8000 - val_loss: 0.4297\n",
            "Epoch 80/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9462 - loss: 0.1756 - val_accuracy: 0.8000 - val_loss: 0.4434\n",
            "Epoch 81/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9384 - loss: 0.1362 - val_accuracy: 0.8000 - val_loss: 0.4270\n",
            "Epoch 82/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9091 - loss: 0.2054 - val_accuracy: 0.8400 - val_loss: 0.4200\n",
            "Epoch 83/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9932 - loss: 0.0828 - val_accuracy: 0.8000 - val_loss: 0.4423\n",
            "Epoch 84/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9707 - loss: 0.1790 - val_accuracy: 0.7600 - val_loss: 0.6709\n",
            "Epoch 85/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.8974 - loss: 0.2099 - val_accuracy: 0.8000 - val_loss: 0.4755\n",
            "Epoch 86/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9521 - loss: 0.1768 - val_accuracy: 0.8800 - val_loss: 0.4711\n",
            "Epoch 87/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9638 - loss: 0.1955 - val_accuracy: 0.8800 - val_loss: 0.4945\n",
            "Epoch 88/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9746 - loss: 0.2220 - val_accuracy: 0.8400 - val_loss: 0.5416\n",
            "Epoch 89/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9345 - loss: 0.1624 - val_accuracy: 0.8000 - val_loss: 0.7623\n",
            "Epoch 90/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9335 - loss: 0.1870 - val_accuracy: 0.8800 - val_loss: 0.4202\n",
            "Epoch 91/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9599 - loss: 0.1296 - val_accuracy: 0.8800 - val_loss: 0.5036\n",
            "Epoch 92/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9443 - loss: 0.2254 - val_accuracy: 0.8400 - val_loss: 0.4371\n",
            "Epoch 93/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9629 - loss: 0.1370 - val_accuracy: 0.8000 - val_loss: 0.7635\n",
            "Epoch 94/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9707 - loss: 0.1275 - val_accuracy: 0.8000 - val_loss: 0.9246\n",
            "Epoch 95/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9560 - loss: 0.1344 - val_accuracy: 0.8400 - val_loss: 0.4178\n",
            "Epoch 96/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9716 - loss: 0.1447 - val_accuracy: 0.8800 - val_loss: 0.5606\n",
            "Epoch 97/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8768 - loss: 0.3233 - val_accuracy: 0.8800 - val_loss: 0.3983\n",
            "Epoch 98/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9599 - loss: 0.1741 - val_accuracy: 0.8000 - val_loss: 0.5541\n",
            "Epoch 99/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9072 - loss: 0.1878 - val_accuracy: 0.8400 - val_loss: 0.3927\n",
            "Epoch 100/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 0.1098 - val_accuracy: 0.8800 - val_loss: 0.3921\n",
            "Epoch 101/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.9892 - loss: 0.1350 - val_accuracy: 0.9200 - val_loss: 0.4118\n",
            "Epoch 102/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9814 - loss: 0.1389 - val_accuracy: 0.9200 - val_loss: 0.4066\n",
            "Epoch 103/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9746 - loss: 0.1119 - val_accuracy: 0.9200 - val_loss: 0.3898\n",
            "Epoch 104/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9638 - loss: 0.1433 - val_accuracy: 0.9200 - val_loss: 0.4180\n",
            "Epoch 105/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9707 - loss: 0.1155 - val_accuracy: 0.9200 - val_loss: 0.4094\n",
            "Epoch 106/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9638 - loss: 0.1245 - val_accuracy: 0.9200 - val_loss: 0.3786\n",
            "Epoch 107/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 0.1084 - val_accuracy: 0.8800 - val_loss: 0.4003\n",
            "Epoch 108/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 0.1206 - val_accuracy: 0.8000 - val_loss: 0.4691\n",
            "Epoch 109/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9932 - loss: 0.0943 - val_accuracy: 0.8000 - val_loss: 0.5098\n",
            "Epoch 110/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9707 - loss: 0.1599 - val_accuracy: 0.8000 - val_loss: 0.4636\n",
            "Epoch 111/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9892 - loss: 0.1013 - val_accuracy: 0.8400 - val_loss: 0.4340\n",
            "Epoch 112/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9785 - loss: 0.1338 - val_accuracy: 0.8800 - val_loss: 0.4220\n",
            "Epoch 113/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9932 - loss: 0.0892 - val_accuracy: 0.8800 - val_loss: 0.4199\n",
            "Epoch 114/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9707 - loss: 0.1379 - val_accuracy: 0.8800 - val_loss: 0.4183\n",
            "Epoch 115/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 0.0678 - val_accuracy: 0.8800 - val_loss: 0.4260\n",
            "Epoch 116/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9599 - loss: 0.1854 - val_accuracy: 0.8800 - val_loss: 0.4297\n",
            "Epoch 117/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9345 - loss: 0.1282 - val_accuracy: 0.8400 - val_loss: 0.4467\n",
            "Epoch 118/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 0.0693 - val_accuracy: 0.8800 - val_loss: 0.5040\n",
            "Epoch 119/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9892 - loss: 0.0938 - val_accuracy: 0.8800 - val_loss: 0.4993\n",
            "Epoch 120/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 0.0421 - val_accuracy: 0.8400 - val_loss: 0.4445\n",
            "Epoch 121/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9814 - loss: 0.0801 - val_accuracy: 0.8000 - val_loss: 0.4453\n",
            "Epoch 122/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9716 - loss: 0.0888 - val_accuracy: 0.8400 - val_loss: 0.4378\n",
            "Epoch 123/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9824 - loss: 0.1112 - val_accuracy: 0.8400 - val_loss: 0.4504\n",
            "Epoch 124/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9892 - loss: 0.0628 - val_accuracy: 0.8800 - val_loss: 0.5101\n",
            "Epoch 125/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 0.1079 - val_accuracy: 0.8400 - val_loss: 0.5984\n",
            "Epoch 126/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 0.0743 - val_accuracy: 0.8400 - val_loss: 0.6410\n",
            "Epoch 127/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.9814 - loss: 0.0688 - val_accuracy: 0.8400 - val_loss: 0.5844\n",
            "Epoch 128/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9814 - loss: 0.0952 - val_accuracy: 0.8800 - val_loss: 0.4837\n",
            "Epoch 129/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9677 - loss: 0.1107 - val_accuracy: 0.8400 - val_loss: 0.4626\n",
            "Epoch 130/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 0.0442 - val_accuracy: 0.8800 - val_loss: 0.4686\n",
            "Epoch 131/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 0.0334 - val_accuracy: 0.8400 - val_loss: 0.4890\n",
            "Epoch 132/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9599 - loss: 0.0981 - val_accuracy: 0.8800 - val_loss: 0.4717\n",
            "Epoch 133/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9892 - loss: 0.0994 - val_accuracy: 0.8800 - val_loss: 0.4698\n",
            "Epoch 134/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 0.0398 - val_accuracy: 0.8800 - val_loss: 0.4787\n",
            "Epoch 135/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 0.0312 - val_accuracy: 0.8800 - val_loss: 0.5121\n",
            "Epoch 136/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9824 - loss: 0.1252 - val_accuracy: 0.8800 - val_loss: 0.4832\n",
            "Epoch 137/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9932 - loss: 0.0497 - val_accuracy: 0.8800 - val_loss: 0.4999\n",
            "Epoch 138/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9707 - loss: 0.0933 - val_accuracy: 0.8400 - val_loss: 0.5833\n",
            "Epoch 139/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9521 - loss: 0.1436 - val_accuracy: 0.8400 - val_loss: 0.5571\n",
            "Epoch 140/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9892 - loss: 0.0532 - val_accuracy: 0.8800 - val_loss: 0.5093\n",
            "Epoch 141/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 0.0523 - val_accuracy: 0.8800 - val_loss: 0.4356\n",
            "Epoch 142/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 0.0320 - val_accuracy: 0.8800 - val_loss: 0.4170\n",
            "Epoch 143/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9414 - loss: 0.1244 - val_accuracy: 0.8800 - val_loss: 0.4301\n",
            "Epoch 144/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0422 - val_accuracy: 0.8400 - val_loss: 0.4767\n",
            "Epoch 145/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9707 - loss: 0.0772 - val_accuracy: 0.8400 - val_loss: 0.5439\n",
            "Epoch 146/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9932 - loss: 0.0411 - val_accuracy: 0.8400 - val_loss: 0.6131\n",
            "Epoch 147/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9335 - loss: 0.1362 - val_accuracy: 0.8400 - val_loss: 0.6252\n",
            "Epoch 148/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9785 - loss: 0.1050 - val_accuracy: 0.8400 - val_loss: 0.6349\n",
            "Epoch 149/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0472 - val_accuracy: 0.8400 - val_loss: 0.6222\n",
            "Epoch 150/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9521 - loss: 0.1477 - val_accuracy: 0.8800 - val_loss: 0.5364\n",
            "Epoch 151/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 0.0404 - val_accuracy: 0.8400 - val_loss: 0.5363\n",
            "Epoch 152/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9707 - loss: 0.1097 - val_accuracy: 0.8400 - val_loss: 0.5571\n",
            "Epoch 153/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9785 - loss: 0.0645 - val_accuracy: 0.8000 - val_loss: 0.5187\n",
            "Epoch 154/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 0.0569 - val_accuracy: 0.8800 - val_loss: 0.5431\n",
            "Epoch 155/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9814 - loss: 0.0505 - val_accuracy: 0.8400 - val_loss: 0.6305\n",
            "Epoch 156/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9814 - loss: 0.0705 - val_accuracy: 0.8400 - val_loss: 0.6807\n",
            "Epoch 157/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 0.0380 - val_accuracy: 0.8400 - val_loss: 0.7003\n",
            "Epoch 158/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9932 - loss: 0.0482 - val_accuracy: 0.8400 - val_loss: 0.6623\n",
            "Epoch 159/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9892 - loss: 0.0765 - val_accuracy: 0.8400 - val_loss: 0.5974\n",
            "Epoch 160/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 0.0226 - val_accuracy: 0.8400 - val_loss: 0.5538\n",
            "Epoch 161/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 0.0270 - val_accuracy: 0.8400 - val_loss: 0.5339\n",
            "Epoch 162/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9785 - loss: 0.0868 - val_accuracy: 0.8400 - val_loss: 0.5341\n",
            "Epoch 163/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9814 - loss: 0.0630 - val_accuracy: 0.8400 - val_loss: 0.5410\n",
            "Epoch 164/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0357 - val_accuracy: 0.8400 - val_loss: 0.5401\n",
            "Epoch 165/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9932 - loss: 0.0333 - val_accuracy: 0.8400 - val_loss: 0.5578\n",
            "Epoch 166/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9629 - loss: 0.1073 - val_accuracy: 0.8400 - val_loss: 0.6586\n",
            "Epoch 167/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9521 - loss: 0.1081 - val_accuracy: 0.8400 - val_loss: 0.7062\n",
            "Epoch 168/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9629 - loss: 0.0974 - val_accuracy: 0.8400 - val_loss: 0.7513\n",
            "Epoch 169/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9599 - loss: 0.1159 - val_accuracy: 0.8400 - val_loss: 0.7902\n",
            "Epoch 170/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 0.0204 - val_accuracy: 0.8400 - val_loss: 0.8179\n",
            "Epoch 171/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 0.0418 - val_accuracy: 0.8400 - val_loss: 0.8787\n",
            "Epoch 172/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0405 - val_accuracy: 0.8400 - val_loss: 0.7901\n",
            "Epoch 173/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0044 - val_accuracy: 0.8400 - val_loss: 0.6726\n",
            "Epoch 174/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9892 - loss: 0.0451 - val_accuracy: 0.8800 - val_loss: 0.6069\n",
            "Epoch 175/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9892 - loss: 0.0446 - val_accuracy: 0.8800 - val_loss: 0.5831\n",
            "Epoch 176/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0262 - val_accuracy: 0.8400 - val_loss: 0.5730\n",
            "Epoch 177/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 0.0400 - val_accuracy: 0.8400 - val_loss: 0.5700\n",
            "Epoch 178/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0289 - val_accuracy: 0.8400 - val_loss: 0.5704\n",
            "Epoch 179/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9707 - loss: 0.0754 - val_accuracy: 0.8800 - val_loss: 0.5820\n",
            "Epoch 180/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0243 - val_accuracy: 0.8800 - val_loss: 0.6041\n",
            "Epoch 181/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0204 - val_accuracy: 0.8800 - val_loss: 0.6274\n",
            "Epoch 182/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9892 - loss: 0.0501 - val_accuracy: 0.8400 - val_loss: 0.6974\n",
            "Epoch 183/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9892 - loss: 0.0683 - val_accuracy: 0.8400 - val_loss: 0.7548\n",
            "Epoch 184/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 0.0254 - val_accuracy: 0.8400 - val_loss: 0.7532\n",
            "Epoch 185/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9814 - loss: 0.1153 - val_accuracy: 0.8800 - val_loss: 0.7259\n",
            "Epoch 186/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 0.0467 - val_accuracy: 0.8800 - val_loss: 0.6894\n",
            "Epoch 187/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 0.0223 - val_accuracy: 0.8800 - val_loss: 0.6596\n",
            "Epoch 188/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 0.0192 - val_accuracy: 0.8400 - val_loss: 0.6449\n",
            "Epoch 189/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9560 - loss: 0.1282 - val_accuracy: 0.8400 - val_loss: 0.6321\n",
            "Epoch 190/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0338 - val_accuracy: 0.8400 - val_loss: 0.6356\n",
            "Epoch 191/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 0.0273 - val_accuracy: 0.8400 - val_loss: 0.6307\n",
            "Epoch 192/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9599 - loss: 0.0935 - val_accuracy: 0.8800 - val_loss: 0.5667\n",
            "Epoch 193/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9892 - loss: 0.0469 - val_accuracy: 0.8400 - val_loss: 0.5719\n",
            "Epoch 194/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9892 - loss: 0.0664 - val_accuracy: 0.8400 - val_loss: 0.5942\n",
            "Epoch 195/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 0.0259 - val_accuracy: 0.8800 - val_loss: 0.6771\n",
            "Epoch 196/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9892 - loss: 0.0453 - val_accuracy: 0.8400 - val_loss: 0.7950\n",
            "Epoch 197/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 0.0246 - val_accuracy: 0.8400 - val_loss: 0.8015\n",
            "Epoch 198/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9892 - loss: 0.0871 - val_accuracy: 0.8400 - val_loss: 0.8805\n",
            "Epoch 199/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0337 - val_accuracy: 0.8400 - val_loss: 1.1261\n",
            "Epoch 200/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 0.0320 - val_accuracy: 0.7600 - val_loss: 1.3350\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:6 out of the last 128 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7c993420be20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n",
            "Accuracy: 0.88\n",
            "Precision: 0.91\n",
            "Recall: 0.88\n",
            "F1 Score: 0.8747252747252747\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict on the test data\n",
        "model.load_weights(\"/content/drive/MyDrive/CorrectedAll/3Class_best_model_with_testdata84.h5\")\n",
        "\n",
        "predicted_probabilities = model.predict(x_test)\n",
        "predicted_labels = np.argmax(predicted_probabilities, axis=1)\n",
        "predicted_labels_original = label_encoder.inverse_transform(predicted_labels)\n",
        "\n",
        "# Convert y_val_cat back to class labels\n",
        "y_val_labels = np.argmax(y_test, axis=1)\n",
        "y_val_labels_original = label_encoder.inverse_transform(y_val_labels)\n",
        "\n",
        "# Calculate and print accuracy, precision, recall, and F1 score\n",
        "accuracy = accuracy_score(y_val_labels_original, predicted_labels_original)\n",
        "precision = precision_score(y_val_labels_original, predicted_labels_original, average='weighted')\n",
        "recall = recall_score(y_val_labels_original, predicted_labels_original, average='weighted')\n",
        "f1 = f1_score(y_val_labels_original, predicted_labels_original, average='weighted')\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1 Score:\", f1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "twwoU7REPUUM",
        "outputId": "a9abbf8c-77d1-4adc-f746-45417152475d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 24ms/step\n",
            "Accuracy: 0.84\n",
            "Precision: 0.84\n",
            "Recall: 0.84\n",
            "F1 Score: 0.84\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# creating confusion matrix\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "labels = [\"Fresh\", \"Frozen_20\", \"Frozen_60\"]\n",
        "\n",
        "cm = confusion_matrix(y_val_labels_original, predicted_labels_original)\n",
        "\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
        "\n",
        "disp.plot(cmap=plt.cm.Blues)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "1JUqu7mqRNVn",
        "outputId": "d56017a9-f256-444d-82b9-0315d2b01202"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Classification using L a b values**\n",
        "\n",
        "\n",
        "1.   Fresh vs Frozen classification\n",
        "2.   Right vs Left classification\n",
        "3.   3 class classification\n",
        "\n",
        "Same models are used for classification with L a b values. First layer adjusted for 3 features \"model.add(Dense(64, input_dim=3, activation='relu'))\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "81216jASZWSU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_excel('/content/drive/MyDrive/FishQuality_images/LensEyeData Analysis.xlsx', sheet_name='FreshF20F60')\n",
        "display(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "tkqbDjkMP7PN",
        "outputId": "4c077f38-3f0f-4aa8-d882-899678b40f36"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                Unnamed: 0  User area  Avg L  Avg a*  Avg b*  DeltaS  DeltaI\n",
              "0      F20-102 RİGHT FRESH     193.14  61.45   23.44   16.66    9.86   30.04\n",
              "1     F20-103 Left FRESH\\t     188.98  60.74   23.06   16.14   10.86   34.29\n",
              "2     F20-202 Left FRESH\\t     224.40  61.21   22.18   15.29   10.16   31.15\n",
              "3      F20-203 RİGHT FRESH     218.85  63.06   20.89   14.68     NaN     NaN\n",
              "4      F20-302 RİGHT FRESH     201.59  60.15   22.57   15.06    8.93   25.23\n",
              "..                     ...        ...    ...     ...     ...     ...     ...\n",
              "123  F60T3-602 Right THIRD     183.13  55.54   20.66   13.75    9.92   31.44\n",
              "124   F60T3-702 Left THIRD     198.31  52.54   23.07   14.15    9.50   28.36\n",
              "125  F60T3-702 Right THIRD     203.91  54.11   21.05   13.69   11.12   35.28\n",
              "126   F60T3-802 Left THIRD     209.38  56.50   24.76   15.56    9.40   27.85\n",
              "127  F60T3-802 Right THIRD     211.45  55.22   23.65   14.00    9.66   29.84\n",
              "\n",
              "[128 rows x 7 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-883e5c54-68aa-413c-989d-d939fa0bda18\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>User area</th>\n",
              "      <th>Avg L</th>\n",
              "      <th>Avg a*</th>\n",
              "      <th>Avg b*</th>\n",
              "      <th>DeltaS</th>\n",
              "      <th>DeltaI</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>F20-102 RİGHT FRESH</td>\n",
              "      <td>193.14</td>\n",
              "      <td>61.45</td>\n",
              "      <td>23.44</td>\n",
              "      <td>16.66</td>\n",
              "      <td>9.86</td>\n",
              "      <td>30.04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>F20-103 Left FRESH\\t</td>\n",
              "      <td>188.98</td>\n",
              "      <td>60.74</td>\n",
              "      <td>23.06</td>\n",
              "      <td>16.14</td>\n",
              "      <td>10.86</td>\n",
              "      <td>34.29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>F20-202 Left FRESH\\t</td>\n",
              "      <td>224.40</td>\n",
              "      <td>61.21</td>\n",
              "      <td>22.18</td>\n",
              "      <td>15.29</td>\n",
              "      <td>10.16</td>\n",
              "      <td>31.15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>F20-203 RİGHT FRESH</td>\n",
              "      <td>218.85</td>\n",
              "      <td>63.06</td>\n",
              "      <td>20.89</td>\n",
              "      <td>14.68</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>F20-302 RİGHT FRESH</td>\n",
              "      <td>201.59</td>\n",
              "      <td>60.15</td>\n",
              "      <td>22.57</td>\n",
              "      <td>15.06</td>\n",
              "      <td>8.93</td>\n",
              "      <td>25.23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>123</th>\n",
              "      <td>F60T3-602 Right THIRD</td>\n",
              "      <td>183.13</td>\n",
              "      <td>55.54</td>\n",
              "      <td>20.66</td>\n",
              "      <td>13.75</td>\n",
              "      <td>9.92</td>\n",
              "      <td>31.44</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>124</th>\n",
              "      <td>F60T3-702 Left THIRD</td>\n",
              "      <td>198.31</td>\n",
              "      <td>52.54</td>\n",
              "      <td>23.07</td>\n",
              "      <td>14.15</td>\n",
              "      <td>9.50</td>\n",
              "      <td>28.36</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>125</th>\n",
              "      <td>F60T3-702 Right THIRD</td>\n",
              "      <td>203.91</td>\n",
              "      <td>54.11</td>\n",
              "      <td>21.05</td>\n",
              "      <td>13.69</td>\n",
              "      <td>11.12</td>\n",
              "      <td>35.28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>126</th>\n",
              "      <td>F60T3-802 Left THIRD</td>\n",
              "      <td>209.38</td>\n",
              "      <td>56.50</td>\n",
              "      <td>24.76</td>\n",
              "      <td>15.56</td>\n",
              "      <td>9.40</td>\n",
              "      <td>27.85</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>127</th>\n",
              "      <td>F60T3-802 Right THIRD</td>\n",
              "      <td>211.45</td>\n",
              "      <td>55.22</td>\n",
              "      <td>23.65</td>\n",
              "      <td>14.00</td>\n",
              "      <td>9.66</td>\n",
              "      <td>29.84</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>128 rows × 7 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-883e5c54-68aa-413c-989d-d939fa0bda18')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-883e5c54-68aa-413c-989d-d939fa0bda18 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-883e5c54-68aa-413c-989d-d939fa0bda18');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c93bf011-979e-4b7e-9c30-45c857afef8f\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c93bf011-979e-4b7e-9c30-45c857afef8f')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c93bf011-979e-4b7e-9c30-45c857afef8f button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_52b31847-21ed-40e1-947a-3b63501e814d\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_52b31847-21ed-40e1-947a-3b63501e814d button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 128,\n  \"fields\": [\n    {\n      \"column\": \"Unnamed: 0\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 128,\n        \"samples\": [\n          \"F20T3-402 Right THIRD\",\n          \"F20T2-502 Left SECOND\",\n          \"F20T1-202 Right FIRST\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"User area\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 17.938683003100156,\n        \"min\": 178.37,\n        \"max\": 249.09,\n        \"num_unique_values\": 122,\n        \"samples\": [\n          223.02,\n          182.57,\n          191.17\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Avg L\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3.1005067392908776,\n        \"min\": 49.82,\n        \"max\": 63.97,\n        \"num_unique_values\": 121,\n        \"samples\": [\n          49.82,\n          57.31,\n          60.15\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Avg a*\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.037811897362525,\n        \"min\": 16.32,\n        \"max\": 28.31,\n        \"num_unique_values\": 114,\n        \"samples\": [\n          20.55,\n          22.57,\n          20.18\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Avg b*\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.8781300612535134,\n        \"min\": 10.44,\n        \"max\": 18.68,\n        \"num_unique_values\": 113,\n        \"samples\": [\n          12.03,\n          15.06,\n          15.69\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"DeltaS\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.2771950400025776,\n        \"min\": 8.36,\n        \"max\": 17.57,\n        \"num_unique_values\": 96,\n        \"samples\": [\n          9.34,\n          10.09,\n          8.77\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"DeltaI\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 20.764118807338445,\n        \"min\": 23.36,\n        \"max\": 254.27,\n        \"num_unique_values\": 118,\n        \"samples\": [\n          24.43,\n          26.9,\n          29.15\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# unmeasured examples that are not included in the picture examples\n",
        "df = df[df['Unnamed: 0'] != 'F60T1-302 Left FIRST']\n",
        "df = df[df['Unnamed: 0'] != 'F60T1-302 Right FIRST']\n",
        "df = df[df['Unnamed: 0'] != 'F60T1-802 Right FIRST']\n",
        "\n",
        "#examples in the images with missing L value\n",
        "df = df[df['Unnamed: 0'] != 'F20T1-102 Left FIRST']\n",
        "df = df[df['Unnamed: 0'] != 'F20T3-202 Left THIRD']"
      ],
      "metadata": {
        "id": "j-mKXuwgZYEL"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1- Fresh vs Frozen classification for L a b\n",
        "search_string = 'fresh'\n",
        "Fresh_df = df[df['Unnamed: 0'].str.contains(search_string, case=False, na=False)]\n",
        "\n",
        "Frozen_df = df.drop(Fresh_df.index)\n",
        "\n",
        "selected_columns = ['Avg L', 'Avg a*', 'Avg b*']\n",
        "Fresh_array = Fresh_df[selected_columns].to_numpy()\n",
        "Frozen_array = Frozen_df[selected_columns].to_numpy()\n",
        "\n",
        "print(Fresh_array.shape)\n",
        "print(Frozen_array.shape)\n",
        "\n",
        "X = np.vstack((Fresh_array, Frozen_array))\n",
        "label1 = np.zeros(len(Fresh_array))\n",
        "label2 = np.ones(len(Frozen_array))\n",
        "Y = np.hstack((label1, label2))\n",
        "X = X.astype(np.float32)"
      ],
      "metadata": {
        "id": "TGlU311nTLoe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32ecc776-ebf0-455e-fcb1-4585d70178e5"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(32, 3)\n",
            "(91, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2- Right vs Left classification for L a b\n",
        "search_string = 'ight'\n",
        "Right_df = df[df['Unnamed: 0'].str.contains(search_string, case=False, na=False)]\n",
        "\n",
        "Left_df = df.drop(Right_df.index)\n",
        "\n",
        "selected_columns = ['Avg L', 'Avg a*', 'Avg b*']\n",
        "Right_array = Right_df[selected_columns].to_numpy()\n",
        "Left_array = Left_df[selected_columns].to_numpy()\n",
        "\n",
        "print(Right_array.shape)\n",
        "print(Left_array.shape)\n",
        "X = np.vstack((Right_array, Left_array))\n",
        "label1 = np.zeros(len(Right_array))\n",
        "label2 = np.ones(len(Left_array))\n",
        "Y = np.hstack((label1, label2))\n",
        "X = X.astype(np.float32)"
      ],
      "metadata": {
        "id": "L1CVUMWCTWFU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "adde8fd8-f009-45df-ece5-84d4951a2cf5"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(62, 3)\n",
            "(61, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3 class classification with L a b values\n",
        "search_string = 'F20'\n",
        "F20_df = Frozen_df[Frozen_df['Unnamed: 0'].str.contains(search_string, case=False, na=False)]\n",
        "F60_df = Frozen_df.drop(F20_df.index)\n",
        "F20_array = F20_df[selected_columns].to_numpy()\n",
        "F60_array = F60_df[selected_columns].to_numpy()\n",
        "X = np.vstack((Fresh_array, F20_array, F60_array))\n",
        "label1 = np.zeros(len(Fresh_array))\n",
        "label2 = np.ones(len(F20_array))\n",
        "label3 = np.full(len(F60_array), 2)\n",
        "Y = np.hstack((label1, label2, label3))\n",
        "X = X.astype(np.float32)"
      ],
      "metadata": {
        "id": "BGJ36EFlUDxK"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2 class classification with L a b values\n",
        "label_encoder = LabelEncoder()\n",
        "y_train_encoded = label_encoder.fit_transform(Y)\n",
        "y_train_categorical = to_categorical(y_train_encoded)\n",
        "\n",
        "# Split the data into training and validation sets\n",
        "x_train, x_test, y_train_cat, y_test = train_test_split(X, y_train_categorical, test_size=0.2, random_state=42)\n",
        "x_train, x_val, y_train_cat, y_val_cat = train_test_split(x_train, y_train_cat, test_size=0.25, random_state=42)\n",
        "\n",
        "\n",
        "# Build the neural network model\n",
        "model = Sequential()\n",
        "# pca 3 ile yapılınca alınan sonuç için\n",
        "model.add(Dense(64, input_dim=3, activation='relu'))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(16, activation='relu'))\n",
        "model.add(Dense(len(label_encoder.classes_), activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Define early stopping criteria\n",
        "#early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "checkpoint_path = \"/content/drive/MyDrive/CorrectedAll/Model_Weightes/Right_Left_L_a_b.keras\"\n",
        "checkpoint = ModelCheckpoint(checkpoint_path, monitor='val_accuracy', save_best_only=True, mode='max')\n",
        "\n",
        "# Train the model with early stopping\n",
        "model.fit(x_train, y_train_cat, epochs=200, batch_size=32, validation_data=(x_val, y_val_cat), callbacks=[checkpoint])\n",
        "\n",
        "model.load_weights(\"/content/drive/MyDrive/CorrectedAll/Model_Weightes/Right_Left_L_a_b.keras\")\n",
        "# Predict on the test data\n",
        "predicted_probabilities = model.predict(x_test)\n",
        "predicted_labels = np.argmax(predicted_probabilities, axis=1)\n",
        "predicted_labels_original = label_encoder.inverse_transform(predicted_labels)\n",
        "\n",
        "# Convert y_val_cat back to class labels\n",
        "y_val_labels = np.argmax(y_test, axis=1)\n",
        "y_val_labels_original = label_encoder.inverse_transform(y_val_labels)\n",
        "\n",
        "# Calculate and print accuracy, precision, recall, and F1 score\n",
        "accuracy = accuracy_score(y_val_labels_original, predicted_labels_original)\n",
        "precision = precision_score(y_val_labels_original, predicted_labels_original, average='weighted')\n",
        "recall = recall_score(y_val_labels_original, predicted_labels_original, average='weighted')\n",
        "f1 = f1_score(y_val_labels_original, predicted_labels_original, average='weighted')\n",
        "\n",
        "# Initialize a Keras AUC metric\n",
        "auc_metric = tf.keras.metrics.AUC(name='auc', multi_label=True)\n",
        "\n",
        "# Update the AUC metric with true labels and predicted probabilities\n",
        "auc_metric.update_state(y_test, predicted_probabilities)\n",
        "auc = auc_metric.result().numpy()\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1 Score:\", f1)\n",
        "print(\"AUC (Keras):\", auc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hzYM1YtTRnzp",
        "outputId": "4ebf207b-4329-4728-a827-83b3106e2a93"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 143ms/step - accuracy: 0.4526 - loss: 1.8751 - val_accuracy: 0.5600 - val_loss: 1.0748\n",
            "Epoch 2/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4565 - loss: 1.2804 - val_accuracy: 0.5600 - val_loss: 0.7965\n",
            "Epoch 3/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4643 - loss: 0.8954 - val_accuracy: 0.5200 - val_loss: 0.6930\n",
            "Epoch 4/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5112 - loss: 0.7071 - val_accuracy: 0.4400 - val_loss: 0.8226\n",
            "Epoch 5/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5513 - loss: 0.7327 - val_accuracy: 0.4400 - val_loss: 0.8408\n",
            "Epoch 6/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.5474 - loss: 0.7392 - val_accuracy: 0.4400 - val_loss: 0.7855\n",
            "Epoch 7/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5943 - loss: 0.6678 - val_accuracy: 0.4400 - val_loss: 0.7069\n",
            "Epoch 8/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.5259 - loss: 0.6903 - val_accuracy: 0.5600 - val_loss: 0.6889\n",
            "Epoch 9/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.4487 - loss: 0.6944 - val_accuracy: 0.5600 - val_loss: 0.6851\n",
            "Epoch 10/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.4868 - loss: 0.6991 - val_accuracy: 0.6800 - val_loss: 0.6858\n",
            "Epoch 11/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4858 - loss: 0.7001 - val_accuracy: 0.4400 - val_loss: 0.6947\n",
            "Epoch 12/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5630 - loss: 0.6872 - val_accuracy: 0.4400 - val_loss: 0.7017\n",
            "Epoch 13/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5679 - loss: 0.6834 - val_accuracy: 0.4400 - val_loss: 0.7046\n",
            "Epoch 14/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5484 - loss: 0.6836 - val_accuracy: 0.4400 - val_loss: 0.7040\n",
            "Epoch 15/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5327 - loss: 0.6882 - val_accuracy: 0.4400 - val_loss: 0.7017\n",
            "Epoch 16/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5142 - loss: 0.6897 - val_accuracy: 0.4400 - val_loss: 0.6979\n",
            "Epoch 17/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5562 - loss: 0.6866 - val_accuracy: 0.4400 - val_loss: 0.7005\n",
            "Epoch 18/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5435 - loss: 0.6885 - val_accuracy: 0.4800 - val_loss: 0.6973\n",
            "Epoch 19/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5679 - loss: 0.6891 - val_accuracy: 0.4400 - val_loss: 0.6983\n",
            "Epoch 20/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.5484 - loss: 0.6852 - val_accuracy: 0.4400 - val_loss: 0.6963\n",
            "Epoch 21/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5552 - loss: 0.6882 - val_accuracy: 0.5200 - val_loss: 0.6926\n",
            "Epoch 22/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5220 - loss: 0.6898 - val_accuracy: 0.6000 - val_loss: 0.6919\n",
            "Epoch 23/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.4986 - loss: 0.6910 - val_accuracy: 0.4800 - val_loss: 0.6943\n",
            "Epoch 24/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5142 - loss: 0.6900 - val_accuracy: 0.4400 - val_loss: 0.7020\n",
            "Epoch 25/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5708 - loss: 0.6830 - val_accuracy: 0.4400 - val_loss: 0.7155\n",
            "Epoch 26/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5787 - loss: 0.6822 - val_accuracy: 0.4400 - val_loss: 0.7204\n",
            "Epoch 27/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5591 - loss: 0.6859 - val_accuracy: 0.4400 - val_loss: 0.7175\n",
            "Epoch 28/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5435 - loss: 0.6902 - val_accuracy: 0.4400 - val_loss: 0.7166\n",
            "Epoch 29/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5630 - loss: 0.6848 - val_accuracy: 0.4400 - val_loss: 0.7153\n",
            "Epoch 30/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5435 - loss: 0.6896 - val_accuracy: 0.4400 - val_loss: 0.7134\n",
            "Epoch 31/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5630 - loss: 0.6844 - val_accuracy: 0.4400 - val_loss: 0.7123\n",
            "Epoch 32/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.5240 - loss: 0.6940 - val_accuracy: 0.4400 - val_loss: 0.7119\n",
            "Epoch 33/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.5513 - loss: 0.6859 - val_accuracy: 0.4400 - val_loss: 0.7145\n",
            "Epoch 34/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.5748 - loss: 0.6816 - val_accuracy: 0.4400 - val_loss: 0.7124\n",
            "Epoch 35/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.5279 - loss: 0.6934 - val_accuracy: 0.4400 - val_loss: 0.7009\n",
            "Epoch 36/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5093 - loss: 0.6904 - val_accuracy: 0.4400 - val_loss: 0.6969\n",
            "Epoch 37/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5288 - loss: 0.6870 - val_accuracy: 0.4400 - val_loss: 0.7038\n",
            "Epoch 38/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.5474 - loss: 0.6869 - val_accuracy: 0.4400 - val_loss: 0.7126\n",
            "Epoch 39/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5630 - loss: 0.6836 - val_accuracy: 0.4400 - val_loss: 0.7137\n",
            "Epoch 40/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.5279 - loss: 0.6923 - val_accuracy: 0.4400 - val_loss: 0.7068\n",
            "Epoch 41/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.5591 - loss: 0.6840 - val_accuracy: 0.4400 - val_loss: 0.7061\n",
            "Epoch 42/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.5318 - loss: 0.6899 - val_accuracy: 0.4400 - val_loss: 0.7110\n",
            "Epoch 43/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5474 - loss: 0.6874 - val_accuracy: 0.4400 - val_loss: 0.7164\n",
            "Epoch 44/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5904 - loss: 0.6764 - val_accuracy: 0.4400 - val_loss: 0.7126\n",
            "Epoch 45/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.5123 - loss: 0.6979 - val_accuracy: 0.4400 - val_loss: 0.7002\n",
            "Epoch 46/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5406 - loss: 0.6868 - val_accuracy: 0.4400 - val_loss: 0.7020\n",
            "Epoch 47/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5288 - loss: 0.6859 - val_accuracy: 0.4400 - val_loss: 0.7061\n",
            "Epoch 48/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.5591 - loss: 0.6858 - val_accuracy: 0.4400 - val_loss: 0.7140\n",
            "Epoch 49/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.5748 - loss: 0.6816 - val_accuracy: 0.4400 - val_loss: 0.7158\n",
            "Epoch 50/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5279 - loss: 0.6942 - val_accuracy: 0.4400 - val_loss: 0.7078\n",
            "Epoch 51/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5591 - loss: 0.6838 - val_accuracy: 0.4400 - val_loss: 0.7108\n",
            "Epoch 52/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5865 - loss: 0.6809 - val_accuracy: 0.4400 - val_loss: 0.7113\n",
            "Epoch 53/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.5552 - loss: 0.6857 - val_accuracy: 0.4400 - val_loss: 0.7061\n",
            "Epoch 54/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.5552 - loss: 0.6852 - val_accuracy: 0.4400 - val_loss: 0.7073\n",
            "Epoch 55/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5474 - loss: 0.6865 - val_accuracy: 0.4400 - val_loss: 0.7109\n",
            "Epoch 56/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.5904 - loss: 0.6780 - val_accuracy: 0.4400 - val_loss: 0.7076\n",
            "Epoch 57/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5591 - loss: 0.6836 - val_accuracy: 0.5600 - val_loss: 0.6948\n",
            "Epoch 58/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.4995 - loss: 0.6913 - val_accuracy: 0.4400 - val_loss: 0.6908\n",
            "Epoch 59/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.6100 - loss: 0.6926 - val_accuracy: 0.4800 - val_loss: 0.6927\n",
            "Epoch 60/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5504 - loss: 0.6908 - val_accuracy: 0.5600 - val_loss: 0.6958\n",
            "Epoch 61/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.5484 - loss: 0.6879 - val_accuracy: 0.4400 - val_loss: 0.7073\n",
            "Epoch 62/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.5435 - loss: 0.6853 - val_accuracy: 0.4400 - val_loss: 0.7211\n",
            "Epoch 63/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.5904 - loss: 0.6789 - val_accuracy: 0.4400 - val_loss: 0.7331\n",
            "Epoch 64/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5669 - loss: 0.6821 - val_accuracy: 0.4400 - val_loss: 0.7192\n",
            "Epoch 65/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.5357 - loss: 0.6909 - val_accuracy: 0.4400 - val_loss: 0.7079\n",
            "Epoch 66/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5435 - loss: 0.6877 - val_accuracy: 0.4000 - val_loss: 0.7024\n",
            "Epoch 67/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5513 - loss: 0.6895 - val_accuracy: 0.4400 - val_loss: 0.7038\n",
            "Epoch 68/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5357 - loss: 0.6878 - val_accuracy: 0.4400 - val_loss: 0.7082\n",
            "Epoch 69/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5543 - loss: 0.6887 - val_accuracy: 0.4400 - val_loss: 0.7127\n",
            "Epoch 70/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5630 - loss: 0.6828 - val_accuracy: 0.4400 - val_loss: 0.7187\n",
            "Epoch 71/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5357 - loss: 0.6895 - val_accuracy: 0.4400 - val_loss: 0.7259\n",
            "Epoch 72/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5435 - loss: 0.6879 - val_accuracy: 0.4400 - val_loss: 0.7301\n",
            "Epoch 73/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5826 - loss: 0.6768 - val_accuracy: 0.4400 - val_loss: 0.7188\n",
            "Epoch 74/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5396 - loss: 0.6906 - val_accuracy: 0.4800 - val_loss: 0.7005\n",
            "Epoch 75/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5484 - loss: 0.6829 - val_accuracy: 0.5200 - val_loss: 0.6929\n",
            "Epoch 76/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6256 - loss: 0.6901 - val_accuracy: 0.4800 - val_loss: 0.6913\n",
            "Epoch 77/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.5953 - loss: 0.6915 - val_accuracy: 0.5200 - val_loss: 0.6926\n",
            "Epoch 78/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5728 - loss: 0.6885 - val_accuracy: 0.4400 - val_loss: 0.7013\n",
            "Epoch 79/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5357 - loss: 0.6862 - val_accuracy: 0.4400 - val_loss: 0.7132\n",
            "Epoch 80/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5201 - loss: 0.6941 - val_accuracy: 0.4400 - val_loss: 0.7215\n",
            "Epoch 81/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5513 - loss: 0.6869 - val_accuracy: 0.4400 - val_loss: 0.7247\n",
            "Epoch 82/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5552 - loss: 0.6864 - val_accuracy: 0.4400 - val_loss: 0.7221\n",
            "Epoch 83/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5123 - loss: 0.6979 - val_accuracy: 0.4400 - val_loss: 0.7155\n",
            "Epoch 84/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5396 - loss: 0.6881 - val_accuracy: 0.4400 - val_loss: 0.7093\n",
            "Epoch 85/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5708 - loss: 0.6811 - val_accuracy: 0.4400 - val_loss: 0.7001\n",
            "Epoch 86/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5396 - loss: 0.6871 - val_accuracy: 0.5200 - val_loss: 0.6885\n",
            "Epoch 87/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.4770 - loss: 0.6943 - val_accuracy: 0.5600 - val_loss: 0.6852\n",
            "Epoch 88/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5318 - loss: 0.6942 - val_accuracy: 0.6000 - val_loss: 0.6890\n",
            "Epoch 89/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.5025 - loss: 0.6893 - val_accuracy: 0.4400 - val_loss: 0.7019\n",
            "Epoch 90/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5318 - loss: 0.6846 - val_accuracy: 0.4400 - val_loss: 0.7213\n",
            "Epoch 91/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5474 - loss: 0.6894 - val_accuracy: 0.4400 - val_loss: 0.7401\n",
            "Epoch 92/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5630 - loss: 0.6884 - val_accuracy: 0.4400 - val_loss: 0.7393\n",
            "Epoch 93/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5240 - loss: 0.7065 - val_accuracy: 0.4400 - val_loss: 0.7103\n",
            "Epoch 94/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.5318 - loss: 0.6908 - val_accuracy: 0.4800 - val_loss: 0.6942\n",
            "Epoch 95/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5523 - loss: 0.6885 - val_accuracy: 0.5600 - val_loss: 0.6930\n",
            "Epoch 96/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5406 - loss: 0.6887 - val_accuracy: 0.4400 - val_loss: 0.6964\n",
            "Epoch 97/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5474 - loss: 0.6872 - val_accuracy: 0.4400 - val_loss: 0.7041\n",
            "Epoch 98/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.5552 - loss: 0.6844 - val_accuracy: 0.4400 - val_loss: 0.7078\n",
            "Epoch 99/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5552 - loss: 0.6839 - val_accuracy: 0.4400 - val_loss: 0.7060\n",
            "Epoch 100/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5630 - loss: 0.6822 - val_accuracy: 0.4400 - val_loss: 0.7010\n",
            "Epoch 101/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5337 - loss: 0.6860 - val_accuracy: 0.4400 - val_loss: 0.6945\n",
            "Epoch 102/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5493 - loss: 0.6851 - val_accuracy: 0.5600 - val_loss: 0.6900\n",
            "Epoch 103/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5699 - loss: 0.6893 - val_accuracy: 0.5600 - val_loss: 0.6861\n",
            "Epoch 104/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5591 - loss: 0.6927 - val_accuracy: 0.6000 - val_loss: 0.6855\n",
            "Epoch 105/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5543 - loss: 0.6937 - val_accuracy: 0.5600 - val_loss: 0.6910\n",
            "Epoch 106/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5601 - loss: 0.6870 - val_accuracy: 0.4400 - val_loss: 0.7007\n",
            "Epoch 107/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5787 - loss: 0.6813 - val_accuracy: 0.4400 - val_loss: 0.7047\n",
            "Epoch 108/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5523 - loss: 0.6840 - val_accuracy: 0.4400 - val_loss: 0.6958\n",
            "Epoch 109/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5337 - loss: 0.6841 - val_accuracy: 0.5600 - val_loss: 0.6893\n",
            "Epoch 110/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5650 - loss: 0.6898 - val_accuracy: 0.5600 - val_loss: 0.6883\n",
            "Epoch 111/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5396 - loss: 0.6909 - val_accuracy: 0.6000 - val_loss: 0.6896\n",
            "Epoch 112/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5787 - loss: 0.6879 - val_accuracy: 0.4400 - val_loss: 0.6964\n",
            "Epoch 113/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5445 - loss: 0.6863 - val_accuracy: 0.4400 - val_loss: 0.6998\n",
            "Epoch 114/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5367 - loss: 0.6862 - val_accuracy: 0.4400 - val_loss: 0.7004\n",
            "Epoch 115/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5220 - loss: 0.6879 - val_accuracy: 0.4400 - val_loss: 0.6964\n",
            "Epoch 116/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5571 - loss: 0.6808 - val_accuracy: 0.6000 - val_loss: 0.6910\n",
            "Epoch 117/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5171 - loss: 0.6891 - val_accuracy: 0.5600 - val_loss: 0.6863\n",
            "Epoch 118/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5464 - loss: 0.6898 - val_accuracy: 0.4800 - val_loss: 0.6927\n",
            "Epoch 119/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.4946 - loss: 0.6878 - val_accuracy: 0.4400 - val_loss: 0.7040\n",
            "Epoch 120/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5523 - loss: 0.6841 - val_accuracy: 0.4400 - val_loss: 0.7146\n",
            "Epoch 121/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5513 - loss: 0.6872 - val_accuracy: 0.4400 - val_loss: 0.7211\n",
            "Epoch 122/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.5826 - loss: 0.6771 - val_accuracy: 0.4400 - val_loss: 0.7205\n",
            "Epoch 123/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5435 - loss: 0.6896 - val_accuracy: 0.4400 - val_loss: 0.7109\n",
            "Epoch 124/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5591 - loss: 0.6838 - val_accuracy: 0.4400 - val_loss: 0.7016\n",
            "Epoch 125/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5181 - loss: 0.6890 - val_accuracy: 0.6000 - val_loss: 0.6925\n",
            "Epoch 126/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5171 - loss: 0.6877 - val_accuracy: 0.5200 - val_loss: 0.6944\n",
            "Epoch 127/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5181 - loss: 0.6868 - val_accuracy: 0.4400 - val_loss: 0.7049\n",
            "Epoch 128/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5318 - loss: 0.6868 - val_accuracy: 0.4400 - val_loss: 0.7196\n",
            "Epoch 129/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5630 - loss: 0.6856 - val_accuracy: 0.4400 - val_loss: 0.7346\n",
            "Epoch 130/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5396 - loss: 0.6948 - val_accuracy: 0.4400 - val_loss: 0.7396\n",
            "Epoch 131/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5357 - loss: 0.6950 - val_accuracy: 0.4400 - val_loss: 0.7339\n",
            "Epoch 132/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5708 - loss: 0.6791 - val_accuracy: 0.4400 - val_loss: 0.7176\n",
            "Epoch 133/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5210 - loss: 0.6944 - val_accuracy: 0.5600 - val_loss: 0.6939\n",
            "Epoch 134/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5259 - loss: 0.6856 - val_accuracy: 0.5600 - val_loss: 0.6866\n",
            "Epoch 135/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.5532 - loss: 0.6913 - val_accuracy: 0.5600 - val_loss: 0.6863\n",
            "Epoch 136/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5210 - loss: 0.6962 - val_accuracy: 0.6000 - val_loss: 0.6941\n",
            "Epoch 137/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5454 - loss: 0.6848 - val_accuracy: 0.4400 - val_loss: 0.7022\n",
            "Epoch 138/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5132 - loss: 0.6877 - val_accuracy: 0.4400 - val_loss: 0.7113\n",
            "Epoch 139/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5308 - loss: 0.6924 - val_accuracy: 0.4400 - val_loss: 0.7128\n",
            "Epoch 140/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5513 - loss: 0.6851 - val_accuracy: 0.4400 - val_loss: 0.7192\n",
            "Epoch 141/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5513 - loss: 0.6852 - val_accuracy: 0.4400 - val_loss: 0.7205\n",
            "Epoch 142/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5669 - loss: 0.6796 - val_accuracy: 0.4400 - val_loss: 0.7147\n",
            "Epoch 143/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.4937 - loss: 0.7029 - val_accuracy: 0.4400 - val_loss: 0.6997\n",
            "Epoch 144/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5142 - loss: 0.6859 - val_accuracy: 0.4400 - val_loss: 0.6977\n",
            "Epoch 145/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5288 - loss: 0.6867 - val_accuracy: 0.4400 - val_loss: 0.6995\n",
            "Epoch 146/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5190 - loss: 0.6837 - val_accuracy: 0.4400 - val_loss: 0.7028\n",
            "Epoch 147/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5054 - loss: 0.6895 - val_accuracy: 0.4400 - val_loss: 0.6992\n",
            "Epoch 148/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5210 - loss: 0.6870 - val_accuracy: 0.4400 - val_loss: 0.7006\n",
            "Epoch 149/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.4946 - loss: 0.6874 - val_accuracy: 0.4400 - val_loss: 0.7013\n",
            "Epoch 150/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5132 - loss: 0.6869 - val_accuracy: 0.4400 - val_loss: 0.7084\n",
            "Epoch 151/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5123 - loss: 0.6920 - val_accuracy: 0.4400 - val_loss: 0.7165\n",
            "Epoch 152/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5396 - loss: 0.6866 - val_accuracy: 0.4400 - val_loss: 0.7199\n",
            "Epoch 153/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5318 - loss: 0.6921 - val_accuracy: 0.4400 - val_loss: 0.7122\n",
            "Epoch 154/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5435 - loss: 0.6861 - val_accuracy: 0.4400 - val_loss: 0.7047\n",
            "Epoch 155/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5210 - loss: 0.6866 - val_accuracy: 0.4400 - val_loss: 0.7056\n",
            "Epoch 156/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5015 - loss: 0.6923 - val_accuracy: 0.4400 - val_loss: 0.7107\n",
            "Epoch 157/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.5708 - loss: 0.6815 - val_accuracy: 0.4400 - val_loss: 0.7267\n",
            "Epoch 158/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.5630 - loss: 0.6834 - val_accuracy: 0.4400 - val_loss: 0.7273\n",
            "Epoch 159/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5552 - loss: 0.6844 - val_accuracy: 0.4400 - val_loss: 0.7202\n",
            "Epoch 160/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5357 - loss: 0.6886 - val_accuracy: 0.4400 - val_loss: 0.7080\n",
            "Epoch 161/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5445 - loss: 0.6819 - val_accuracy: 0.4400 - val_loss: 0.7056\n",
            "Epoch 162/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5259 - loss: 0.6851 - val_accuracy: 0.4400 - val_loss: 0.6996\n",
            "Epoch 163/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5210 - loss: 0.6872 - val_accuracy: 0.4400 - val_loss: 0.6989\n",
            "Epoch 164/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5601 - loss: 0.6806 - val_accuracy: 0.4400 - val_loss: 0.7041\n",
            "Epoch 165/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5406 - loss: 0.6865 - val_accuracy: 0.4400 - val_loss: 0.7046\n",
            "Epoch 166/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5367 - loss: 0.6859 - val_accuracy: 0.4400 - val_loss: 0.7069\n",
            "Epoch 167/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5484 - loss: 0.6827 - val_accuracy: 0.4400 - val_loss: 0.7033\n",
            "Epoch 168/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5445 - loss: 0.6814 - val_accuracy: 0.5200 - val_loss: 0.6956\n",
            "Epoch 169/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.4995 - loss: 0.6857 - val_accuracy: 0.5200 - val_loss: 0.6937\n",
            "Epoch 170/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5073 - loss: 0.6872 - val_accuracy: 0.5200 - val_loss: 0.6970\n",
            "Epoch 171/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5650 - loss: 0.6835 - val_accuracy: 0.4800 - val_loss: 0.7028\n",
            "Epoch 172/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5562 - loss: 0.6817 - val_accuracy: 0.4800 - val_loss: 0.7047\n",
            "Epoch 173/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5288 - loss: 0.6827 - val_accuracy: 0.4400 - val_loss: 0.7106\n",
            "Epoch 174/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5249 - loss: 0.6883 - val_accuracy: 0.4400 - val_loss: 0.7099\n",
            "Epoch 175/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5279 - loss: 0.6857 - val_accuracy: 0.4400 - val_loss: 0.7069\n",
            "Epoch 176/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5562 - loss: 0.6772 - val_accuracy: 0.4400 - val_loss: 0.7074\n",
            "Epoch 177/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5288 - loss: 0.6856 - val_accuracy: 0.4400 - val_loss: 0.7051\n",
            "Epoch 178/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5367 - loss: 0.6868 - val_accuracy: 0.4400 - val_loss: 0.7063\n",
            "Epoch 179/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5445 - loss: 0.6821 - val_accuracy: 0.4400 - val_loss: 0.7058\n",
            "Epoch 180/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.5327 - loss: 0.6863 - val_accuracy: 0.4400 - val_loss: 0.7005\n",
            "Epoch 181/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5288 - loss: 0.6853 - val_accuracy: 0.5200 - val_loss: 0.7002\n",
            "Epoch 182/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.4976 - loss: 0.6904 - val_accuracy: 0.4800 - val_loss: 0.7049\n",
            "Epoch 183/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5513 - loss: 0.6845 - val_accuracy: 0.4400 - val_loss: 0.7001\n",
            "Epoch 184/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.5220 - loss: 0.6901 - val_accuracy: 0.4800 - val_loss: 0.6985\n",
            "Epoch 185/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.5767 - loss: 0.6902 - val_accuracy: 0.4400 - val_loss: 0.7176\n",
            "Epoch 186/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5474 - loss: 0.6855 - val_accuracy: 0.4400 - val_loss: 0.7487\n",
            "Epoch 187/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5435 - loss: 0.6988 - val_accuracy: 0.4400 - val_loss: 0.7404\n",
            "Epoch 188/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.5396 - loss: 0.6949 - val_accuracy: 0.4400 - val_loss: 0.7133\n",
            "Epoch 189/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.5142 - loss: 0.6899 - val_accuracy: 0.6000 - val_loss: 0.6919\n",
            "Epoch 190/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6109 - loss: 0.6821 - val_accuracy: 0.5600 - val_loss: 0.6825\n",
            "Epoch 191/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.4975 - loss: 0.6976 - val_accuracy: 0.5600 - val_loss: 0.6804\n",
            "Epoch 192/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.5669 - loss: 0.6940 - val_accuracy: 0.6000 - val_loss: 0.6872\n",
            "Epoch 193/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5572 - loss: 0.6839 - val_accuracy: 0.4400 - val_loss: 0.7099\n",
            "Epoch 194/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5357 - loss: 0.6885 - val_accuracy: 0.4400 - val_loss: 0.7429\n",
            "Epoch 195/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.5513 - loss: 0.6954 - val_accuracy: 0.4400 - val_loss: 0.7459\n",
            "Epoch 196/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.5591 - loss: 0.6872 - val_accuracy: 0.4400 - val_loss: 0.7336\n",
            "Epoch 197/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.5748 - loss: 0.6772 - val_accuracy: 0.4400 - val_loss: 0.7143\n",
            "Epoch 198/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.5669 - loss: 0.6757 - val_accuracy: 0.5200 - val_loss: 0.6974\n",
            "Epoch 199/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6061 - loss: 0.6851 - val_accuracy: 0.5600 - val_loss: 0.6892\n",
            "Epoch 200/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.4868 - loss: 0.6950 - val_accuracy: 0.5600 - val_loss: 0.6871\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function pfor.<locals>.f at 0x78155da31fc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 6 calls to <function pfor.<locals>.f at 0x78155d4cbd90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.52\n",
            "Precision: 0.4807017543859649\n",
            "Recall: 0.52\n",
            "F1 Score: 0.4882352941176471\n",
            "AUC (Keras): 0.41999996\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# creating confusion matrix\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "labels = [\"Fresh\", \"Frozen\"]\n",
        "\n",
        "cm = confusion_matrix(y_val_labels_original, predicted_labels_original)\n",
        "\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
        "\n",
        "disp.plot(cmap=plt.cm.Blues)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "dpJZ20q5VhhC",
        "outputId": "e2bd2d0f-1598-4fb7-9310-d220000be8bb"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3 class classification L_a_b\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from keras.utils import to_categorical\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Convert labels to integers using LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "y_train_encoded = label_encoder.fit_transform(Y)\n",
        "y_train_categorical = to_categorical(y_train_encoded)\n",
        "\n",
        "# Split the data into training and validation sets\n",
        "x_train, x_test, y_train_cat, y_test = train_test_split(X, y_train_categorical, test_size=0.2, random_state=42)\n",
        "x_train, x_val, y_train_cat, y_val_cat = train_test_split(x_train, y_train_cat, test_size=0.25, random_state=42)\n",
        "\n",
        "# Build the neural network model\n",
        "model = Sequential()\n",
        "# Classification with L a b values\n",
        "model.add(Dense(64, input_dim=3, activation='relu'))\n",
        "#model.add(Dense(64, input_dim=4096, activation='relu'))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Dense(16, activation='relu'))\n",
        "model.add(Dense(len(label_encoder.classes_), activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Define early stopping criteria\n",
        "#early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "\n",
        "\n",
        "checkpoint_path = \"/content/drive/MyDrive/CorrectedAll/Model_Weightes/Fresh_Frozen20_Frozen60_L_a_b.keras\"\n",
        "checkpoint = ModelCheckpoint(checkpoint_path, monitor='val_accuracy', save_best_only=True, mode='max')\n",
        "\n",
        "# Train the model with early stopping\n",
        "model.fit(x_train, y_train_cat, epochs=200, batch_size=32, validation_data=(x_val, y_val_cat), callbacks=[checkpoint])\n",
        "\n",
        "\n",
        "model.load_weights(\"/content/drive/MyDrive/CorrectedAll/Model_Weightes/Fresh_Frozen20_Frozen60_L_a_b.keras\")\n",
        "# Predict on the test data\n",
        "predicted_probabilities = model.predict(x_test)\n",
        "predicted_labels = np.argmax(predicted_probabilities, axis=1)\n",
        "predicted_labels_original = label_encoder.inverse_transform(predicted_labels)\n",
        "\n",
        "# Convert y_val_cat back to class labels\n",
        "y_val_labels = np.argmax(y_test, axis=1)\n",
        "y_val_labels_original = label_encoder.inverse_transform(y_val_labels)\n",
        "\n",
        "# Calculate and print accuracy, precision, recall, and F1 score\n",
        "accuracy = accuracy_score(y_val_labels_original, predicted_labels_original)\n",
        "precision = precision_score(y_val_labels_original, predicted_labels_original, average='weighted')\n",
        "recall = recall_score(y_val_labels_original, predicted_labels_original, average='weighted')\n",
        "f1 = f1_score(y_val_labels_original, predicted_labels_original, average='weighted')\n",
        "\n",
        "# Initialize a Keras AUC metric\n",
        "auc_metric = tf.keras.metrics.AUC(name='auc', multi_label=True)\n",
        "\n",
        "# Update the AUC metric with true labels and predicted probabilities\n",
        "auc_metric.update_state(y_test, predicted_probabilities)\n",
        "auc = auc_metric.result().numpy()\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1 Score:\", f1)\n",
        "print(\"AUC (Keras):\", auc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "003a33e7-7c20-436a-9f77-02e6e4bf74c3",
        "id": "fZTTFaXAWcor"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 205ms/step - accuracy: 0.3158 - loss: 3.7906 - val_accuracy: 0.3200 - val_loss: 2.6172\n",
            "Epoch 2/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.4105 - loss: 2.4296 - val_accuracy: 0.3200 - val_loss: 1.4762\n",
            "Epoch 3/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.3891 - loss: 1.8013 - val_accuracy: 0.2400 - val_loss: 1.1546\n",
            "Epoch 4/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.2982 - loss: 1.8427 - val_accuracy: 0.2800 - val_loss: 1.1883\n",
            "Epoch 5/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.3431 - loss: 1.7694 - val_accuracy: 0.2800 - val_loss: 1.2384\n",
            "Epoch 6/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.3910 - loss: 1.4918 - val_accuracy: 0.2800 - val_loss: 1.2378\n",
            "Epoch 7/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.3256 - loss: 1.6644 - val_accuracy: 0.2000 - val_loss: 1.1940\n",
            "Epoch 8/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.2815 - loss: 1.5320 - val_accuracy: 0.1200 - val_loss: 1.1625\n",
            "Epoch 9/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.3138 - loss: 1.4458 - val_accuracy: 0.0800 - val_loss: 1.1514\n",
            "Epoch 10/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.3676 - loss: 1.4576 - val_accuracy: 0.0800 - val_loss: 1.1424\n",
            "Epoch 11/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.4468 - loss: 1.2794 - val_accuracy: 0.0800 - val_loss: 1.1292\n",
            "Epoch 12/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.3275 - loss: 1.4218 - val_accuracy: 0.2800 - val_loss: 1.1228\n",
            "Epoch 13/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.2669 - loss: 1.3946 - val_accuracy: 0.2800 - val_loss: 1.1253\n",
            "Epoch 14/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.3812 - loss: 1.2248 - val_accuracy: 0.2800 - val_loss: 1.1240\n",
            "Epoch 15/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.3744 - loss: 1.1892 - val_accuracy: 0.2800 - val_loss: 1.1269\n",
            "Epoch 16/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.3206 - loss: 1.3227 - val_accuracy: 0.2800 - val_loss: 1.1226\n",
            "Epoch 17/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.3949 - loss: 1.1722 - val_accuracy: 0.2800 - val_loss: 1.1188\n",
            "Epoch 18/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.3754 - loss: 1.1659 - val_accuracy: 0.2800 - val_loss: 1.1136\n",
            "Epoch 19/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.3910 - loss: 1.1527 - val_accuracy: 0.2800 - val_loss: 1.1082\n",
            "Epoch 20/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.2756 - loss: 1.2394 - val_accuracy: 0.2800 - val_loss: 1.1056\n",
            "Epoch 21/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.3802 - loss: 1.1330 - val_accuracy: 0.2800 - val_loss: 1.1016\n",
            "Epoch 22/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.3695 - loss: 1.1778 - val_accuracy: 0.2800 - val_loss: 1.0959\n",
            "Epoch 23/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5151 - loss: 1.0169 - val_accuracy: 0.2800 - val_loss: 1.0903\n",
            "Epoch 24/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.3294 - loss: 1.1538 - val_accuracy: 0.2800 - val_loss: 1.0860\n",
            "Epoch 25/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.3832 - loss: 1.1132 - val_accuracy: 0.3200 - val_loss: 1.0808\n",
            "Epoch 26/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.4037 - loss: 1.0514 - val_accuracy: 0.4000 - val_loss: 1.0797\n",
            "Epoch 27/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.3978 - loss: 1.0734 - val_accuracy: 0.4800 - val_loss: 1.0757\n",
            "Epoch 28/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.3607 - loss: 1.0962 - val_accuracy: 0.5200 - val_loss: 1.0722\n",
            "Epoch 29/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.4292 - loss: 1.0718 - val_accuracy: 0.5600 - val_loss: 1.0710\n",
            "Epoch 30/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4594 - loss: 1.1180 - val_accuracy: 0.3600 - val_loss: 1.0742\n",
            "Epoch 31/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4565 - loss: 1.0271 - val_accuracy: 0.3600 - val_loss: 1.0711\n",
            "Epoch 32/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.3529 - loss: 1.0649 - val_accuracy: 0.3600 - val_loss: 1.0634\n",
            "Epoch 33/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.4292 - loss: 1.0490 - val_accuracy: 0.3600 - val_loss: 1.0656\n",
            "Epoch 34/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.4829 - loss: 1.0212 - val_accuracy: 0.3600 - val_loss: 1.0785\n",
            "Epoch 35/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.4496 - loss: 1.0041 - val_accuracy: 0.3200 - val_loss: 1.0925\n",
            "Epoch 36/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.3969 - loss: 1.0967 - val_accuracy: 0.3200 - val_loss: 1.0975\n",
            "Epoch 37/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.4487 - loss: 1.0270 - val_accuracy: 0.3200 - val_loss: 1.0910\n",
            "Epoch 38/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.4301 - loss: 1.0753 - val_accuracy: 0.3200 - val_loss: 1.0821\n",
            "Epoch 39/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4751 - loss: 1.1009 - val_accuracy: 0.2800 - val_loss: 1.0771\n",
            "Epoch 40/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5014 - loss: 0.9990 - val_accuracy: 0.2400 - val_loss: 1.0740\n",
            "Epoch 41/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.4194 - loss: 1.1218 - val_accuracy: 0.3200 - val_loss: 1.0721\n",
            "Epoch 42/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.4770 - loss: 1.0486 - val_accuracy: 0.3600 - val_loss: 1.0701\n",
            "Epoch 43/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.4731 - loss: 1.0293 - val_accuracy: 0.3600 - val_loss: 1.0749\n",
            "Epoch 44/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5308 - loss: 1.0000 - val_accuracy: 0.4000 - val_loss: 1.0779\n",
            "Epoch 45/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.4614 - loss: 1.0568 - val_accuracy: 0.3600 - val_loss: 1.0739\n",
            "Epoch 46/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.4594 - loss: 1.0204 - val_accuracy: 0.3600 - val_loss: 1.0668\n",
            "Epoch 47/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.4047 - loss: 1.0450 - val_accuracy: 0.3600 - val_loss: 1.0605\n",
            "Epoch 48/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5591 - loss: 1.0319 - val_accuracy: 0.4400 - val_loss: 1.0574\n",
            "Epoch 49/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.4565 - loss: 1.0171 - val_accuracy: 0.4400 - val_loss: 1.0536\n",
            "Epoch 50/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.4516 - loss: 1.0263 - val_accuracy: 0.4000 - val_loss: 1.0421\n",
            "Epoch 51/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5728 - loss: 0.9846 - val_accuracy: 0.3200 - val_loss: 1.0399\n",
            "Epoch 52/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4340 - loss: 0.9698 - val_accuracy: 0.3200 - val_loss: 1.0442\n",
            "Epoch 53/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.4956 - loss: 0.9951 - val_accuracy: 0.3200 - val_loss: 1.0479\n",
            "Epoch 54/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.4301 - loss: 1.0258 - val_accuracy: 0.4000 - val_loss: 1.0443\n",
            "Epoch 55/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.4594 - loss: 1.0268 - val_accuracy: 0.4400 - val_loss: 1.0445\n",
            "Epoch 56/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.4673 - loss: 1.0253 - val_accuracy: 0.4000 - val_loss: 1.0419\n",
            "Epoch 57/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.3871 - loss: 1.1383 - val_accuracy: 0.4000 - val_loss: 1.0402\n",
            "Epoch 58/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5728 - loss: 0.9459 - val_accuracy: 0.3600 - val_loss: 1.0573\n",
            "Epoch 59/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5112 - loss: 0.9916 - val_accuracy: 0.3200 - val_loss: 1.0816\n",
            "Epoch 60/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4331 - loss: 1.0125 - val_accuracy: 0.3200 - val_loss: 1.0881\n",
            "Epoch 61/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.5757 - loss: 0.9670 - val_accuracy: 0.4000 - val_loss: 1.0792\n",
            "Epoch 62/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.4907 - loss: 1.0186 - val_accuracy: 0.4000 - val_loss: 1.0594\n",
            "Epoch 63/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.4712 - loss: 0.9717 - val_accuracy: 0.4000 - val_loss: 1.0397\n",
            "Epoch 64/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5083 - loss: 1.0527 - val_accuracy: 0.4000 - val_loss: 1.0343\n",
            "Epoch 65/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.4624 - loss: 1.0183 - val_accuracy: 0.4000 - val_loss: 1.0335\n",
            "Epoch 66/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5162 - loss: 0.9833 - val_accuracy: 0.3600 - val_loss: 1.0408\n",
            "Epoch 67/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.4399 - loss: 1.0349 - val_accuracy: 0.3600 - val_loss: 1.0458\n",
            "Epoch 68/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.4712 - loss: 0.9955 - val_accuracy: 0.3600 - val_loss: 1.0459\n",
            "Epoch 69/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.4888 - loss: 0.9946 - val_accuracy: 0.4000 - val_loss: 1.0410\n",
            "Epoch 70/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.4262 - loss: 1.0210 - val_accuracy: 0.3600 - val_loss: 1.0298\n",
            "Epoch 71/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.4409 - loss: 0.9830 - val_accuracy: 0.4000 - val_loss: 1.0267\n",
            "Epoch 72/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.4457 - loss: 1.0596 - val_accuracy: 0.3600 - val_loss: 1.0313\n",
            "Epoch 73/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5367 - loss: 0.9652 - val_accuracy: 0.3600 - val_loss: 1.0368\n",
            "Epoch 74/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5279 - loss: 0.9826 - val_accuracy: 0.3600 - val_loss: 1.0376\n",
            "Epoch 75/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.4623 - loss: 1.0138 - val_accuracy: 0.3600 - val_loss: 1.0384\n",
            "Epoch 76/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.4751 - loss: 1.0008 - val_accuracy: 0.3600 - val_loss: 1.0406\n",
            "Epoch 77/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.4946 - loss: 1.0197 - val_accuracy: 0.3600 - val_loss: 1.0420\n",
            "Epoch 78/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5064 - loss: 1.0588 - val_accuracy: 0.3600 - val_loss: 1.0650\n",
            "Epoch 79/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.4770 - loss: 1.0014 - val_accuracy: 0.3600 - val_loss: 1.0880\n",
            "Epoch 80/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.4770 - loss: 1.0024 - val_accuracy: 0.3600 - val_loss: 1.1007\n",
            "Epoch 81/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5151 - loss: 1.0170 - val_accuracy: 0.3600 - val_loss: 1.0948\n",
            "Epoch 82/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.4780 - loss: 1.0727 - val_accuracy: 0.4000 - val_loss: 1.0575\n",
            "Epoch 83/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.4956 - loss: 0.9794 - val_accuracy: 0.4400 - val_loss: 1.0458\n",
            "Epoch 84/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5279 - loss: 0.9753 - val_accuracy: 0.4400 - val_loss: 1.0354\n",
            "Epoch 85/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5230 - loss: 0.9732 - val_accuracy: 0.4000 - val_loss: 1.0334\n",
            "Epoch 86/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.4692 - loss: 1.0081 - val_accuracy: 0.4400 - val_loss: 1.0336\n",
            "Epoch 87/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5259 - loss: 0.9925 - val_accuracy: 0.4000 - val_loss: 1.0431\n",
            "Epoch 88/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5415 - loss: 1.0165 - val_accuracy: 0.4000 - val_loss: 1.0473\n",
            "Epoch 89/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5777 - loss: 0.9256 - val_accuracy: 0.4400 - val_loss: 1.0335\n",
            "Epoch 90/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5660 - loss: 0.9635 - val_accuracy: 0.3600 - val_loss: 1.0318\n",
            "Epoch 91/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5220 - loss: 0.9602 - val_accuracy: 0.3600 - val_loss: 1.0461\n",
            "Epoch 92/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5181 - loss: 0.9963 - val_accuracy: 0.4000 - val_loss: 1.0552\n",
            "Epoch 93/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.4898 - loss: 1.0615 - val_accuracy: 0.3600 - val_loss: 1.0587\n",
            "Epoch 94/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5591 - loss: 0.9537 - val_accuracy: 0.3600 - val_loss: 1.0706\n",
            "Epoch 95/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.4946 - loss: 0.9826 - val_accuracy: 0.3600 - val_loss: 1.0850\n",
            "Epoch 96/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4770 - loss: 1.0278 - val_accuracy: 0.3600 - val_loss: 1.0841\n",
            "Epoch 97/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.4858 - loss: 1.0284 - val_accuracy: 0.3600 - val_loss: 1.0673\n",
            "Epoch 98/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.4986 - loss: 0.9854 - val_accuracy: 0.4000 - val_loss: 1.0506\n",
            "Epoch 99/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5220 - loss: 0.9811 - val_accuracy: 0.3600 - val_loss: 1.0294\n",
            "Epoch 100/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.4721 - loss: 0.9956 - val_accuracy: 0.4000 - val_loss: 1.0170\n",
            "Epoch 101/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.4839 - loss: 0.9838 - val_accuracy: 0.3600 - val_loss: 1.0163\n",
            "Epoch 102/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.4829 - loss: 1.0078 - val_accuracy: 0.3600 - val_loss: 1.0086\n",
            "Epoch 103/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.4477 - loss: 1.0492 - val_accuracy: 0.4000 - val_loss: 1.0059\n",
            "Epoch 104/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5767 - loss: 0.9230 - val_accuracy: 0.3600 - val_loss: 1.0115\n",
            "Epoch 105/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5337 - loss: 0.9636 - val_accuracy: 0.4400 - val_loss: 1.0149\n",
            "Epoch 106/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5474 - loss: 0.9710 - val_accuracy: 0.4000 - val_loss: 1.0282\n",
            "Epoch 107/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5972 - loss: 0.9303 - val_accuracy: 0.3600 - val_loss: 1.0395\n",
            "Epoch 108/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.4379 - loss: 0.9968 - val_accuracy: 0.4000 - val_loss: 1.0137\n",
            "Epoch 109/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6080 - loss: 0.9428 - val_accuracy: 0.3600 - val_loss: 1.0193\n",
            "Epoch 110/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.4995 - loss: 0.9870 - val_accuracy: 0.3600 - val_loss: 1.0168\n",
            "Epoch 111/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5073 - loss: 1.0224 - val_accuracy: 0.4400 - val_loss: 1.0253\n",
            "Epoch 112/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5327 - loss: 0.9457 - val_accuracy: 0.4000 - val_loss: 1.0338\n",
            "Epoch 113/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5249 - loss: 0.9742 - val_accuracy: 0.3200 - val_loss: 1.0306\n",
            "Epoch 114/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6178 - loss: 0.9280 - val_accuracy: 0.3200 - val_loss: 1.0269\n",
            "Epoch 115/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5161 - loss: 0.9940 - val_accuracy: 0.3600 - val_loss: 1.0249\n",
            "Epoch 116/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.4516 - loss: 1.0097 - val_accuracy: 0.3600 - val_loss: 1.0187\n",
            "Epoch 117/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.5151 - loss: 0.9621 - val_accuracy: 0.4000 - val_loss: 1.0140\n",
            "Epoch 118/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.5269 - loss: 0.9878 - val_accuracy: 0.4000 - val_loss: 1.0113\n",
            "Epoch 119/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.4946 - loss: 1.0150 - val_accuracy: 0.3600 - val_loss: 1.0158\n",
            "Epoch 120/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.5327 - loss: 0.9756 - val_accuracy: 0.3600 - val_loss: 1.0243\n",
            "Epoch 121/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5073 - loss: 0.9577 - val_accuracy: 0.3600 - val_loss: 1.0321\n",
            "Epoch 122/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5523 - loss: 0.9710 - val_accuracy: 0.3200 - val_loss: 1.0344\n",
            "Epoch 123/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5112 - loss: 1.0056 - val_accuracy: 0.4000 - val_loss: 1.0259\n",
            "Epoch 124/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.5689 - loss: 0.9829 - val_accuracy: 0.4400 - val_loss: 1.0201\n",
            "Epoch 125/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5611 - loss: 0.9613 - val_accuracy: 0.3600 - val_loss: 1.0261\n",
            "Epoch 126/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.5982 - loss: 0.9707 - val_accuracy: 0.3600 - val_loss: 1.0242\n",
            "Epoch 127/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5288 - loss: 0.9542 - val_accuracy: 0.3600 - val_loss: 1.0095\n",
            "Epoch 128/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.5249 - loss: 0.9904 - val_accuracy: 0.3600 - val_loss: 1.0143\n",
            "Epoch 129/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5806 - loss: 0.9199 - val_accuracy: 0.3600 - val_loss: 1.0164\n",
            "Epoch 130/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.5474 - loss: 0.9558 - val_accuracy: 0.4000 - val_loss: 1.0327\n",
            "Epoch 131/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5279 - loss: 0.9507 - val_accuracy: 0.3600 - val_loss: 1.0529\n",
            "Epoch 132/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.5356 - loss: 1.0202 - val_accuracy: 0.3600 - val_loss: 1.0269\n",
            "Epoch 133/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5699 - loss: 0.9248 - val_accuracy: 0.4400 - val_loss: 1.0042\n",
            "Epoch 134/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.4946 - loss: 1.0030 - val_accuracy: 0.4000 - val_loss: 1.0026\n",
            "Epoch 135/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.4067 - loss: 1.0076 - val_accuracy: 0.3600 - val_loss: 1.0052\n",
            "Epoch 136/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.4966 - loss: 0.9585 - val_accuracy: 0.3600 - val_loss: 1.0091\n",
            "Epoch 137/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.5073 - loss: 0.9580 - val_accuracy: 0.4000 - val_loss: 1.0067\n",
            "Epoch 138/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.4585 - loss: 1.0095 - val_accuracy: 0.3600 - val_loss: 1.0186\n",
            "Epoch 139/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.5845 - loss: 0.9301 - val_accuracy: 0.4000 - val_loss: 1.0088\n",
            "Epoch 140/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.5083 - loss: 0.9816 - val_accuracy: 0.4400 - val_loss: 1.0010\n",
            "Epoch 141/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.5220 - loss: 0.9452 - val_accuracy: 0.3600 - val_loss: 1.0056\n",
            "Epoch 142/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.4780 - loss: 0.9304 - val_accuracy: 0.4400 - val_loss: 1.0059\n",
            "Epoch 143/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.4966 - loss: 0.9990 - val_accuracy: 0.4000 - val_loss: 1.0100\n",
            "Epoch 144/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.5415 - loss: 0.9370 - val_accuracy: 0.4000 - val_loss: 1.0185\n",
            "Epoch 145/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.5406 - loss: 0.9260 - val_accuracy: 0.4000 - val_loss: 1.0161\n",
            "Epoch 146/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5679 - loss: 0.9626 - val_accuracy: 0.4400 - val_loss: 1.0041\n",
            "Epoch 147/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5288 - loss: 0.9570 - val_accuracy: 0.4400 - val_loss: 0.9994\n",
            "Epoch 148/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5337 - loss: 0.8805 - val_accuracy: 0.4000 - val_loss: 1.0022\n",
            "Epoch 149/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5249 - loss: 0.9587 - val_accuracy: 0.4000 - val_loss: 0.9955\n",
            "Epoch 150/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5308 - loss: 0.9762 - val_accuracy: 0.4400 - val_loss: 0.9936\n",
            "Epoch 151/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5552 - loss: 0.9041 - val_accuracy: 0.4000 - val_loss: 0.9889\n",
            "Epoch 152/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5630 - loss: 0.9467 - val_accuracy: 0.4000 - val_loss: 0.9943\n",
            "Epoch 153/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5112 - loss: 0.9619 - val_accuracy: 0.4000 - val_loss: 0.9890\n",
            "Epoch 154/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5689 - loss: 0.9244 - val_accuracy: 0.4000 - val_loss: 0.9877\n",
            "Epoch 155/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.4770 - loss: 0.9679 - val_accuracy: 0.3600 - val_loss: 1.0020\n",
            "Epoch 156/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6178 - loss: 0.9128 - val_accuracy: 0.3600 - val_loss: 1.0220\n",
            "Epoch 157/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5591 - loss: 0.9237 - val_accuracy: 0.3600 - val_loss: 1.0239\n",
            "Epoch 158/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5367 - loss: 0.9519 - val_accuracy: 0.3600 - val_loss: 1.0230\n",
            "Epoch 159/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5924 - loss: 0.9251 - val_accuracy: 0.4000 - val_loss: 1.0046\n",
            "Epoch 160/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5513 - loss: 0.9495 - val_accuracy: 0.4000 - val_loss: 1.0025\n",
            "Epoch 161/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5288 - loss: 0.9128 - val_accuracy: 0.3600 - val_loss: 1.0148\n",
            "Epoch 162/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.5914 - loss: 0.9705 - val_accuracy: 0.3200 - val_loss: 1.0181\n",
            "Epoch 163/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5718 - loss: 0.9419 - val_accuracy: 0.3600 - val_loss: 1.0171\n",
            "Epoch 164/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.4810 - loss: 1.0048 - val_accuracy: 0.3200 - val_loss: 1.0180\n",
            "Epoch 165/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6011 - loss: 0.9113 - val_accuracy: 0.3600 - val_loss: 1.0067\n",
            "Epoch 166/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.4614 - loss: 1.0069 - val_accuracy: 0.4000 - val_loss: 0.9850\n",
            "Epoch 167/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.4496 - loss: 1.0099 - val_accuracy: 0.4400 - val_loss: 0.9801\n",
            "Epoch 168/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5572 - loss: 1.0051 - val_accuracy: 0.4400 - val_loss: 0.9754\n",
            "Epoch 169/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5621 - loss: 0.9144 - val_accuracy: 0.4000 - val_loss: 0.9816\n",
            "Epoch 170/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6139 - loss: 0.9516 - val_accuracy: 0.4000 - val_loss: 0.9939\n",
            "Epoch 171/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5689 - loss: 0.9553 - val_accuracy: 0.3200 - val_loss: 1.0318\n",
            "Epoch 172/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.4614 - loss: 0.9763 - val_accuracy: 0.3200 - val_loss: 1.0281\n",
            "Epoch 173/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5367 - loss: 0.9125 - val_accuracy: 0.4000 - val_loss: 1.0149\n",
            "Epoch 174/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5797 - loss: 0.9656 - val_accuracy: 0.4400 - val_loss: 1.0022\n",
            "Epoch 175/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5523 - loss: 0.9365 - val_accuracy: 0.3600 - val_loss: 0.9969\n",
            "Epoch 176/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6197 - loss: 0.8822 - val_accuracy: 0.3600 - val_loss: 1.0039\n",
            "Epoch 177/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.4966 - loss: 1.0018 - val_accuracy: 0.4000 - val_loss: 1.0100\n",
            "Epoch 178/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5611 - loss: 0.9108 - val_accuracy: 0.3600 - val_loss: 1.0124\n",
            "Epoch 179/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5836 - loss: 0.9746 - val_accuracy: 0.3600 - val_loss: 1.0126\n",
            "Epoch 180/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.4888 - loss: 1.0041 - val_accuracy: 0.3600 - val_loss: 1.0155\n",
            "Epoch 181/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5396 - loss: 0.9662 - val_accuracy: 0.3600 - val_loss: 1.0191\n",
            "Epoch 182/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5601 - loss: 0.9609 - val_accuracy: 0.4000 - val_loss: 1.0166\n",
            "Epoch 183/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4858 - loss: 0.9537 - val_accuracy: 0.4000 - val_loss: 0.9937\n",
            "Epoch 184/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.5347 - loss: 0.9103 - val_accuracy: 0.4000 - val_loss: 0.9834\n",
            "Epoch 185/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.5112 - loss: 0.9545 - val_accuracy: 0.4000 - val_loss: 0.9951\n",
            "Epoch 186/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6002 - loss: 0.8994 - val_accuracy: 0.4000 - val_loss: 0.9973\n",
            "Epoch 187/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5904 - loss: 0.9062 - val_accuracy: 0.3600 - val_loss: 0.9987\n",
            "Epoch 188/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6100 - loss: 0.8958 - val_accuracy: 0.3600 - val_loss: 0.9843\n",
            "Epoch 189/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5953 - loss: 0.9684 - val_accuracy: 0.3600 - val_loss: 0.9829\n",
            "Epoch 190/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5806 - loss: 0.9097 - val_accuracy: 0.4000 - val_loss: 0.9788\n",
            "Epoch 191/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5288 - loss: 0.9243 - val_accuracy: 0.4000 - val_loss: 0.9721\n",
            "Epoch 192/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4986 - loss: 0.9344 - val_accuracy: 0.3600 - val_loss: 0.9769\n",
            "Epoch 193/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6100 - loss: 0.9008 - val_accuracy: 0.3600 - val_loss: 0.9779\n",
            "Epoch 194/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5044 - loss: 0.9108 - val_accuracy: 0.4000 - val_loss: 0.9696\n",
            "Epoch 195/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5963 - loss: 0.9156 - val_accuracy: 0.4000 - val_loss: 0.9703\n",
            "Epoch 196/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5347 - loss: 0.9628 - val_accuracy: 0.4400 - val_loss: 0.9673\n",
            "Epoch 197/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.4780 - loss: 0.9706 - val_accuracy: 0.3600 - val_loss: 0.9874\n",
            "Epoch 198/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5611 - loss: 0.9041 - val_accuracy: 0.3200 - val_loss: 1.0097\n",
            "Epoch 199/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5650 - loss: 0.8839 - val_accuracy: 0.3200 - val_loss: 1.0041\n",
            "Epoch 200/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5190 - loss: 0.9056 - val_accuracy: 0.4000 - val_loss: 0.9877\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
            "Accuracy: 0.64\n",
            "Precision: 0.6433406593406593\n",
            "Recall: 0.64\n",
            "F1 Score: 0.6375757575757575\n",
            "AUC (Keras): 0.8738832\n"
          ]
        }
      ]
    }
  ]
}