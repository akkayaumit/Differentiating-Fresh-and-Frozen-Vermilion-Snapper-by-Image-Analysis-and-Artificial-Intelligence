{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "kkWt_4vVENns"
      },
      "outputs": [],
      "source": [
        "# for loading/processing the images\n",
        "from keras.preprocessing.image import load_img\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "\n",
        "# models\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.models import Model\n",
        "\n",
        "# clustering and dimension reduction\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# for everything else\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from random import randint\n",
        "import pandas as pd\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Python version\n",
        "import sys\n",
        "print(f\"Python version: {sys.version}\")\n",
        "\n",
        "# Check TensorFlow version\n",
        "import tensorflow as tf\n",
        "print(f\"TensorFlow version: {tf.__version__}\")\n",
        "\n",
        "# Check Keras version\n",
        "import keras\n",
        "print(f\"Keras version: {keras.__version__}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GtQZhRCuF792",
        "outputId": "66c16057-081a-443a-cf40-e1b32f428344"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python version: 3.10.12 (main, Sep 11 2024, 15:47:36) [GCC 11.4.0]\n",
            "TensorFlow version: 2.17.0\n",
            "Keras version: 3.4.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Dosyaların Drive dan alınması\n",
        "path = r\"/content/drive/MyDrive/CorrectedAll\"\n",
        "\n",
        "# change the working directory to the path where the images are located\n",
        "os.chdir(path)\n",
        "\n",
        "# this list holds all the image filename\n",
        "flowers = []\n",
        "\n",
        "# creates a ScandirIterator aliased as files\n",
        "with os.scandir(path) as files:\n",
        "  # loops through each file in the directory\n",
        "    for file in files:\n",
        "        if file.name.endswith('.jpg'):\n",
        "          # adds only the image files to the flowers list\n",
        "            flowers.append(file.name)"
      ],
      "metadata": {
        "id": "FHp9G3edGCf_"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# removing faulty images\n",
        "strings_to_remove = {'F20T1_102Left_CorrectedImage.jpg', 'F20T3-201Left_CorrectedImage.jpg'}\n",
        "\n",
        "flowers = list(filter(lambda x: x not in strings_to_remove, flowers))"
      ],
      "metadata": {
        "id": "GqXxltdqGSRG"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# extracting features from images using Transfer Learning\n",
        "model = VGG16()\n",
        "model = Model(inputs = model.inputs, outputs = model.layers[-2].output)\n",
        "\n",
        "def extract_features(file, model):\n",
        "\n",
        "    #crop images resize and load\n",
        "    img = load_img(file)\n",
        "    img = img.crop((0,0,img.size[0],img.size[1]-220))\n",
        "    img = img.resize((224,224))\n",
        "\n",
        "\n",
        "    # convert from image to numpy array\n",
        "    img = np.array(img)\n",
        "    # reshape the data for the model reshape(num_of_samples, dim 1, dim 2, channels)\n",
        "    reshaped_img = img.reshape(1,224,224,3)\n",
        "    # prepare image for model\n",
        "    imgx = preprocess_input(reshaped_img)\n",
        "    # get the feature vector\n",
        "    features = model.predict(imgx)\n",
        "    return features"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jgZe3l4IGcIF",
        "outputId": "a079dbf3-a9d7-4747-9ed5-73c46747e7c2"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n",
            "\u001b[1m553467096/553467096\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# rigth, left for two-class classification\n",
        "def get_label(flower):\n",
        "    if 'ight' in flower:\n",
        "        return '0'\n",
        "    elif 'eft' in flower:\n",
        "        return '1'\n",
        "    else:\n",
        "        return '7'\n",
        "\n",
        "# Create the DataFrame\n",
        "df = pd.DataFrame({'file': flowers})\n",
        "df['label'] = df['file'].apply(get_label)"
      ],
      "metadata": {
        "id": "GO0iHyjdI515"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# assigning Labels to Images\n",
        "def get_label(flower):\n",
        "    if 'Fresh' in flower:\n",
        "        return '2'\n",
        "    elif 'F20T1' in flower:\n",
        "        return '0'\n",
        "    elif 'F20T2' in flower:\n",
        "        return '0'\n",
        "    elif 'F20T3' in flower:\n",
        "        return '0'\n",
        "    elif 'F60T1' in flower:\n",
        "        return '1'\n",
        "    elif 'F60-T1' in flower:\n",
        "        return '1'\n",
        "    elif 'F60T2' in flower:\n",
        "        return '1'\n",
        "    elif 'F60T3' in flower:\n",
        "        return '1'\n",
        "    else:\n",
        "        return '7'\n",
        "\n",
        "# create the DataFrame\n",
        "df = pd.DataFrame({'file': flowers})\n",
        "df['label'] = df['file'].apply(get_label)"
      ],
      "metadata": {
        "id": "CG1t85KJJ3HP"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = df['label'].tolist()"
      ],
      "metadata": {
        "id": "D3mK1dbCMEaL"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Count the number of elements in each class\n",
        "class_counts = df['label'].value_counts()\n",
        "\n",
        "print(class_counts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cOfIS1s2KKBf",
        "outputId": "3fd49733-006b-4c6e-8172-a115fd00de09"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "label\n",
            "0    62\n",
            "1    61\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# extracting features from images using Transfer Learning\n",
        "data = {}\n",
        "\n",
        "for flower in flowers:\n",
        "  feat = extract_features(flower,model)\n",
        "  data[flower] = feat"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "0XymWX29KT2e",
        "outputId": "dd2c9f56-ef54-47ee-c3d0-c875d7557c93"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 936ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 549ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 547ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 536ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 597ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 566ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 621ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 529ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 537ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 525ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 638ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 917ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 873ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 530ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 536ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 539ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 544ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 528ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 533ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 645ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 547ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 558ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 554ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 668ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 958ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 921ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 537ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 539ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 544ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 537ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 541ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 548ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 566ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 556ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 530ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 530ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 886ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 635ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 567ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 530ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 564ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 540ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 556ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 539ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 539ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 546ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 539ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 816ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 924ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 897ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 714ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 538ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 523ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 532ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 534ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 547ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 522ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 544ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 525ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 587ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 788ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 973ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 880ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 531ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 528ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 532ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 534ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 547ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 553ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 541ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 553ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 539ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 540ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 964ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 982ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step   \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 542ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 525ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 845ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 521ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 524ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 640ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 542ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 529ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 548ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 544ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 972ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 895ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 999ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 801ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 537ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 675ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 544ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 530ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 530ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 551ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 739ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 576ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 860ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 665ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 523ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 544ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 521ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 524ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 530ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 524ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 518ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 547ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 537ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 585ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 967ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 856ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 654ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 549ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 545ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 537ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 539ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 522ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 571ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# put the extracted features together in an array\n",
        "filenames = np.array(list(data.keys()))\n",
        "\n",
        "feat = np.array(list(data.values()))\n",
        "\n",
        "feat = feat.reshape(-1,4096)"
      ],
      "metadata": {
        "id": "0mo8g7w9Ksd1"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# obtaining PCA components\n",
        "pca = PCA(n_components=3, random_state=22)\n",
        "pca.fit(feat)\n",
        "x = pca.transform(feat)"
      ],
      "metadata": {
        "id": "w9d500EvLCNt"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# to be used when any class needs to be removed\n",
        "labels_array = np.array(labels)\n",
        "\n",
        "indices_to_keep = labels_array != '2'\n",
        "\n",
        "filtered_features = x[indices_to_keep]\n",
        "labels = labels_array[indices_to_keep]"
      ],
      "metadata": {
        "id": "5X8HWJFkNYWZ"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cndB8ZV2ToeO",
        "outputId": "184afc7d-559a-4dc1-d769-59e3d392216b"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(123,)"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hnWi-v0sTJAX",
        "outputId": "6048c002-db82-4e02-9431-cf2c927b9d3e"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(123, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x1 = filtered_features[:, 0]\n",
        "y = filtered_features[:, 1]\n",
        "z = filtered_features[:, 2]\n",
        "\n",
        "unique_labels = sorted(set(labels))\n",
        "custom_label_names = [\"Frozen (-20)\", \"Frozen (-60)\"]  # Customize these names as needed\n",
        "custom_colors = [\"blue\", \"orange\"]\n",
        "custom_markers = [\"o\", \"^\"]  # Customize these markers as needed\n",
        "\n",
        "fig = plt.figure(figsize=(16, 8))\n",
        "\n",
        "# Second subplot: 2D scatter plot for comparison\n",
        "ax2 = fig.add_subplot(122)  # 1 row, 2 columns, second subplot\n",
        "for label, custom_name, color, marker in zip(unique_labels, custom_label_names, custom_colors, custom_markers):\n",
        "    indices = [i for i, l in enumerate(labels) if l == label]\n",
        "    ax2.scatter(x1[indices], y[indices], label=custom_name, color=color, marker=marker)\n",
        "\n",
        "ax2.set_title('2D Scatter Plot of Data with Labels')\n",
        "ax2.set_xlabel('PC 1')\n",
        "ax2.set_ylabel('PC 2')\n",
        "ax2.legend()\n",
        "\n",
        "\n",
        "#plt.subplots_adjust(left=0.1, right=0.9, top=0.9, bottom=0.1, wspace=0.4, hspace=0.4)\n",
        "plt.tight_layout()\n",
        "\n",
        "# Save the plot as a PNG file\n",
        "#file_name = '/content/drive/MyDrive/FishQuality_images/scatter_plots_20_60.png'\n",
        "#plt.savefig(file_name, format='png', dpi=300)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "qWa2lEMFLWx8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#2 class right left classification\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from keras.utils import to_categorical\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_curve, roc_auc_score\n",
        "from keras.models import Sequential, load_model\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Assuming x_train, y_train are available from the previous code\n",
        "\n",
        "# Convert labels to integers using LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "y_train_encoded = label_encoder.fit_transform(labels)\n",
        "y_train_categorical = to_categorical(y_train_encoded)\n",
        "\n",
        "# Split the data into training and validation sets\n",
        "#x_train, x_test, y_train_cat, y_test = train_test_split(feat, y_train_categorical, test_size=0.2, random_state=42)\n",
        "#x_train, x_val, y_train_cat, y_val_cat = train_test_split(x_train, y_train_cat, test_size=0.25, random_state=42)\n",
        "\n",
        "x_train, x_test, y_train_cat, y_test = train_test_split(feat, y_train_categorical, test_size=0.2, random_state=15)\n",
        "x_train, x_val, y_train_cat, y_val_cat = train_test_split(x_train, y_train_cat, test_size=0.25, random_state=15)\n",
        "\n",
        "\n",
        "# Build the neural network model\n",
        "model = Sequential()\n",
        "# pca 3 ile yapılınca alınan sonuç için\n",
        "#model.add(Dense(64, input_dim=3, activation='relu'))\n",
        "model.add(Dense(64, input_dim=4096, activation='relu'))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(16, activation='relu'))\n",
        "model.add(Dense(len(label_encoder.classes_), activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Define early stopping criteria\n",
        "#early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "checkpoint_path = \"/content/drive/MyDrive/CorrectedAll/2Class_best_model_with_testdata_RightvsLeft_2.h5\"\n",
        "checkpoint = ModelCheckpoint(checkpoint_path, monitor='val_accuracy', save_best_only=True, mode='max')\n",
        "\n",
        "# Train the model with early stopping\n",
        "model.fit(x_train, y_train_cat, epochs=200, batch_size=32, validation_data=(x_val, y_val_cat), callbacks=[checkpoint])\n",
        "\n",
        "model.load_weights(\"/content/drive/MyDrive/CorrectedAll/2Class_best_model_with_testdata_RightvsLeft_2.h5\")\n",
        "# Predict on the test data\n",
        "predicted_probabilities = model.predict(x_test)\n",
        "predicted_labels = np.argmax(predicted_probabilities, axis=1)\n",
        "predicted_labels_original = label_encoder.inverse_transform(predicted_labels)\n",
        "\n",
        "# Convert y_val_cat back to class labels\n",
        "y_val_labels = np.argmax(y_test, axis=1)\n",
        "y_val_labels_original = label_encoder.inverse_transform(y_val_labels)\n",
        "\n",
        "# Calculate and print accuracy, precision, recall, and F1 score\n",
        "accuracy = accuracy_score(y_val_labels_original, predicted_labels_original)\n",
        "precision = precision_score(y_val_labels_original, predicted_labels_original, average='weighted')\n",
        "recall = recall_score(y_val_labels_original, predicted_labels_original, average='weighted')\n",
        "f1 = f1_score(y_val_labels_original, predicted_labels_original, average='weighted')\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1 Score:\", f1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ol39JnCkLH_m",
        "outputId": "574541e0-c385-4ead-c461-17c722661acd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "1/3 [=========>....................] - ETA: 2s - loss: 0.7204 - accuracy: 0.5312"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 2s 434ms/step - loss: 0.6901 - accuracy: 0.5616 - val_loss: 0.5848 - val_accuracy: 0.6800\n",
            "Epoch 2/200\n",
            "3/3 [==============================] - 0s 44ms/step - loss: 0.5529 - accuracy: 0.7945 - val_loss: 0.5016 - val_accuracy: 0.7200\n",
            "Epoch 3/200\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.3732 - accuracy: 0.7671 - val_loss: 0.4190 - val_accuracy: 0.6800\n",
            "Epoch 4/200\n",
            "3/3 [==============================] - 0s 56ms/step - loss: 0.2457 - accuracy: 0.8630 - val_loss: 0.2737 - val_accuracy: 0.8800\n",
            "Epoch 5/200\n",
            "3/3 [==============================] - 0s 52ms/step - loss: 0.1546 - accuracy: 0.9589 - val_loss: 0.1627 - val_accuracy: 0.9600\n",
            "Epoch 6/200\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 0.0823 - accuracy: 1.0000 - val_loss: 0.1435 - val_accuracy: 0.9200\n",
            "Epoch 7/200\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.0538 - accuracy: 1.0000 - val_loss: 0.0864 - val_accuracy: 0.9600\n",
            "Epoch 8/200\n",
            "3/3 [==============================] - 0s 48ms/step - loss: 0.0297 - accuracy: 1.0000 - val_loss: 0.0621 - val_accuracy: 1.0000\n",
            "Epoch 9/200\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 0.0180 - accuracy: 1.0000 - val_loss: 0.0464 - val_accuracy: 1.0000\n",
            "Epoch 10/200\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 0.0419 - val_accuracy: 1.0000\n",
            "Epoch 11/200\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 0.0349 - val_accuracy: 1.0000\n",
            "Epoch 12/200\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.0398 - val_accuracy: 1.0000\n",
            "Epoch 13/200\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 0.0324 - val_accuracy: 1.0000\n",
            "Epoch 14/200\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0199 - val_accuracy: 1.0000\n",
            "Epoch 15/200\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0309 - val_accuracy: 1.0000\n",
            "Epoch 16/200\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0426 - val_accuracy: 1.0000\n",
            "Epoch 17/200\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0296 - val_accuracy: 1.0000\n",
            "Epoch 18/200\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0169 - val_accuracy: 1.0000\n",
            "Epoch 19/200\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 8.4677e-04 - accuracy: 1.0000 - val_loss: 0.0151 - val_accuracy: 1.0000\n",
            "Epoch 20/200\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 8.7942e-04 - accuracy: 1.0000 - val_loss: 0.0162 - val_accuracy: 1.0000\n",
            "Epoch 21/200\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 9.2968e-04 - accuracy: 1.0000 - val_loss: 0.0151 - val_accuracy: 1.0000\n",
            "Epoch 22/200\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 8.3137e-04 - accuracy: 1.0000 - val_loss: 0.0135 - val_accuracy: 1.0000\n",
            "Epoch 23/200\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 6.5912e-04 - accuracy: 1.0000 - val_loss: 0.0126 - val_accuracy: 1.0000\n",
            "Epoch 24/200\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 5.5352e-04 - accuracy: 1.0000 - val_loss: 0.0126 - val_accuracy: 1.0000\n",
            "Epoch 25/200\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 4.9547e-04 - accuracy: 1.0000 - val_loss: 0.0132 - val_accuracy: 1.0000\n",
            "Epoch 26/200\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 4.7162e-04 - accuracy: 1.0000 - val_loss: 0.0140 - val_accuracy: 1.0000\n",
            "Epoch 27/200\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 4.7019e-04 - accuracy: 1.0000 - val_loss: 0.0147 - val_accuracy: 1.0000\n",
            "Epoch 28/200\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 4.6398e-04 - accuracy: 1.0000 - val_loss: 0.0148 - val_accuracy: 1.0000\n",
            "Epoch 29/200\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 4.3273e-04 - accuracy: 1.0000 - val_loss: 0.0143 - val_accuracy: 1.0000\n",
            "Epoch 30/200\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 3.9867e-04 - accuracy: 1.0000 - val_loss: 0.0133 - val_accuracy: 1.0000\n",
            "Epoch 31/200\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 3.6623e-04 - accuracy: 1.0000 - val_loss: 0.0126 - val_accuracy: 1.0000\n",
            "Epoch 32/200\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 3.3050e-04 - accuracy: 1.0000 - val_loss: 0.0121 - val_accuracy: 1.0000\n",
            "Epoch 33/200\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 3.1383e-04 - accuracy: 1.0000 - val_loss: 0.0115 - val_accuracy: 1.0000\n",
            "Epoch 34/200\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 2.9719e-04 - accuracy: 1.0000 - val_loss: 0.0112 - val_accuracy: 1.0000\n",
            "Epoch 35/200\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 2.7891e-04 - accuracy: 1.0000 - val_loss: 0.0110 - val_accuracy: 1.0000\n",
            "Epoch 36/200\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 2.6095e-04 - accuracy: 1.0000 - val_loss: 0.0109 - val_accuracy: 1.0000\n",
            "Epoch 37/200\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 2.4319e-04 - accuracy: 1.0000 - val_loss: 0.0108 - val_accuracy: 1.0000\n",
            "Epoch 38/200\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 2.2722e-04 - accuracy: 1.0000 - val_loss: 0.0104 - val_accuracy: 1.0000\n",
            "Epoch 39/200\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 2.1101e-04 - accuracy: 1.0000 - val_loss: 0.0101 - val_accuracy: 1.0000\n",
            "Epoch 40/200\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 1.9596e-04 - accuracy: 1.0000 - val_loss: 0.0099 - val_accuracy: 1.0000\n",
            "Epoch 41/200\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 1.8306e-04 - accuracy: 1.0000 - val_loss: 0.0096 - val_accuracy: 1.0000\n",
            "Epoch 42/200\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 1.7172e-04 - accuracy: 1.0000 - val_loss: 0.0093 - val_accuracy: 1.0000\n",
            "Epoch 43/200\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 1.6130e-04 - accuracy: 1.0000 - val_loss: 0.0091 - val_accuracy: 1.0000\n",
            "Epoch 44/200\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 1.5224e-04 - accuracy: 1.0000 - val_loss: 0.0088 - val_accuracy: 1.0000\n",
            "Epoch 45/200\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 1.4327e-04 - accuracy: 1.0000 - val_loss: 0.0085 - val_accuracy: 1.0000\n",
            "Epoch 46/200\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 1.3535e-04 - accuracy: 1.0000 - val_loss: 0.0083 - val_accuracy: 1.0000\n",
            "Epoch 47/200\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 1.2845e-04 - accuracy: 1.0000 - val_loss: 0.0081 - val_accuracy: 1.0000\n",
            "Epoch 48/200\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 1.2162e-04 - accuracy: 1.0000 - val_loss: 0.0079 - val_accuracy: 1.0000\n",
            "Epoch 49/200\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 1.1511e-04 - accuracy: 1.0000 - val_loss: 0.0078 - val_accuracy: 1.0000\n",
            "Epoch 50/200\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 1.0970e-04 - accuracy: 1.0000 - val_loss: 0.0077 - val_accuracy: 1.0000\n",
            "Epoch 51/200\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 1.0431e-04 - accuracy: 1.0000 - val_loss: 0.0076 - val_accuracy: 1.0000\n",
            "Epoch 52/200\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 9.9823e-05 - accuracy: 1.0000 - val_loss: 0.0075 - val_accuracy: 1.0000\n",
            "Epoch 53/200\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 9.5708e-05 - accuracy: 1.0000 - val_loss: 0.0074 - val_accuracy: 1.0000\n",
            "Epoch 54/200\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 9.2176e-05 - accuracy: 1.0000 - val_loss: 0.0073 - val_accuracy: 1.0000\n",
            "Epoch 55/200\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 8.9301e-05 - accuracy: 1.0000 - val_loss: 0.0071 - val_accuracy: 1.0000\n",
            "Epoch 56/200\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 8.6293e-05 - accuracy: 1.0000 - val_loss: 0.0070 - val_accuracy: 1.0000\n",
            "Epoch 57/200\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 8.3448e-05 - accuracy: 1.0000 - val_loss: 0.0070 - val_accuracy: 1.0000\n",
            "Epoch 58/200\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 8.0828e-05 - accuracy: 1.0000 - val_loss: 0.0070 - val_accuracy: 1.0000\n",
            "Epoch 59/200\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 7.8879e-05 - accuracy: 1.0000 - val_loss: 0.0070 - val_accuracy: 1.0000\n",
            "Epoch 60/200\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 7.6388e-05 - accuracy: 1.0000 - val_loss: 0.0069 - val_accuracy: 1.0000\n",
            "Epoch 61/200\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 7.4104e-05 - accuracy: 1.0000 - val_loss: 0.0068 - val_accuracy: 1.0000\n",
            "Epoch 62/200\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 7.1732e-05 - accuracy: 1.0000 - val_loss: 0.0066 - val_accuracy: 1.0000\n",
            "Epoch 63/200\n",
            "3/3 [==============================] - 0s 39ms/step - loss: 6.9789e-05 - accuracy: 1.0000 - val_loss: 0.0064 - val_accuracy: 1.0000\n",
            "Epoch 64/200\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 6.8153e-05 - accuracy: 1.0000 - val_loss: 0.0063 - val_accuracy: 1.0000\n",
            "Epoch 65/200\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 6.6109e-05 - accuracy: 1.0000 - val_loss: 0.0061 - val_accuracy: 1.0000\n",
            "Epoch 66/200\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 6.4596e-05 - accuracy: 1.0000 - val_loss: 0.0061 - val_accuracy: 1.0000\n",
            "Epoch 67/200\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 6.2804e-05 - accuracy: 1.0000 - val_loss: 0.0060 - val_accuracy: 1.0000\n",
            "Epoch 68/200\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 6.1139e-05 - accuracy: 1.0000 - val_loss: 0.0060 - val_accuracy: 1.0000\n",
            "Epoch 69/200\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 5.9555e-05 - accuracy: 1.0000 - val_loss: 0.0060 - val_accuracy: 1.0000\n",
            "Epoch 70/200\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 5.8192e-05 - accuracy: 1.0000 - val_loss: 0.0059 - val_accuracy: 1.0000\n",
            "Epoch 71/200\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 5.6737e-05 - accuracy: 1.0000 - val_loss: 0.0059 - val_accuracy: 1.0000\n",
            "Epoch 72/200\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 5.5479e-05 - accuracy: 1.0000 - val_loss: 0.0058 - val_accuracy: 1.0000\n",
            "Epoch 73/200\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 5.4168e-05 - accuracy: 1.0000 - val_loss: 0.0057 - val_accuracy: 1.0000\n",
            "Epoch 74/200\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 5.2968e-05 - accuracy: 1.0000 - val_loss: 0.0055 - val_accuracy: 1.0000\n",
            "Epoch 75/200\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 5.2065e-05 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 1.0000\n",
            "Epoch 76/200\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 5.1405e-05 - accuracy: 1.0000 - val_loss: 0.0053 - val_accuracy: 1.0000\n",
            "Epoch 77/200\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 5.0299e-05 - accuracy: 1.0000 - val_loss: 0.0053 - val_accuracy: 1.0000\n",
            "Epoch 78/200\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 4.9060e-05 - accuracy: 1.0000 - val_loss: 0.0053 - val_accuracy: 1.0000\n",
            "Epoch 79/200\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 4.7622e-05 - accuracy: 1.0000 - val_loss: 0.0053 - val_accuracy: 1.0000\n",
            "Epoch 80/200\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 4.6550e-05 - accuracy: 1.0000 - val_loss: 0.0053 - val_accuracy: 1.0000\n",
            "Epoch 81/200\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 4.5239e-05 - accuracy: 1.0000 - val_loss: 0.0053 - val_accuracy: 1.0000\n",
            "Epoch 82/200\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 4.4263e-05 - accuracy: 1.0000 - val_loss: 0.0053 - val_accuracy: 1.0000\n",
            "Epoch 83/200\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 4.3265e-05 - accuracy: 1.0000 - val_loss: 0.0053 - val_accuracy: 1.0000\n",
            "Epoch 84/200\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 4.2369e-05 - accuracy: 1.0000 - val_loss: 0.0053 - val_accuracy: 1.0000\n",
            "Epoch 85/200\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 4.1226e-05 - accuracy: 1.0000 - val_loss: 0.0052 - val_accuracy: 1.0000\n",
            "Epoch 86/200\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 4.0650e-05 - accuracy: 1.0000 - val_loss: 0.0050 - val_accuracy: 1.0000\n",
            "Epoch 87/200\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 3.9649e-05 - accuracy: 1.0000 - val_loss: 0.0049 - val_accuracy: 1.0000\n",
            "Epoch 88/200\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 3.8801e-05 - accuracy: 1.0000 - val_loss: 0.0049 - val_accuracy: 1.0000\n",
            "Epoch 89/200\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 3.8009e-05 - accuracy: 1.0000 - val_loss: 0.0048 - val_accuracy: 1.0000\n",
            "Epoch 90/200\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 3.7322e-05 - accuracy: 1.0000 - val_loss: 0.0048 - val_accuracy: 1.0000\n",
            "Epoch 91/200\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 3.6520e-05 - accuracy: 1.0000 - val_loss: 0.0048 - val_accuracy: 1.0000\n",
            "Epoch 92/200\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 3.5662e-05 - accuracy: 1.0000 - val_loss: 0.0048 - val_accuracy: 1.0000\n",
            "Epoch 93/200\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 3.5077e-05 - accuracy: 1.0000 - val_loss: 0.0048 - val_accuracy: 1.0000\n",
            "Epoch 94/200\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 3.4228e-05 - accuracy: 1.0000 - val_loss: 0.0048 - val_accuracy: 1.0000\n",
            "Epoch 95/200\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 3.3361e-05 - accuracy: 1.0000 - val_loss: 0.0048 - val_accuracy: 1.0000\n",
            "Epoch 96/200\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 3.2847e-05 - accuracy: 1.0000 - val_loss: 0.0048 - val_accuracy: 1.0000\n",
            "Epoch 97/200\n",
            "3/3 [==============================] - 0s 38ms/step - loss: 3.2168e-05 - accuracy: 1.0000 - val_loss: 0.0048 - val_accuracy: 1.0000\n",
            "Epoch 98/200\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 3.1435e-05 - accuracy: 1.0000 - val_loss: 0.0048 - val_accuracy: 1.0000\n",
            "Epoch 99/200\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 3.0806e-05 - accuracy: 1.0000 - val_loss: 0.0047 - val_accuracy: 1.0000\n",
            "Epoch 100/200\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 3.0275e-05 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 1.0000\n",
            "Epoch 101/200\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 2.9691e-05 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 1.0000\n",
            "Epoch 102/200\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 2.9134e-05 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 1.0000\n",
            "Epoch 103/200\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 2.8599e-05 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 1.0000\n",
            "Epoch 104/200\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 2.8097e-05 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 1.0000\n",
            "Epoch 105/200\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 2.7565e-05 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 1.0000\n",
            "Epoch 106/200\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 2.7106e-05 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 1.0000\n",
            "Epoch 107/200\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 2.6847e-05 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 1.0000\n",
            "Epoch 108/200\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 2.6447e-05 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 1.0000\n",
            "Epoch 109/200\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 2.6042e-05 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 1.0000\n",
            "Epoch 110/200\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 2.5581e-05 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 1.0000\n",
            "Epoch 111/200\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 2.5194e-05 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 1.0000\n",
            "Epoch 112/200\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 2.4775e-05 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 1.0000\n",
            "Epoch 113/200\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 2.4319e-05 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 1.0000\n",
            "Epoch 114/200\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 2.3909e-05 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 1.0000\n",
            "Epoch 115/200\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 2.3569e-05 - accuracy: 1.0000 - val_loss: 0.0042 - val_accuracy: 1.0000\n",
            "Epoch 116/200\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 2.3142e-05 - accuracy: 1.0000 - val_loss: 0.0042 - val_accuracy: 1.0000\n",
            "Epoch 117/200\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 2.2810e-05 - accuracy: 1.0000 - val_loss: 0.0042 - val_accuracy: 1.0000\n",
            "Epoch 118/200\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 2.2454e-05 - accuracy: 1.0000 - val_loss: 0.0041 - val_accuracy: 1.0000\n",
            "Epoch 119/200\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 2.2155e-05 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
            "Epoch 120/200\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 2.1832e-05 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
            "Epoch 121/200\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 2.1527e-05 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
            "Epoch 122/200\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 2.1280e-05 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
            "Epoch 123/200\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 2.0962e-05 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
            "Epoch 124/200\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 2.0679e-05 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
            "Epoch 125/200\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 2.0354e-05 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
            "Epoch 126/200\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 2.0052e-05 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
            "Epoch 127/200\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 1.9806e-05 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
            "Epoch 128/200\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 1.9523e-05 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
            "Epoch 129/200\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 1.9280e-05 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
            "Epoch 130/200\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 1.9061e-05 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
            "Epoch 131/200\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 1.8803e-05 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
            "Epoch 132/200\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 1.8553e-05 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
            "Epoch 133/200\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 1.8258e-05 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 1.0000\n",
            "Epoch 134/200\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 1.7995e-05 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
            "Epoch 135/200\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 1.7724e-05 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
            "Epoch 136/200\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 1.7523e-05 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 1.0000\n",
            "Epoch 137/200\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 1.7275e-05 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 1.0000\n",
            "Epoch 138/200\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 1.7066e-05 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 1.0000\n",
            "Epoch 139/200\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 1.6862e-05 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 1.0000\n",
            "Epoch 140/200\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 1.6672e-05 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
            "Epoch 141/200\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 1.6458e-05 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
            "Epoch 142/200\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 1.6256e-05 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
            "Epoch 143/200\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 1.6040e-05 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
            "Epoch 144/200\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 1.5840e-05 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
            "Epoch 145/200\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 1.5648e-05 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
            "Epoch 146/200\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 1.5459e-05 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
            "Epoch 147/200\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 1.5291e-05 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
            "Epoch 148/200\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 1.5075e-05 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
            "Epoch 149/200\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 1.4881e-05 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
            "Epoch 150/200\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 1.4701e-05 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
            "Epoch 151/200\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 1.4517e-05 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
            "Epoch 152/200\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 1.4350e-05 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
            "Epoch 153/200\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 1.4184e-05 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
            "Epoch 154/200\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 1.4022e-05 - accuracy: 1.0000 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
            "Epoch 155/200\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 1.3877e-05 - accuracy: 1.0000 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
            "Epoch 156/200\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 1.3730e-05 - accuracy: 1.0000 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
            "Epoch 157/200\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 1.3576e-05 - accuracy: 1.0000 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
            "Epoch 158/200\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 1.3436e-05 - accuracy: 1.0000 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
            "Epoch 159/200\n",
            "3/3 [==============================] - 0s 41ms/step - loss: 1.3286e-05 - accuracy: 1.0000 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
            "Epoch 160/200\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 1.3144e-05 - accuracy: 1.0000 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
            "Epoch 161/200\n",
            "3/3 [==============================] - 0s 41ms/step - loss: 1.3002e-05 - accuracy: 1.0000 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
            "Epoch 162/200\n",
            "3/3 [==============================] - 0s 60ms/step - loss: 1.2861e-05 - accuracy: 1.0000 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
            "Epoch 163/200\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 1.2732e-05 - accuracy: 1.0000 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
            "Epoch 164/200\n",
            "3/3 [==============================] - 0s 37ms/step - loss: 1.2593e-05 - accuracy: 1.0000 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
            "Epoch 165/200\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 1.2489e-05 - accuracy: 1.0000 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
            "Epoch 166/200\n",
            "3/3 [==============================] - 0s 37ms/step - loss: 1.2365e-05 - accuracy: 1.0000 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
            "Epoch 167/200\n",
            "3/3 [==============================] - 0s 43ms/step - loss: 1.2229e-05 - accuracy: 1.0000 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
            "Epoch 168/200\n",
            "3/3 [==============================] - 0s 37ms/step - loss: 1.2102e-05 - accuracy: 1.0000 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
            "Epoch 169/200\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 1.1983e-05 - accuracy: 1.0000 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
            "Epoch 170/200\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 1.1876e-05 - accuracy: 1.0000 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
            "Epoch 171/200\n",
            "3/3 [==============================] - 0s 38ms/step - loss: 1.1769e-05 - accuracy: 1.0000 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
            "Epoch 172/200\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 1.1646e-05 - accuracy: 1.0000 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
            "Epoch 173/200\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 1.1520e-05 - accuracy: 1.0000 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
            "Epoch 174/200\n",
            "3/3 [==============================] - 0s 41ms/step - loss: 1.1391e-05 - accuracy: 1.0000 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
            "Epoch 175/200\n",
            "3/3 [==============================] - 0s 42ms/step - loss: 1.1280e-05 - accuracy: 1.0000 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
            "Epoch 176/200\n",
            "3/3 [==============================] - 0s 39ms/step - loss: 1.1163e-05 - accuracy: 1.0000 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
            "Epoch 177/200\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 1.1065e-05 - accuracy: 1.0000 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
            "Epoch 178/200\n",
            "3/3 [==============================] - 0s 37ms/step - loss: 1.0960e-05 - accuracy: 1.0000 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
            "Epoch 179/200\n",
            "3/3 [==============================] - 0s 42ms/step - loss: 1.0851e-05 - accuracy: 1.0000 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
            "Epoch 180/200\n",
            "3/3 [==============================] - 0s 37ms/step - loss: 1.0773e-05 - accuracy: 1.0000 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
            "Epoch 181/200\n",
            "3/3 [==============================] - 0s 43ms/step - loss: 1.0660e-05 - accuracy: 1.0000 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
            "Epoch 182/200\n",
            "3/3 [==============================] - 0s 37ms/step - loss: 1.0578e-05 - accuracy: 1.0000 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
            "Epoch 183/200\n",
            "3/3 [==============================] - 0s 42ms/step - loss: 1.0466e-05 - accuracy: 1.0000 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
            "Epoch 184/200\n",
            "3/3 [==============================] - 0s 37ms/step - loss: 1.0394e-05 - accuracy: 1.0000 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
            "Epoch 185/200\n",
            "3/3 [==============================] - 0s 38ms/step - loss: 1.0271e-05 - accuracy: 1.0000 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
            "Epoch 186/200\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 1.0190e-05 - accuracy: 1.0000 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
            "Epoch 187/200\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 1.0100e-05 - accuracy: 1.0000 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
            "Epoch 188/200\n",
            "3/3 [==============================] - 0s 38ms/step - loss: 1.0000e-05 - accuracy: 1.0000 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
            "Epoch 189/200\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 9.9154e-06 - accuracy: 1.0000 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
            "Epoch 190/200\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 9.8239e-06 - accuracy: 1.0000 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
            "Epoch 191/200\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 9.7292e-06 - accuracy: 1.0000 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
            "Epoch 192/200\n",
            "3/3 [==============================] - 0s 43ms/step - loss: 9.6394e-06 - accuracy: 1.0000 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
            "Epoch 193/200\n",
            "3/3 [==============================] - 0s 39ms/step - loss: 9.5626e-06 - accuracy: 1.0000 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
            "Epoch 194/200\n",
            "3/3 [==============================] - 0s 37ms/step - loss: 9.4761e-06 - accuracy: 1.0000 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
            "Epoch 195/200\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 9.4010e-06 - accuracy: 1.0000 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
            "Epoch 196/200\n",
            "3/3 [==============================] - 0s 40ms/step - loss: 9.3226e-06 - accuracy: 1.0000 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
            "Epoch 197/200\n",
            "3/3 [==============================] - 0s 45ms/step - loss: 9.2573e-06 - accuracy: 1.0000 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
            "Epoch 198/200\n",
            "3/3 [==============================] - 0s 41ms/step - loss: 9.1740e-06 - accuracy: 1.0000 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
            "Epoch 199/200\n",
            "3/3 [==============================] - 0s 38ms/step - loss: 9.0825e-06 - accuracy: 1.0000 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
            "Epoch 200/200\n",
            "3/3 [==============================] - 0s 37ms/step - loss: 9.0172e-06 - accuracy: 1.0000 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 74ms/step\n",
            "Accuracy: 0.96\n",
            "Precision: 0.9640000000000001\n",
            "Recall: 0.96\n",
            "F1 Score: 0.9604074702886248\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# creating confusion matrix\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "labels = [\"Fresh\", \"Frozen\"]\n",
        "\n",
        "cm = confusion_matrix(y_val_labels_original, predicted_labels_original)\n",
        "\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
        "\n",
        "disp.plot(cmap=plt.cm.Blues)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "tSwdM3XZSlcY",
        "outputId": "dda15022-13c4-44a7-d0cf-b245980cb17d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3 class classification\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from keras.utils import to_categorical\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Convert labels to integers using LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "y_train_encoded = label_encoder.fit_transform(labels)\n",
        "y_train_categorical = to_categorical(y_train_encoded)\n",
        "\n",
        "# Split the data into training and validation sets\n",
        "x_train, x_test, y_train_cat, y_test = train_test_split(feat, y_train_categorical, test_size=0.2, random_state=15)\n",
        "x_train, x_val, y_train_cat, y_val_cat = train_test_split(x_train, y_train_cat, test_size=0.25, random_state=15)\n",
        "\n",
        "# Build the neural network model\n",
        "model = Sequential()\n",
        "# Classification with L a b values\n",
        "#model.add(Dense(64, input_dim=3, activation='relu'))\n",
        "model.add(Dense(64, input_dim=4096, activation='relu'))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Dense(16, activation='relu'))\n",
        "model.add(Dense(len(label_encoder.classes_), activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Define early stopping criteria\n",
        "#early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "\n",
        "\n",
        "checkpoint_path = \"/content/drive/MyDrive/CorrectedAll/3Class_best_model_with_testdata3.h5\"\n",
        "checkpoint = ModelCheckpoint(checkpoint_path, monitor='val_accuracy', save_best_only=True, mode='max')\n",
        "\n",
        "# Train the model with early stopping\n",
        "model.fit(x_train, y_train_cat, epochs=200, batch_size=32, validation_data=(x_val, y_val_cat), callbacks=[checkpoint])\n",
        "\n",
        "\n",
        "model.load_weights(\"/content/drive/MyDrive/CorrectedAll/3Class_best_model_with_testdata3.h5\")\n",
        "# Predict on the test data\n",
        "predicted_probabilities = model.predict(x_test)\n",
        "predicted_labels = np.argmax(predicted_probabilities, axis=1)\n",
        "predicted_labels_original = label_encoder.inverse_transform(predicted_labels)\n",
        "\n",
        "# Convert y_val_cat back to class labels\n",
        "y_val_labels = np.argmax(y_test, axis=1)\n",
        "y_val_labels_original = label_encoder.inverse_transform(y_val_labels)\n",
        "\n",
        "# Calculate and print accuracy, precision, recall, and F1 score\n",
        "accuracy = accuracy_score(y_val_labels_original, predicted_labels_original)\n",
        "precision = precision_score(y_val_labels_original, predicted_labels_original, average='weighted')\n",
        "recall = recall_score(y_val_labels_original, predicted_labels_original, average='weighted')\n",
        "f1 = f1_score(y_val_labels_original, predicted_labels_original, average='weighted')\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1 Score:\", f1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cit06KOFM5_P",
        "outputId": "e74156bc-c5ba-48ea-fc89-b1fb7ab9f31f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "1/3 [=========>....................] - ETA: 3s - loss: 1.3656 - accuracy: 0.2500"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 3s 393ms/step - loss: 1.6919 - accuracy: 0.2466 - val_loss: 1.1485 - val_accuracy: 0.3200\n",
            "Epoch 2/200\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 1.3503 - accuracy: 0.3562 - val_loss: 1.1461 - val_accuracy: 0.2800\n",
            "Epoch 3/200\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 1.2764 - accuracy: 0.3836 - val_loss: 1.1478 - val_accuracy: 0.2800\n",
            "Epoch 4/200\n",
            "3/3 [==============================] - 0s 75ms/step - loss: 1.2220 - accuracy: 0.3562 - val_loss: 1.0782 - val_accuracy: 0.3600\n",
            "Epoch 5/200\n",
            "3/3 [==============================] - 0s 57ms/step - loss: 1.1075 - accuracy: 0.3699 - val_loss: 1.0049 - val_accuracy: 0.5600\n",
            "Epoch 6/200\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 1.1654 - accuracy: 0.3699 - val_loss: 1.0487 - val_accuracy: 0.4800\n",
            "Epoch 7/200\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 1.1177 - accuracy: 0.3288 - val_loss: 1.0677 - val_accuracy: 0.3200\n",
            "Epoch 8/200\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 1.1302 - accuracy: 0.3425 - val_loss: 1.0744 - val_accuracy: 0.3600\n",
            "Epoch 9/200\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 1.1360 - accuracy: 0.3151 - val_loss: 1.0493 - val_accuracy: 0.4000\n",
            "Epoch 10/200\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 1.0714 - accuracy: 0.4384 - val_loss: 1.0412 - val_accuracy: 0.4800\n",
            "Epoch 11/200\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 0.9983 - accuracy: 0.5068 - val_loss: 1.0264 - val_accuracy: 0.4400\n",
            "Epoch 12/200\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 1.0874 - accuracy: 0.4110 - val_loss: 0.9846 - val_accuracy: 0.4800\n",
            "Epoch 13/200\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 0.9460 - accuracy: 0.5068 - val_loss: 0.9115 - val_accuracy: 0.5600\n",
            "Epoch 14/200\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 0.9541 - accuracy: 0.5068 - val_loss: 0.8831 - val_accuracy: 0.5600\n",
            "Epoch 15/200\n",
            "3/3 [==============================] - 0s 71ms/step - loss: 0.9598 - accuracy: 0.4932 - val_loss: 0.8530 - val_accuracy: 0.6400\n",
            "Epoch 16/200\n",
            "3/3 [==============================] - 0s 51ms/step - loss: 0.8986 - accuracy: 0.5616 - val_loss: 0.8201 - val_accuracy: 0.7200\n",
            "Epoch 17/200\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 0.8799 - accuracy: 0.5068 - val_loss: 0.7910 - val_accuracy: 0.7200\n",
            "Epoch 18/200\n",
            "3/3 [==============================] - 0s 49ms/step - loss: 1.0073 - accuracy: 0.4521 - val_loss: 0.7474 - val_accuracy: 0.7600\n",
            "Epoch 19/200\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 0.8723 - accuracy: 0.4932 - val_loss: 0.6973 - val_accuracy: 0.7200\n",
            "Epoch 20/200\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.8302 - accuracy: 0.5753 - val_loss: 0.6611 - val_accuracy: 0.6800\n",
            "Epoch 21/200\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 0.7848 - accuracy: 0.6438 - val_loss: 0.6520 - val_accuracy: 0.7200\n",
            "Epoch 22/200\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 0.8137 - accuracy: 0.6027 - val_loss: 0.6515 - val_accuracy: 0.7200\n",
            "Epoch 23/200\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 0.7913 - accuracy: 0.6164 - val_loss: 0.6533 - val_accuracy: 0.7200\n",
            "Epoch 24/200\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 0.8129 - accuracy: 0.5616 - val_loss: 0.6221 - val_accuracy: 0.6800\n",
            "Epoch 25/200\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 0.7621 - accuracy: 0.6027 - val_loss: 0.6081 - val_accuracy: 0.6800\n",
            "Epoch 26/200\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.7244 - accuracy: 0.6301 - val_loss: 0.6101 - val_accuracy: 0.6800\n",
            "Epoch 27/200\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.6265 - accuracy: 0.6849 - val_loss: 0.6572 - val_accuracy: 0.6800\n",
            "Epoch 28/200\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.6779 - accuracy: 0.6301 - val_loss: 0.7055 - val_accuracy: 0.7200\n",
            "Epoch 29/200\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.7044 - accuracy: 0.6438 - val_loss: 0.6476 - val_accuracy: 0.7200\n",
            "Epoch 30/200\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.6124 - accuracy: 0.6712 - val_loss: 0.5542 - val_accuracy: 0.7200\n",
            "Epoch 31/200\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.7133 - accuracy: 0.5753 - val_loss: 0.5099 - val_accuracy: 0.7200\n",
            "Epoch 32/200\n",
            "3/3 [==============================] - 0s 46ms/step - loss: 0.7514 - accuracy: 0.6438 - val_loss: 0.4920 - val_accuracy: 0.8800\n",
            "Epoch 33/200\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 0.5575 - accuracy: 0.7671 - val_loss: 0.5221 - val_accuracy: 0.7600\n",
            "Epoch 34/200\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 0.6012 - accuracy: 0.7260 - val_loss: 0.5589 - val_accuracy: 0.6400\n",
            "Epoch 35/200\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 0.6608 - accuracy: 0.6438 - val_loss: 0.5063 - val_accuracy: 0.7600\n",
            "Epoch 36/200\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.6218 - accuracy: 0.6849 - val_loss: 0.4636 - val_accuracy: 0.8000\n",
            "Epoch 37/200\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 0.5017 - accuracy: 0.7534 - val_loss: 0.4510 - val_accuracy: 0.8400\n",
            "Epoch 38/200\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 0.5378 - accuracy: 0.7397 - val_loss: 0.4560 - val_accuracy: 0.8000\n",
            "Epoch 39/200\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 0.4834 - accuracy: 0.7260 - val_loss: 0.4735 - val_accuracy: 0.7600\n",
            "Epoch 40/200\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 0.5597 - accuracy: 0.7260 - val_loss: 0.4559 - val_accuracy: 0.8000\n",
            "Epoch 41/200\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 0.5899 - accuracy: 0.7671 - val_loss: 0.4285 - val_accuracy: 0.8000\n",
            "Epoch 42/200\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 0.4937 - accuracy: 0.7671 - val_loss: 0.4456 - val_accuracy: 0.7200\n",
            "Epoch 43/200\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.5610 - accuracy: 0.7397 - val_loss: 0.4459 - val_accuracy: 0.8000\n",
            "Epoch 44/200\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.5713 - accuracy: 0.6986 - val_loss: 0.5236 - val_accuracy: 0.7600\n",
            "Epoch 45/200\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.4782 - accuracy: 0.7808 - val_loss: 0.5106 - val_accuracy: 0.7600\n",
            "Epoch 46/200\n",
            "3/3 [==============================] - 0s 50ms/step - loss: 0.5066 - accuracy: 0.7808 - val_loss: 0.4170 - val_accuracy: 0.8000\n",
            "Epoch 47/200\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.4829 - accuracy: 0.8219 - val_loss: 0.3621 - val_accuracy: 0.8400\n",
            "Epoch 48/200\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 0.4497 - accuracy: 0.8493 - val_loss: 0.4189 - val_accuracy: 0.8000\n",
            "Epoch 49/200\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 0.5035 - accuracy: 0.7808 - val_loss: 0.4950 - val_accuracy: 0.7200\n",
            "Epoch 50/200\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 0.4445 - accuracy: 0.8219 - val_loss: 0.3889 - val_accuracy: 0.8400\n",
            "Epoch 51/200\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 0.4543 - accuracy: 0.7945 - val_loss: 0.3602 - val_accuracy: 0.8800\n",
            "Epoch 52/200\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 0.4275 - accuracy: 0.8219 - val_loss: 0.3623 - val_accuracy: 0.8800\n",
            "Epoch 53/200\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 0.4017 - accuracy: 0.7671 - val_loss: 0.3896 - val_accuracy: 0.8400\n",
            "Epoch 54/200\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 0.4298 - accuracy: 0.7671 - val_loss: 0.3973 - val_accuracy: 0.8000\n",
            "Epoch 55/200\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 0.4044 - accuracy: 0.8767 - val_loss: 0.3694 - val_accuracy: 0.8000\n",
            "Epoch 56/200\n",
            "3/3 [==============================] - 0s 89ms/step - loss: 0.3547 - accuracy: 0.8356 - val_loss: 0.3534 - val_accuracy: 0.8800\n",
            "Epoch 57/200\n",
            "3/3 [==============================] - 0s 136ms/step - loss: 0.3309 - accuracy: 0.8767 - val_loss: 0.3437 - val_accuracy: 0.8800\n",
            "Epoch 58/200\n",
            "3/3 [==============================] - 0s 80ms/step - loss: 0.3835 - accuracy: 0.8493 - val_loss: 0.3790 - val_accuracy: 0.8800\n",
            "Epoch 59/200\n",
            "3/3 [==============================] - 0s 47ms/step - loss: 0.2679 - accuracy: 0.9315 - val_loss: 0.4814 - val_accuracy: 0.8000\n",
            "Epoch 60/200\n",
            "3/3 [==============================] - 0s 61ms/step - loss: 0.3233 - accuracy: 0.8493 - val_loss: 0.4686 - val_accuracy: 0.7600\n",
            "Epoch 61/200\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.4198 - accuracy: 0.8219 - val_loss: 0.3817 - val_accuracy: 0.8400\n",
            "Epoch 62/200\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.3040 - accuracy: 0.8904 - val_loss: 0.4230 - val_accuracy: 0.8400\n",
            "Epoch 63/200\n",
            "3/3 [==============================] - 0s 40ms/step - loss: 0.3591 - accuracy: 0.8904 - val_loss: 0.3953 - val_accuracy: 0.8400\n",
            "Epoch 64/200\n",
            "3/3 [==============================] - 0s 42ms/step - loss: 0.3485 - accuracy: 0.8493 - val_loss: 0.5214 - val_accuracy: 0.8000\n",
            "Epoch 65/200\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 0.3017 - accuracy: 0.8630 - val_loss: 0.4028 - val_accuracy: 0.8400\n",
            "Epoch 66/200\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.3048 - accuracy: 0.8767 - val_loss: 0.4242 - val_accuracy: 0.8000\n",
            "Epoch 67/200\n",
            "3/3 [==============================] - 0s 38ms/step - loss: 0.2422 - accuracy: 0.9315 - val_loss: 0.3637 - val_accuracy: 0.8400\n",
            "Epoch 68/200\n",
            "3/3 [==============================] - 0s 39ms/step - loss: 0.2974 - accuracy: 0.8767 - val_loss: 0.3972 - val_accuracy: 0.8400\n",
            "Epoch 69/200\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 0.2845 - accuracy: 0.9041 - val_loss: 0.4771 - val_accuracy: 0.8000\n",
            "Epoch 70/200\n",
            "3/3 [==============================] - 0s 38ms/step - loss: 0.2382 - accuracy: 0.9452 - val_loss: 0.4330 - val_accuracy: 0.8400\n",
            "Epoch 71/200\n",
            "3/3 [==============================] - 0s 39ms/step - loss: 0.1825 - accuracy: 0.9315 - val_loss: 0.4150 - val_accuracy: 0.7600\n",
            "Epoch 72/200\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 0.2811 - accuracy: 0.8904 - val_loss: 0.4111 - val_accuracy: 0.8400\n",
            "Epoch 73/200\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 0.1842 - accuracy: 0.9452 - val_loss: 0.5590 - val_accuracy: 0.8000\n",
            "Epoch 74/200\n",
            "3/3 [==============================] - 0s 41ms/step - loss: 0.2641 - accuracy: 0.8904 - val_loss: 0.5319 - val_accuracy: 0.8000\n",
            "Epoch 75/200\n",
            "3/3 [==============================] - 0s 51ms/step - loss: 0.2790 - accuracy: 0.8630 - val_loss: 0.4542 - val_accuracy: 0.8000\n",
            "Epoch 76/200\n",
            "3/3 [==============================] - 0s 38ms/step - loss: 0.3118 - accuracy: 0.8630 - val_loss: 0.4161 - val_accuracy: 0.8000\n",
            "Epoch 77/200\n",
            "3/3 [==============================] - 0s 39ms/step - loss: 0.1689 - accuracy: 0.9315 - val_loss: 0.4093 - val_accuracy: 0.8400\n",
            "Epoch 78/200\n",
            "3/3 [==============================] - 0s 42ms/step - loss: 0.2337 - accuracy: 0.8904 - val_loss: 0.4168 - val_accuracy: 0.8400\n",
            "Epoch 79/200\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.1850 - accuracy: 0.9452 - val_loss: 0.3971 - val_accuracy: 0.8400\n",
            "Epoch 80/200\n",
            "3/3 [==============================] - 0s 41ms/step - loss: 0.1553 - accuracy: 0.9452 - val_loss: 0.3917 - val_accuracy: 0.8400\n",
            "Epoch 81/200\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 0.2372 - accuracy: 0.8904 - val_loss: 0.4136 - val_accuracy: 0.8400\n",
            "Epoch 82/200\n",
            "3/3 [==============================] - 0s 37ms/step - loss: 0.2042 - accuracy: 0.9452 - val_loss: 0.4364 - val_accuracy: 0.8400\n",
            "Epoch 83/200\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.2389 - accuracy: 0.9178 - val_loss: 0.4296 - val_accuracy: 0.8400\n",
            "Epoch 84/200\n",
            "3/3 [==============================] - 0s 38ms/step - loss: 0.1563 - accuracy: 0.9589 - val_loss: 0.4299 - val_accuracy: 0.8400\n",
            "Epoch 85/200\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.1137 - accuracy: 0.9726 - val_loss: 0.4554 - val_accuracy: 0.8400\n",
            "Epoch 86/200\n",
            "3/3 [==============================] - 0s 38ms/step - loss: 0.1201 - accuracy: 0.9589 - val_loss: 0.5055 - val_accuracy: 0.8400\n",
            "Epoch 87/200\n",
            "3/3 [==============================] - 0s 38ms/step - loss: 0.1633 - accuracy: 0.9315 - val_loss: 0.5923 - val_accuracy: 0.8400\n",
            "Epoch 88/200\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.1604 - accuracy: 0.9589 - val_loss: 0.5403 - val_accuracy: 0.8400\n",
            "Epoch 89/200\n",
            "3/3 [==============================] - 0s 42ms/step - loss: 0.2444 - accuracy: 0.8767 - val_loss: 0.5017 - val_accuracy: 0.8400\n",
            "Epoch 90/200\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 0.2266 - accuracy: 0.9315 - val_loss: 0.4968 - val_accuracy: 0.8400\n",
            "Epoch 91/200\n",
            "3/3 [==============================] - 0s 37ms/step - loss: 0.1696 - accuracy: 0.9589 - val_loss: 0.4802 - val_accuracy: 0.8400\n",
            "Epoch 92/200\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.1221 - accuracy: 0.9726 - val_loss: 0.3945 - val_accuracy: 0.8400\n",
            "Epoch 93/200\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.2309 - accuracy: 0.8904 - val_loss: 0.3859 - val_accuracy: 0.8400\n",
            "Epoch 94/200\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.1733 - accuracy: 0.9452 - val_loss: 0.5787 - val_accuracy: 0.7600\n",
            "Epoch 95/200\n",
            "3/3 [==============================] - 0s 40ms/step - loss: 0.2532 - accuracy: 0.9041 - val_loss: 0.6246 - val_accuracy: 0.8000\n",
            "Epoch 96/200\n",
            "3/3 [==============================] - 0s 37ms/step - loss: 0.1595 - accuracy: 0.9589 - val_loss: 0.4898 - val_accuracy: 0.8400\n",
            "Epoch 97/200\n",
            "3/3 [==============================] - 0s 41ms/step - loss: 0.1508 - accuracy: 0.9178 - val_loss: 0.4409 - val_accuracy: 0.8400\n",
            "Epoch 98/200\n",
            "3/3 [==============================] - 0s 41ms/step - loss: 0.1157 - accuracy: 0.9726 - val_loss: 0.4432 - val_accuracy: 0.8400\n",
            "Epoch 99/200\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 0.1648 - accuracy: 0.9452 - val_loss: 0.4940 - val_accuracy: 0.8400\n",
            "Epoch 100/200\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 0.1264 - accuracy: 0.9726 - val_loss: 0.5582 - val_accuracy: 0.8400\n",
            "Epoch 101/200\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.0880 - accuracy: 0.9863 - val_loss: 0.6308 - val_accuracy: 0.8400\n",
            "Epoch 102/200\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 0.0780 - accuracy: 0.9726 - val_loss: 0.6926 - val_accuracy: 0.8400\n",
            "Epoch 103/200\n",
            "3/3 [==============================] - 0s 38ms/step - loss: 0.1224 - accuracy: 0.9452 - val_loss: 0.7233 - val_accuracy: 0.8400\n",
            "Epoch 104/200\n",
            "3/3 [==============================] - 0s 38ms/step - loss: 0.0855 - accuracy: 0.9589 - val_loss: 0.7422 - val_accuracy: 0.8000\n",
            "Epoch 105/200\n",
            "3/3 [==============================] - 0s 40ms/step - loss: 0.0802 - accuracy: 0.9863 - val_loss: 0.6895 - val_accuracy: 0.8000\n",
            "Epoch 106/200\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.0960 - accuracy: 0.9863 - val_loss: 0.6596 - val_accuracy: 0.8400\n",
            "Epoch 107/200\n",
            "3/3 [==============================] - 0s 45ms/step - loss: 0.1424 - accuracy: 0.9452 - val_loss: 0.6783 - val_accuracy: 0.8400\n",
            "Epoch 108/200\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.1063 - accuracy: 0.9589 - val_loss: 0.7265 - val_accuracy: 0.8000\n",
            "Epoch 109/200\n",
            "3/3 [==============================] - 0s 40ms/step - loss: 0.0936 - accuracy: 0.9589 - val_loss: 0.7360 - val_accuracy: 0.8400\n",
            "Epoch 110/200\n",
            "3/3 [==============================] - 0s 42ms/step - loss: 0.0545 - accuracy: 0.9863 - val_loss: 0.6890 - val_accuracy: 0.8400\n",
            "Epoch 111/200\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.0877 - accuracy: 0.9726 - val_loss: 0.6846 - val_accuracy: 0.8000\n",
            "Epoch 112/200\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.0697 - accuracy: 0.9863 - val_loss: 0.7028 - val_accuracy: 0.7600\n",
            "Epoch 113/200\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 0.0842 - accuracy: 0.9726 - val_loss: 0.6768 - val_accuracy: 0.8000\n",
            "Epoch 114/200\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.0941 - accuracy: 0.9589 - val_loss: 0.7068 - val_accuracy: 0.8400\n",
            "Epoch 115/200\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 0.0392 - accuracy: 0.9726 - val_loss: 0.7677 - val_accuracy: 0.8000\n",
            "Epoch 116/200\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 0.1511 - accuracy: 0.9726 - val_loss: 0.8384 - val_accuracy: 0.8000\n",
            "Epoch 117/200\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 0.0852 - accuracy: 0.9726 - val_loss: 0.8203 - val_accuracy: 0.8000\n",
            "Epoch 118/200\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 0.0769 - accuracy: 0.9863 - val_loss: 0.7759 - val_accuracy: 0.8400\n",
            "Epoch 119/200\n",
            "3/3 [==============================] - 0s 40ms/step - loss: 0.0532 - accuracy: 0.9863 - val_loss: 0.7146 - val_accuracy: 0.8400\n",
            "Epoch 120/200\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 0.0809 - accuracy: 0.9589 - val_loss: 0.6681 - val_accuracy: 0.8400\n",
            "Epoch 121/200\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 0.0548 - accuracy: 1.0000 - val_loss: 0.7082 - val_accuracy: 0.8400\n",
            "Epoch 122/200\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.0478 - accuracy: 0.9863 - val_loss: 0.7528 - val_accuracy: 0.8400\n",
            "Epoch 123/200\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 0.0541 - accuracy: 0.9726 - val_loss: 0.8013 - val_accuracy: 0.8400\n",
            "Epoch 124/200\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 0.0434 - accuracy: 0.9726 - val_loss: 0.7986 - val_accuracy: 0.8400\n",
            "Epoch 125/200\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.0677 - accuracy: 0.9726 - val_loss: 0.8078 - val_accuracy: 0.8400\n",
            "Epoch 126/200\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 0.0395 - accuracy: 1.0000 - val_loss: 0.8307 - val_accuracy: 0.8400\n",
            "Epoch 127/200\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.0708 - accuracy: 0.9726 - val_loss: 0.8702 - val_accuracy: 0.8400\n",
            "Epoch 128/200\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 0.0661 - accuracy: 0.9726 - val_loss: 0.8943 - val_accuracy: 0.8400\n",
            "Epoch 129/200\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 0.0224 - accuracy: 1.0000 - val_loss: 0.9203 - val_accuracy: 0.8400\n",
            "Epoch 130/200\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 0.0829 - accuracy: 0.9726 - val_loss: 0.8798 - val_accuracy: 0.8400\n",
            "Epoch 131/200\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 0.0463 - accuracy: 0.9863 - val_loss: 0.8585 - val_accuracy: 0.8400\n",
            "Epoch 132/200\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.0550 - accuracy: 0.9863 - val_loss: 0.8501 - val_accuracy: 0.8400\n",
            "Epoch 133/200\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 0.0275 - accuracy: 1.0000 - val_loss: 0.8397 - val_accuracy: 0.8400\n",
            "Epoch 134/200\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.0496 - accuracy: 0.9726 - val_loss: 0.8467 - val_accuracy: 0.8400\n",
            "Epoch 135/200\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.0819 - accuracy: 0.9589 - val_loss: 0.8810 - val_accuracy: 0.8400\n",
            "Epoch 136/200\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.0898 - accuracy: 0.9726 - val_loss: 0.9490 - val_accuracy: 0.8400\n",
            "Epoch 137/200\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.0121 - accuracy: 1.0000 - val_loss: 0.9860 - val_accuracy: 0.8400\n",
            "Epoch 138/200\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.0761 - accuracy: 0.9726 - val_loss: 0.9809 - val_accuracy: 0.8400\n",
            "Epoch 139/200\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 0.0452 - accuracy: 1.0000 - val_loss: 0.9580 - val_accuracy: 0.8400\n",
            "Epoch 140/200\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 0.0472 - accuracy: 0.9863 - val_loss: 0.9995 - val_accuracy: 0.8400\n",
            "Epoch 141/200\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 0.0500 - accuracy: 0.9863 - val_loss: 1.0385 - val_accuracy: 0.8400\n",
            "Epoch 142/200\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 0.0472 - accuracy: 0.9863 - val_loss: 1.0755 - val_accuracy: 0.8400\n",
            "Epoch 143/200\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 0.0736 - accuracy: 0.9726 - val_loss: 1.0702 - val_accuracy: 0.8400\n",
            "Epoch 144/200\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.0296 - accuracy: 1.0000 - val_loss: 1.0613 - val_accuracy: 0.8400\n",
            "Epoch 145/200\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 0.0210 - accuracy: 1.0000 - val_loss: 1.0515 - val_accuracy: 0.8400\n",
            "Epoch 146/200\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 0.0321 - accuracy: 0.9863 - val_loss: 1.0690 - val_accuracy: 0.8400\n",
            "Epoch 147/200\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 0.0466 - accuracy: 0.9726 - val_loss: 1.1248 - val_accuracy: 0.8000\n",
            "Epoch 148/200\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 0.0721 - accuracy: 0.9863 - val_loss: 0.9052 - val_accuracy: 0.8400\n",
            "Epoch 149/200\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 0.1031 - accuracy: 0.9726 - val_loss: 0.8087 - val_accuracy: 0.8400\n",
            "Epoch 150/200\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.2567 - accuracy: 0.9315 - val_loss: 0.7517 - val_accuracy: 0.8400\n",
            "Epoch 151/200\n",
            "3/3 [==============================] - 0s 39ms/step - loss: 0.0436 - accuracy: 0.9863 - val_loss: 1.4268 - val_accuracy: 0.7600\n",
            "Epoch 152/200\n",
            "3/3 [==============================] - 0s 37ms/step - loss: 0.2924 - accuracy: 0.9041 - val_loss: 0.8427 - val_accuracy: 0.8000\n",
            "Epoch 153/200\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.1213 - accuracy: 0.9589 - val_loss: 0.7126 - val_accuracy: 0.8400\n",
            "Epoch 154/200\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 0.1863 - accuracy: 0.9315 - val_loss: 0.7128 - val_accuracy: 0.8400\n",
            "Epoch 155/200\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 0.0829 - accuracy: 0.9863 - val_loss: 0.7696 - val_accuracy: 0.8000\n",
            "Epoch 156/200\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 0.0772 - accuracy: 0.9726 - val_loss: 0.8467 - val_accuracy: 0.8000\n",
            "Epoch 157/200\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 0.0640 - accuracy: 0.9863 - val_loss: 0.9180 - val_accuracy: 0.8000\n",
            "Epoch 158/200\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 0.0408 - accuracy: 0.9863 - val_loss: 0.9679 - val_accuracy: 0.8000\n",
            "Epoch 159/200\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.0884 - accuracy: 0.9589 - val_loss: 0.8736 - val_accuracy: 0.8400\n",
            "Epoch 160/200\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.0274 - accuracy: 1.0000 - val_loss: 0.8138 - val_accuracy: 0.8000\n",
            "Epoch 161/200\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 0.1044 - accuracy: 0.9589 - val_loss: 0.8777 - val_accuracy: 0.8400\n",
            "Epoch 162/200\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 0.0594 - accuracy: 0.9863 - val_loss: 1.0381 - val_accuracy: 0.8400\n",
            "Epoch 163/200\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 0.0348 - accuracy: 1.0000 - val_loss: 1.1229 - val_accuracy: 0.8000\n",
            "Epoch 164/200\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.0847 - accuracy: 0.9863 - val_loss: 1.0830 - val_accuracy: 0.8400\n",
            "Epoch 165/200\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.0305 - accuracy: 0.9863 - val_loss: 1.0434 - val_accuracy: 0.8400\n",
            "Epoch 166/200\n",
            "3/3 [==============================] - 0s 40ms/step - loss: 0.0310 - accuracy: 0.9863 - val_loss: 1.0150 - val_accuracy: 0.8400\n",
            "Epoch 167/200\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 0.0580 - accuracy: 0.9589 - val_loss: 0.9976 - val_accuracy: 0.8400\n",
            "Epoch 168/200\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.0306 - accuracy: 1.0000 - val_loss: 0.9911 - val_accuracy: 0.8400\n",
            "Epoch 169/200\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 0.0302 - accuracy: 1.0000 - val_loss: 1.0022 - val_accuracy: 0.8400\n",
            "Epoch 170/200\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.0252 - accuracy: 0.9863 - val_loss: 1.0212 - val_accuracy: 0.8400\n",
            "Epoch 171/200\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.0529 - accuracy: 0.9863 - val_loss: 1.0509 - val_accuracy: 0.8400\n",
            "Epoch 172/200\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 0.0482 - accuracy: 0.9863 - val_loss: 1.0759 - val_accuracy: 0.8400\n",
            "Epoch 173/200\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 0.0297 - accuracy: 0.9863 - val_loss: 1.0914 - val_accuracy: 0.8400\n",
            "Epoch 174/200\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.0171 - accuracy: 1.0000 - val_loss: 1.0995 - val_accuracy: 0.8400\n",
            "Epoch 175/200\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 0.0177 - accuracy: 1.0000 - val_loss: 1.1108 - val_accuracy: 0.8400\n",
            "Epoch 176/200\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.0123 - accuracy: 1.0000 - val_loss: 1.1165 - val_accuracy: 0.8400\n",
            "Epoch 177/200\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.0457 - accuracy: 0.9863 - val_loss: 1.1110 - val_accuracy: 0.8400\n",
            "Epoch 178/200\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 0.0237 - accuracy: 1.0000 - val_loss: 1.1068 - val_accuracy: 0.8400\n",
            "Epoch 179/200\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 0.0118 - accuracy: 1.0000 - val_loss: 1.1049 - val_accuracy: 0.8400\n",
            "Epoch 180/200\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.0181 - accuracy: 1.0000 - val_loss: 1.1061 - val_accuracy: 0.8400\n",
            "Epoch 181/200\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 0.0399 - accuracy: 0.9863 - val_loss: 1.1205 - val_accuracy: 0.8400\n",
            "Epoch 182/200\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 0.0612 - accuracy: 0.9726 - val_loss: 1.1263 - val_accuracy: 0.8400\n",
            "Epoch 183/200\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 0.0111 - accuracy: 1.0000 - val_loss: 1.1325 - val_accuracy: 0.8400\n",
            "Epoch 184/200\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 0.0335 - accuracy: 0.9863 - val_loss: 1.1434 - val_accuracy: 0.8000\n",
            "Epoch 185/200\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 0.0134 - accuracy: 1.0000 - val_loss: 1.1603 - val_accuracy: 0.8000\n",
            "Epoch 186/200\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.0476 - accuracy: 0.9726 - val_loss: 1.1512 - val_accuracy: 0.8000\n",
            "Epoch 187/200\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 0.0253 - accuracy: 1.0000 - val_loss: 1.1373 - val_accuracy: 0.8400\n",
            "Epoch 188/200\n",
            "3/3 [==============================] - 0s 102ms/step - loss: 0.0250 - accuracy: 1.0000 - val_loss: 1.1393 - val_accuracy: 0.8400\n",
            "Epoch 189/200\n",
            "3/3 [==============================] - 0s 120ms/step - loss: 0.0275 - accuracy: 1.0000 - val_loss: 1.1454 - val_accuracy: 0.8400\n",
            "Epoch 190/200\n",
            "3/3 [==============================] - 0s 133ms/step - loss: 0.0833 - accuracy: 0.9589 - val_loss: 1.1517 - val_accuracy: 0.8400\n",
            "Epoch 191/200\n",
            "3/3 [==============================] - 0s 50ms/step - loss: 0.0387 - accuracy: 0.9863 - val_loss: 1.1663 - val_accuracy: 0.8000\n",
            "Epoch 192/200\n",
            "3/3 [==============================] - 0s 44ms/step - loss: 0.0129 - accuracy: 1.0000 - val_loss: 1.1937 - val_accuracy: 0.8000\n",
            "Epoch 193/200\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 1.2251 - val_accuracy: 0.8000\n",
            "Epoch 194/200\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.0336 - accuracy: 1.0000 - val_loss: 1.2455 - val_accuracy: 0.8000\n",
            "Epoch 195/200\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 0.0123 - accuracy: 1.0000 - val_loss: 1.2614 - val_accuracy: 0.8000\n",
            "Epoch 196/200\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.0139 - accuracy: 1.0000 - val_loss: 1.2718 - val_accuracy: 0.8000\n",
            "Epoch 197/200\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.0585 - accuracy: 0.9726 - val_loss: 1.2506 - val_accuracy: 0.8000\n",
            "Epoch 198/200\n",
            "3/3 [==============================] - 0s 40ms/step - loss: 0.0145 - accuracy: 1.0000 - val_loss: 1.2338 - val_accuracy: 0.8400\n",
            "Epoch 199/200\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.0213 - accuracy: 1.0000 - val_loss: 1.2393 - val_accuracy: 0.8400\n",
            "Epoch 200/200\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.0345 - accuracy: 0.9863 - val_loss: 1.2476 - val_accuracy: 0.8400\n",
            "1/1 [==============================] - 0s 118ms/step\n",
            "Accuracy: 0.88\n",
            "Precision: 0.8822727272727272\n",
            "Recall: 0.88\n",
            "F1 Score: 0.879327731092437\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict on the test data\n",
        "model.load_weights(\"/content/drive/MyDrive/CorrectedAll/3Class_best_model_with_testdata84.h5\")\n",
        "\n",
        "predicted_probabilities = model.predict(x_test)\n",
        "predicted_labels = np.argmax(predicted_probabilities, axis=1)\n",
        "predicted_labels_original = label_encoder.inverse_transform(predicted_labels)\n",
        "\n",
        "# Convert y_val_cat back to class labels\n",
        "y_val_labels = np.argmax(y_test, axis=1)\n",
        "y_val_labels_original = label_encoder.inverse_transform(y_val_labels)\n",
        "\n",
        "# Calculate and print accuracy, precision, recall, and F1 score\n",
        "accuracy = accuracy_score(y_val_labels_original, predicted_labels_original)\n",
        "precision = precision_score(y_val_labels_original, predicted_labels_original, average='weighted')\n",
        "recall = recall_score(y_val_labels_original, predicted_labels_original, average='weighted')\n",
        "f1 = f1_score(y_val_labels_original, predicted_labels_original, average='weighted')\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1 Score:\", f1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "twwoU7REPUUM",
        "outputId": "a9abbf8c-77d1-4adc-f746-45417152475d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 24ms/step\n",
            "Accuracy: 0.84\n",
            "Precision: 0.84\n",
            "Recall: 0.84\n",
            "F1 Score: 0.84\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# creating confusion matrix\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "labels = [\"Fresh\", \"Frozen_20\", \"Frozen_60\"]\n",
        "\n",
        "cm = confusion_matrix(y_val_labels_original, predicted_labels_original)\n",
        "\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
        "\n",
        "disp.plot(cmap=plt.cm.Blues)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "1JUqu7mqRNVn",
        "outputId": "b7781d37-f63f-4564-98d9-7eac2081a68d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Classification using L a b values**\n",
        "\n",
        "\n",
        "1.   Fresh vs Frozen classification\n",
        "2.   Right vs Left classification\n",
        "3.   3 class classification\n",
        "\n",
        "Same models are used for classification with L a b values. First layer adjusted for 3 features \"model.add(Dense(64, input_dim=3, activation='relu'))\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "81216jASZWSU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# unmeasured examples that are not included in the picture examples\n",
        "df = df[df['Unnamed: 0'] != 'F60T1-302 Left FIRST']\n",
        "df = df[df['Unnamed: 0'] != 'F60T1-302 Right FIRST']\n",
        "df = df[df['Unnamed: 0'] != 'F60T1-802 Right FIRST']\n",
        "\n",
        "#examples in the images with missing L value\n",
        "df = df[df['Unnamed: 0'] != 'F20T1-102 Left FIRST']\n",
        "df = df[df['Unnamed: 0'] != 'F20T3-202 Left THIRD']"
      ],
      "metadata": {
        "id": "j-mKXuwgZYEL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1- Fresh vs Frozen classification for L a b\n",
        "search_string = 'fresh'\n",
        "Fresh_df = df[df['Unnamed: 0'].str.contains(search_string, case=False, na=False)]\n",
        "print(Fresh_df.shape)\n",
        "\n",
        "Frozen_df = df.drop(Fresh_df.index)\n",
        "\n",
        "selected_columns = ['Avg L', 'Avg a*', 'Avg b*']\n",
        "Fresh_array = Fresh_df[selected_columns].to_numpy()\n",
        "Frozen_array = Frozen_df[selected_columns].to_numpy()\n",
        "\n",
        "print(Fresh_array.shape)\n",
        "print(Frozen_array.shape)\n",
        "\n",
        "X = np.vstack((Fresh_array, Frozen_array))\n",
        "label1 = np.zeros(len(Fresh_array))\n",
        "label2 = np.ones(len(Frozen_array))\n",
        "Y = np.hstack((label1, label2))\n",
        "X = X.astype(np.float32)"
      ],
      "metadata": {
        "id": "TGlU311nTLoe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2- Right vs Left classification for L a b\n",
        "search_string = 'ight'\n",
        "Right_df = df[df['Unnamed: 0'].str.contains(search_string, case=False, na=False)]\n",
        "\n",
        "Left_df = df.drop(Right_df.index)\n",
        "\n",
        "Right_array = Right_df[selected_columns].to_numpy()\n",
        "Left_array = Left_df[selected_columns].to_numpy()\n",
        "\n",
        "print(Right_array.shape)\n",
        "print(Left_array.shape)\n",
        "X = np.vstack((Right_array, Left_array))\n",
        "label1 = np.zeros(len(Right_array))\n",
        "label2 = np.ones(len(Left_array))\n",
        "Y = np.hstack((label1, label2))\n",
        "X = X.astype(np.float32)"
      ],
      "metadata": {
        "id": "L1CVUMWCTWFU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3 class classification with L a b values\n",
        "search_string = 'F20'\n",
        "F20_df = Frozen_df[Frozen_df['Unnamed: 0'].str.contains(search_string, case=False, na=False)]\n",
        "F60_df = Frozen_df.drop(F20_df.index)\n",
        "F20_array = F20_df[selected_columns].to_numpy()\n",
        "F60_array = F60_df[selected_columns].to_numpy()\n",
        "X = np.vstack((Fresh_array, F20_array, F60_array))\n",
        "label1 = np.zeros(len(Fresh_array))\n",
        "label2 = np.ones(len(F20_array))\n",
        "label3 = np.full(len(F60_array), 2)\n",
        "Y = np.hstack((label1, label2, label3))\n",
        "X = X.astype(np.float32)"
      ],
      "metadata": {
        "id": "BGJ36EFlUDxK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}